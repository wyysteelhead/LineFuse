import cv2
import numpy as np
import albumentations as A
from pathlib import Path
from typing import Union, List, Dict, Any
import random
import logging
from .difficulty_config import get_difficulty_config, get_random_value_in_range, get_random_range_in_ranges

class BlurGenerator:
    def __init__(self, random_seed: int = 42, difficulty: str = 'easy'):
        self.random_seed = random_seed
        self.difficulty = difficulty
        self.difficulty_config = get_difficulty_config(difficulty)
        random.seed(random_seed)
        np.random.seed(random_seed)
        
    def gaussian_blur(self, image: np.ndarray, kernel_size_range: tuple = (5, 15),
                     sigma_range: tuple = (1.0, 3.0),
                     kernel_size: int = None) -> np.ndarray:
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæä¾›äº†å•ä¸ªkernel_sizeï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä»èŒƒå›´ä¸­éšæœºé€‰æ‹©
        if kernel_size is not None:
            selected_kernel_size = kernel_size
        else:
            # ç¡®ä¿kernel_sizeä¸ºå¥‡æ•°ä¸”åœ¨æœ‰æ•ˆèŒƒå›´å†…
            min_size = kernel_size_range[0]
            max_size = kernel_size_range[1]

            # ç¡®ä¿æœ€å°å€¼ä¸ºå¥‡æ•°
            if min_size % 2 == 0:
                min_size += 1
            # ç¡®ä¿æœ€å¤§å€¼ä¸ºå¥‡æ•°
            if max_size % 2 == 0:
                max_size -= 1

            # ç¡®ä¿æœ‰æ•ˆèŒƒå›´
            if min_size > max_size:
                min_size = max_size

            # ç”Ÿæˆå¥‡æ•°kernelå¤§å°
            if min_size == max_size:
                selected_kernel_size = min_size
            else:
                selected_kernel_size = random.randrange(min_size, max_size + 1, 2)

        # ç¡®ä¿selected_kernel_sizeæ˜¯å¥‡æ•°
        if selected_kernel_size % 2 == 0:
            selected_kernel_size += 1

        sigma = random.uniform(sigma_range[0], sigma_range[1])
        return cv2.GaussianBlur(image, (selected_kernel_size, selected_kernel_size), sigma)
    
    def motion_blur(self, image: np.ndarray, kernel_size_range: tuple = (5, 20),
                   angle_range: tuple = (0, 180),
                   kernel_size: int = None) -> np.ndarray:
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæä¾›äº†å•ä¸ªkernel_sizeï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä»èŒƒå›´ä¸­éšæœºé€‰æ‹©
        if kernel_size is not None:
            selected_kernel_size = kernel_size
        else:
            selected_kernel_size = random.randint(kernel_size_range[0], kernel_size_range[1])
        angle = random.randint(angle_range[0], angle_range[1])

        kernel = np.zeros((selected_kernel_size, selected_kernel_size))
        kernel[int((selected_kernel_size-1)/2), :] = np.ones(selected_kernel_size)
        kernel = kernel / selected_kernel_size

        angle_rad = np.deg2rad(angle)
        rotation_matrix = cv2.getRotationMatrix2D((selected_kernel_size//2, selected_kernel_size//2), angle, 1)
        kernel = cv2.warpAffine(kernel, rotation_matrix, (selected_kernel_size, selected_kernel_size))
        
        return cv2.filter2D(image, -1, kernel)
    
    def compression_artifacts(self, image: np.ndarray, quality_range: tuple = (30, 70)) -> np.ndarray:
        quality = random.randint(quality_range[0], quality_range[1])
        
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]
        result, encoded_img = cv2.imencode('.jpg', image, encode_param)
        decoded_img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)
        
        return decoded_img
    
    def print_scan_simulation(self, image: np.ndarray,
                             enable_geometric_distortion: bool = False,
                             noise_intensity: float = 0.3,
                             brightness_contrast_intensity: float = 0.1) -> np.ndarray:
        """
        æ‰“å°æ‰«ææ¨¡æ‹Ÿæ•ˆæœ - å¯é…ç½®å¼ºåº¦å‚æ•°

        Args:
            noise_intensity: å™ªå£°å¼ºåº¦ (0-1)
            brightness_contrast_intensity: äº®åº¦å¯¹æ¯”åº¦å˜åŒ–å¼ºåº¦ (0-1)
        """
        transforms = []

        # å¯é€‰çš„å‡ ä½•å˜å½¢ï¼ˆæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ï¼‰
        if enable_geometric_distortion:
            transforms.append(A.Affine(
                translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},
                scale=(0.9, 1.1),
                rotate=(-2, 2),
                p=0.8
            ))

        # å¯é…ç½®å¼ºåº¦çš„æ•ˆæœ
        # å™ªå£°å¼ºåº¦: æ ¹æ®difficultyè°ƒæ•´
        noise_var_max = 10.0 + 40.0 * noise_intensity  # 10-50çš„èŒƒå›´
        transforms.append(A.GaussNoise(
            var_limit=(5.0, noise_var_max),
            mean=0,
            p=0.7
        ))

        # äº®åº¦å¯¹æ¯”åº¦å˜åŒ–: æ ¹æ®difficultyè°ƒæ•´
        bc_limit = 0.05 + 0.15 * brightness_contrast_intensity  # 0.05-0.2çš„èŒƒå›´
        transforms.append(A.RandomBrightnessContrast(
            brightness_limit=bc_limit,
            contrast_limit=bc_limit,
            p=0.8
        ))

        transform = A.Compose(transforms)
        augmented = transform(image=image)
        return augmented['image']
    
    def low_resolution_upscale(self, image: np.ndarray, 
                              downscale_factor_range: tuple = (4, 8)) -> np.ndarray:
        h, w = image.shape[:2]
        factor = random.randint(downscale_factor_range[0], downscale_factor_range[1])
        
        low_res = cv2.resize(image, (w//factor, h//factor), interpolation=cv2.INTER_AREA)
        upscaled = cv2.resize(low_res, (w, h), interpolation=cv2.INTER_CUBIC)
        
        return upscaled
    
    def add_text_interference(self, image: np.ndarray, 
                            num_texts_range: tuple = (3, 8)) -> np.ndarray:
        h, w = image.shape[:2]
        result = image.copy()
        
        num_texts = random.randint(num_texts_range[0], num_texts_range[1])
        
        for _ in range(num_texts):
            text = random.choice(['A', 'B', 'C', '1', '2', '3', 'X', 'Y'])
            font_scale = random.uniform(0.3, 0.8)
            thickness = random.randint(1, 2)
            
            x = random.randint(50, w-50)
            y = random.randint(50, h-50)
            
            cv2.putText(result, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 
                       font_scale, (128, 128, 128), thickness)
        
        return result
    
    def add_line_interference(self, image: np.ndarray, 
                            num_lines_range: tuple = (2, 6)) -> np.ndarray:
        h, w = image.shape[:2]
        result = image.copy()
        
        num_lines = random.randint(num_lines_range[0], num_lines_range[1])
        
        for _ in range(num_lines):
            pt1 = (random.randint(0, w), random.randint(0, h))
            pt2 = (random.randint(0, w), random.randint(0, h))
            thickness = random.randint(1, 2)
            
            cv2.line(result, pt1, pt2, (200, 200, 200), thickness)
        
        return result
    
    # DEPRECATED: ä½¿ç”¨æ–°çš„é…ç½®åŒ–ç³»ç»Ÿ apply_base_degradation + apply_random_additional_blur
    def apply_random_blur(self, image: np.ndarray, blur_types: List[str] = None) -> Dict[str, Any]:
        if blur_types is None:
            blur_types = [
                'gaussian', 'motion', 'compression', 'scan', 'lowres',
                'text', 'lines',
                'print_scan', 'localblur', 'threshold', 'print_noise',
                'scan_lines', 'composite',
                'line_discontinuity', 'regional_thinning', 'spectral_degradation'
            ]

        blur_type = random.choice(blur_types)
        result_image = image.copy()

        if blur_type == 'gaussian':
            result_image = self.gaussian_blur(result_image)
        elif blur_type == 'motion':
            result_image = self.motion_blur(result_image)
        elif blur_type == 'compression':
            result_image = self.compression_artifacts(result_image)
        elif blur_type == 'scan':
            result_image = self.print_scan_simulation(result_image, enable_geometric_distortion=False)
        elif blur_type == 'lowres':
            result_image = self.low_resolution_upscale(result_image)
        elif blur_type == 'text':
            result_image = self.add_text_interference(result_image)
        elif blur_type == 'lines':
            result_image = self.add_line_interference(result_image)
        elif blur_type == 'print_scan':
            result_image = self.print_scan_blur(result_image)
        elif blur_type == 'localblur':
            result_image = self.local_blur(result_image)
        elif blur_type == 'threshold':
            result_image = self.threshold_artifacts(result_image)
        elif blur_type == 'print_noise':
            result_image = self.add_print_noise(result_image)
        elif blur_type == 'scan_lines':
            result_image = self.add_scan_lines(result_image)
        elif blur_type == 'line_discontinuity':
            result_image = self.line_discontinuity_blur(result_image)
        elif blur_type == 'regional_thinning':
            result_image = self.regional_line_thinning(result_image)
        elif blur_type == 'spectral_degradation':
            result_image = self.spectral_line_degradation(result_image)
        elif blur_type == 'composite':
            return self.apply_composite_blur(result_image, num_ops=random.randint(2, 3))

        return {
            'image': result_image,
            'blur_type': blur_type
        }

    def print_scan_blur(self, image: np.ndarray,
                        edge_blur_sigma: float = 1.2,
                        contrast_reduction: float = 0.9) -> np.ndarray:
        """æ¨¡æ‹ŸçœŸå®çš„æ‰“å°æ‰«ææ•ˆæœï¼šçº¿æ¡å˜ç»†+è¾¹ç¼˜æ¨¡ç³Š+å¯¹æ¯”åº¦é™ä½"""

        # 1. å¼ºçƒˆçš„é«˜æ–¯æ¨¡ç³Šï¼Œæ¨¡æ‹Ÿæ‰“å°çš„ç¾½åŒ–æ•ˆæœ
        heavily_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma)

        # 2. è½»åº¦æ¨¡ç³Šï¼Œä¿æŒä¸€äº›çº¿æ¡ç»“æ„
        lightly_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma * 0.3)

        # 3. æ··åˆå¾—åˆ°ç¾½åŒ–ä½†è¿˜èƒ½çœ‹åˆ°çš„çº¿æ¡ - é™ä½é‡åº¦æ¨¡ç³Šæ¯”ä¾‹
        result = cv2.addWeighted(lightly_blurred, 0.5, heavily_blurred, 0.5, 0)

        # 4. é™ä½å¯¹æ¯”åº¦ï¼Œæ¨¡æ‹ŸçœŸå®æ‰“å°çš„ç°åº¦æ•ˆæœ
        result = result.astype(np.float32)
        # å°†é»‘è‰²(0)å˜æˆæ·±ç°è‰²ï¼Œç™½è‰²(255)ä¿æŒ
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # 5. æ·»åŠ ç»†å¾®çš„èƒŒæ™¯å™ªå£°ï¼Œæ¨¡æ‹Ÿçº¸å¼ çº¹ç†
        paper_texture = np.random.normal(0, 8, result.shape)
        result += paper_texture

        return np.clip(result, 0, 255).astype(np.uint8)

    def local_blur(self, image: np.ndarray,
                   num_patches_range: tuple = (3, 8),
                   patch_size_range: tuple = (20, 60)) -> np.ndarray:
        """Apply blur to random local patches to simulate partial degradation"""
        h, w = image.shape[:2]
        result = image.copy()

        num_patches = random.randint(num_patches_range[0], num_patches_range[1])

        for _ in range(num_patches):
            # Random patch location and size
            patch_size = random.randint(patch_size_range[0], patch_size_range[1])
            x = random.randint(0, max(1, w - patch_size))
            y = random.randint(0, max(1, h - patch_size))

            # Extract patch
            patch = result[y:y+patch_size, x:x+patch_size].copy()

            # Apply strong blur to patch
            kernel_size = random.randrange(7, 15, 2)
            sigma = random.uniform(2.0, 4.0)
            blurred_patch = cv2.GaussianBlur(patch, (kernel_size, kernel_size), sigma)

            # Put back the blurred patch
            result[y:y+patch_size, x:x+patch_size] = blurred_patch

        return result

    def threshold_artifacts(self, image: np.ndarray,
                           threshold_range: tuple = (80, 120)) -> np.ndarray:
        """Apply threshold artifacts to simulate binary conversion effects"""
        # Convert to grayscale if color image
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            is_color = True
        else:
            gray = image.copy()
            is_color = False

        # Apply random threshold
        threshold_val = random.randint(threshold_range[0], threshold_range[1])
        _, binary = cv2.threshold(gray, threshold_val, 255, cv2.THRESH_BINARY)

        # Convert back to original format
        if is_color:
            # Convert back to BGR
            result = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
        else:
            result = binary

        return result

    def add_print_noise(self, image: np.ndarray,
                       noise_intensity: float = 0.15,
                       intensity: float = None) -> np.ndarray:
        """æ·»åŠ çœŸå®çš„æ‰“å°çº¸å¼ å™ªç‚¹ï¼šç°è‰²æ–‘ç‚¹ã€çº¸å¼ çº¹ç†"""
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä½¿ç”¨äº†intensityå‚æ•°ï¼Œåˆ™è¦†ç›–noise_intensity
        if intensity is not None:
            noise_intensity = intensity

        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # 1. ç”Ÿæˆçº¸å¼ çº¹ç†å™ªå£°ï¼ˆä¸»è¦æ˜¯ç°è‰²å€¼ï¼‰
        paper_noise = np.random.normal(0, noise_intensity * 20, (h, w))

        # 2. ç”Ÿæˆç»†å¾®çš„æ‰“å°æ–‘ç‚¹ï¼ˆä¸æ˜¯çº¯é»‘ç™½ï¼Œè€Œæ˜¯ç°è‰²ï¼‰
        spot_mask = np.random.random((h, w)) < (noise_intensity * 0.02)  # 2%çš„åƒç´ æœ‰æ–‘ç‚¹
        spot_values = np.random.uniform(180, 220, np.sum(spot_mask))  # ç°è‰²æ–‘ç‚¹ï¼Œä¸æ˜¯çº¯ç™½

        # 3. åº”ç”¨çº¸å¼ çº¹ç†
        if len(result.shape) == 3:
            for c in range(3):
                result[:, :, c] += paper_noise
        else:
            result += paper_noise

        # 4. æ·»åŠ ç°è‰²æ–‘ç‚¹
        if len(result.shape) == 3:
            # å¯¹äºå½©è‰²å›¾åƒï¼Œä¸ºæ¯ä¸ªé€šé“è®¾ç½®ç›¸åŒçš„ç°è‰²å€¼
            result[spot_mask, 0] = spot_values
            result[spot_mask, 1] = spot_values
            result[spot_mask, 2] = spot_values
        else:
            result[spot_mask] = spot_values

        # 5. ç¡®ä¿å€¼åœ¨åˆç†èŒƒå›´å†…
        result = np.clip(result, 0, 255).astype(np.uint8)

        return result

    def add_scan_lines(self, image: np.ndarray,
                      line_intensity: float = 0.1,
                      line_spacing: int = 3) -> np.ndarray:
        """æ·»åŠ æ‰«ææ¡çº¹æ•ˆæœ"""
        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # åˆ›å»ºæ°´å¹³æ‰«æçº¿æ•ˆæœ
        for y in range(0, h, line_spacing):
            # éšæœºå¼ºåº¦çš„æ‰«æçº¿
            line_strength = np.random.uniform(0.5, 1.0) * line_intensity * 30
            if len(result.shape) == 3:
                result[y, :] = result[y, :] * (1 - line_strength) + 240 * line_strength
            else:
                result[y, :] = result[y, :] * (1 - line_strength) + 240 * line_strength

        return np.clip(result, 0, 255).astype(np.uint8)

    # DEPRECATED: ä½¿ç”¨æ–°çš„é…ç½®åŒ–ç³»ç»Ÿ apply_random_additional_blur æ›´çµæ´»
    def apply_composite_blur(self, image: np.ndarray, num_ops: int = 2) -> Dict[str, Any]:
        """Apply multiple blur operations in sequence for more realistic degradation"""
        available_ops = [
            'gaussian', 'motion', 'compression', 'print_scan',
            'localblur', 'threshold', 'print_noise', 'scan_lines'
        ]

        # Randomly select operations
        selected_ops = random.sample(available_ops, min(num_ops, len(available_ops)))

        result_image = image.copy()
        applied_operations = []

        for op in selected_ops:
            if op == 'gaussian':
                result_image = self.gaussian_blur(result_image)
            elif op == 'motion':
                result_image = self.motion_blur(result_image)
            elif op == 'compression':
                result_image = self.compression_artifacts(result_image)
            elif op == 'morphology':
                result_image = self.random_morphology(result_image)
            elif op == 'localblur':
                result_image = self.local_blur(result_image)
            elif op == 'threshold':
                result_image = self.threshold_artifacts(result_image)
            elif op == 'saltpepper':
                result_image = self.add_salt_pepper(result_image)

            applied_operations.append(op)

        return {
            'image': result_image,
            'blur_type': f"composite_{'_'.join(applied_operations)}"
        }

    def batch_generate_blur(self, 
                          input_dir: Union[str, Path],
                          output_dir: Union[str, Path],
                          num_variants_per_image: int = 5) -> None:
        
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        image_files = list(input_path.glob("*.png")) + list(input_path.glob("*.jpg"))
        
        for img_file in image_files:
            image = cv2.imread(str(img_file))
            if image is None:
                logging.warning(f"Could not load image: {img_file}")
                continue
                
            for i in range(num_variants_per_image):
                result = self.apply_random_blur(image)
                blur_image = result['image']
                blur_type = result['blur_type']

                output_file = output_path / f"{img_file.stem}_{blur_type}_{i}.png"
                cv2.imwrite(str(output_file), blur_image)

                logging.info(f"Generated blur variant: {output_file}")

    def generate_blur(self, input_path: Union[str, Path], output_path: Union[str, Path],
                     blur_type: str = None) -> None:
        """Generate a single blurred image"""
        # Load the image
        image = cv2.imread(str(input_path))
        if image is None:
            raise ValueError(f"Could not load image: {input_path}")

        # Apply blur effect
        if blur_type:
            result = self.apply_random_blur(image, blur_types=[blur_type])
        else:
            result = self.apply_random_blur(image)

        # Save result
        cv2.imwrite(str(output_path), result['image'])

    def generate_blur_with_difficulty(self, input_path: Union[str, Path],
                                    output_path: Union[str, Path],
                                    blur_type: str, difficulty_config: dict) -> None:
        """æ ¹æ®éš¾åº¦é…ç½®ç”Ÿæˆæ¨¡ç³Šå›¾åƒ"""
        # Load the image
        image = cv2.imread(str(input_path))
        if image is None:
            raise ValueError(f"Could not load image: {input_path}")

        # æ ¹æ®æ¨¡ç³Šç±»å‹å’Œéš¾åº¦é…ç½®åº”ç”¨æ•ˆæœ
        if blur_type == 'print_scan':
            result = self.print_scan_blur_with_config(image, difficulty_config)
        elif blur_type == 'print_noise':
            result = self.add_print_noise_with_config(image, difficulty_config)
        elif blur_type == 'scan_lines':
            result = self.add_scan_lines_with_config(image, difficulty_config)
        else:
            # é»˜è®¤ä½¿ç”¨åŸæœ‰æ–¹æ³•
            blur_result = self.apply_random_blur(image, blur_types=[blur_type])
            result = blur_result['image']

        # Save result
        cv2.imwrite(str(output_path), result)

    # DEPRECATED: ä½¿ç”¨æ–°çš„é…ç½®ç³»ç»Ÿ get_difficulty_config() æ›¿ä»£
    def print_scan_blur_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰“å°æ‰«ææ¨¡ç³Šæ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # æ ¹æ®éš¾åº¦è°ƒæ•´æ¨¡ç³Šå¼ºåº¦
        edge_blur_sigma = 1.5 * blur_strength

        # çº¿æ¡ç»†åŒ–å¤„ç†ï¼ˆæ›´é«˜éš¾åº¦->æ›´ç»†çš„çº¿ï¼‰
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        # å¤šå±‚æ¨¡ç³Šå åŠ 
        heavily_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma)
        lightly_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma * 0.3)

        # æ··åˆæ¨¡ç³Šæ•ˆæœ
        result = cv2.addWeighted(lightly_blurred, 0.4, heavily_blurred, 0.6, 0)

        # å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # æ·»åŠ è½»å¾®çš„çº¸å¼ çº¹ç†
        noise_intensity = 0.02 * blur_strength
        noise = np.random.normal(0, noise_intensity * 255, image.shape).astype(np.float32)
        result = np.clip(result + noise, 0, 255)

        return result.astype(np.uint8)

    # DEPRECATED: ä½¿ç”¨æ–°çš„é…ç½®ç³»ç»Ÿ get_difficulty_config() æ›¿ä»£
    def add_print_noise_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰“å°å™ªç‚¹æ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # é¦–å…ˆåº”ç”¨ç»†åŒ–å¤„ç†
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        result = image.copy().astype(np.float32)

        # æ ¹æ®éš¾åº¦è°ƒæ•´å™ªç‚¹å¯†åº¦å’Œå¼ºåº¦
        noise_density = 0.001 * (blur_strength ** 2)  # éš¾åº¦è¶Šé«˜å™ªç‚¹è¶Šå¤š
        noise_intensity = 30 * blur_strength  # éš¾åº¦è¶Šé«˜å™ªç‚¹è¶Šæ˜æ˜¾

        # ç”Ÿæˆå™ªç‚¹ä½ç½®
        h, w = result.shape[:2]
        num_spots = int(h * w * noise_density)

        if num_spots > 0:
            spot_coords = np.random.randint(0, [h, w], size=(num_spots, 2))

            # ç”Ÿæˆç°è‰²å™ªç‚¹ï¼ˆä¸æ˜¯çº¯é»‘ç™½ï¼‰
            spot_values = np.random.uniform(80, 180, num_spots).astype(np.float32)  # ç°è‰²èŒƒå›´

            # åˆ›å»ºæ©ç 
            spot_mask = (spot_coords[:, 0], spot_coords[:, 1])

            # åº”ç”¨å™ªç‚¹åˆ°æ‰€æœ‰é¢œè‰²é€šé“
            if len(result.shape) == 3:
                result[spot_mask[0], spot_mask[1], 0] = spot_values
                result[spot_mask[0], spot_mask[1], 1] = spot_values
                result[spot_mask[0], spot_mask[1], 2] = spot_values
            else:
                result[spot_mask] = spot_values

        # åº”ç”¨å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        return np.clip(result, 0, 255).astype(np.uint8)

    # DEPRECATED: ä½¿ç”¨æ–°çš„é…ç½®ç³»ç»Ÿ get_difficulty_config() æ›¿ä»£
    def add_scan_lines_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰«æçº¿æ¡æ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # é¦–å…ˆåº”ç”¨ç»†åŒ–å¤„ç†
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # æ ¹æ®éš¾åº¦è°ƒæ•´æ‰«æçº¿å¯†åº¦å’Œå¼ºåº¦
        line_spacing = max(2, int(8 - blur_strength * 2))  # éš¾åº¦è¶Šé«˜çº¿æ¡è¶Šå¯†
        line_opacity = 0.1 + 0.1 * blur_strength  # éš¾åº¦è¶Šé«˜çº¿æ¡è¶Šæ˜æ˜¾

        # æ·»åŠ æ°´å¹³æ‰«æçº¿
        for y in range(0, h, line_spacing):
            if len(result.shape) == 3:
                result[y, :, :] *= (1 - line_opacity)
            else:
                result[y, :] *= (1 - line_opacity)

        # æ·»åŠ è½»å¾®çš„å‚ç›´æ‰«æçº¿ï¼ˆå¯†åº¦æ›´ä½ï¼‰
        vertical_spacing = line_spacing * 3
        for x in range(0, w, vertical_spacing):
            if len(result.shape) == 3:
                result[:, x, :] *= (1 - line_opacity * 0.5)
            else:
                result[:, x] *= (1 - line_opacity * 0.5)

        # åº”ç”¨å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # æ·»åŠ è½»å¾®çš„æ•´ä½“æ¨¡ç³Š
        result = cv2.GaussianBlur(result.astype(np.uint8), (3, 3), 0.8 * blur_strength)

        return result.astype(np.uint8)

    def load_image(self, image_path: Union[str, Path]) -> np.ndarray:
        """Load an image from file"""
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        return image

    def line_discontinuity_blur(self, image: np.ndarray,
                               gap_density: float = 0.1,
                               gap_size_range: tuple = (1, 2)) -> np.ndarray:
        """
        åˆ›å»ºæ¸©å’Œè™šçº¿æ•ˆæœ - è§„å¾‹æ€§å°é—´éš™ï¼Œä¿æŒçº¿æ¡ä¸»ä½“è¿ç»­
        gap_density: æ§åˆ¶è™šçº¿é—´éš”é¢‘ç‡ï¼ˆ0.05-0.15ï¼Œä½é¢‘ç‡é«˜è´¨é‡ï¼‰
        gap_size_range: å•ä¸ªé—´éš™å¤§å°ï¼ˆ1-2åƒç´ ï¼ŒçœŸæ­£çš„å°é—´éš™ï¼‰
        """
        result = image.copy()
        h, w = result.shape[:2]

        # Convert to grayscale for line detection
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        # æ‰¾åˆ°çº¿æ¡åƒç´ ï¼ˆæš—è‰²åƒç´ ï¼‰
        line_mask = gray < 180  # ç¨å¾®æ”¾å®½çº¿æ¡æ£€æµ‹
        line_coords = np.where(line_mask)

        if len(line_coords[0]) > 0:
            # æ¸©å’Œè™šçº¿ç­–ç•¥ï¼šä½å¯†åº¦ä½†è§„å¾‹æ€§çš„å°é—´éš™
            # å¤§å¹…é™ä½è¦†ç›–ç‡ï¼Œç¡®ä¿çº¿æ¡ä¸»ä½“ä¿æŒè¿ç»­
            safe_coverage = min(0.15, gap_density)  # å¼ºåˆ¶é™åˆ¶æœ€å¤§15%è¦†ç›–ç‡
            num_dash_gaps = int(len(line_coords[0]) * safe_coverage)

            if num_dash_gaps > 0:
                # å‡åŒ€åˆ†å¸ƒè€Œééšæœºåˆ†å¸ƒï¼Œåˆ›é€ æ›´è§„å¾‹çš„è™šçº¿æ„Ÿ
                step = max(1, len(line_coords[0]) // num_dash_gaps)
                indices = list(range(0, len(line_coords[0]), step))[:num_dash_gaps]

                for idx in indices:
                    gap_y, gap_x = line_coords[0][idx], line_coords[1][idx]

                    # çœŸæ­£çš„å°é—´éš™ - 1-2åƒç´ 
                    gap_size = min(2, max(1, random.randint(gap_size_range[0], gap_size_range[1])))

                    # å•åƒç´ æˆ–åŒåƒç´ é—´éš™
                    if gap_size == 1:
                        # å•åƒç´ é—´éš™
                        if len(result.shape) == 3:
                            result[gap_y, gap_x] = (255, 255, 255)
                        else:
                            result[gap_y, gap_x] = 255
                    else:
                        # 2åƒç´ é—´éš™ï¼ˆåå­—å½¢ï¼‰
                        if gap_y > 0:
                            result[gap_y-1, gap_x] = 255 if len(result.shape) == 2 else (255, 255, 255)
                        if gap_y < h-1:
                            result[gap_y+1, gap_x] = 255 if len(result.shape) == 2 else (255, 255, 255)
                        if gap_x > 0:
                            result[gap_y, gap_x-1] = 255 if len(result.shape) == 2 else (255, 255, 255)
                        if gap_x < w-1:
                            result[gap_y, gap_x+1] = 255 if len(result.shape) == 2 else (255, 255, 255)
                        # ä¸­å¿ƒç‚¹
                        result[gap_y, gap_x] = 255 if len(result.shape) == 2 else (255, 255, 255)

        return result

    def generate_chart_with_line_variations(self, csv_data_path: str,
                                          output_path: str,
                                          thinning_strength: float = 0.3,
                                          fading_strength: float = 0.3,
                                          dash_density: float = 0.0) -> np.ndarray:
        """
        Generate chart with line variations using matplotlib drawing (not image processing)
        é€šè¿‡matplotlibç»˜åˆ¶æ—¶çš„å‚æ•°æ§åˆ¶å®ç°çº¿æ¡å˜åŒ–ï¼Œé¿å…å›¾åƒå¤„ç†ä¼ªå½±

        Args:
            csv_data_path: åŸå§‹CSVæ•°æ®æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºå›¾åƒè·¯å¾„
            thinning_strength: çº¿æ¡å˜ç»†å¼ºåº¦ (0-1)
            fading_strength: çº¿æ¡å˜æ·¡å¼ºåº¦ (0-1)
            dash_density: è™šçº¿å¯†åº¦ (0-1)

        Returns:
            ç”Ÿæˆçš„å›¾åƒæ•°ç»„
        """
        from .clean_chart_generator import CleanChartGenerator

        # åˆ›å»ºå¸¦æœ‰çº¿æ¡å˜åŒ–åŠŸèƒ½çš„å›¾è¡¨ç”Ÿæˆå™¨
        generator = CleanChartGenerator(
            enable_line_variations=True,  # å¯ç”¨çº¿æ¡å˜åŒ–
            enable_style_diversity=False,  # demoä¸­ç¦ç”¨æ ·å¼å¤šæ ·åŒ–
            style_diversity_level=0.0      # ç¡®ä¿ä¸€è‡´æ€§
        )

        # åŠ è½½CSVæ•°æ®
        csv_data = generator.load_csv_data(csv_data_path)
        data = csv_data['data']
        columns = csv_data['columns']
        x_data = data[:, 0]  # ç¬¬ä¸€åˆ—ä¸ºxè½´æ•°æ®
        y_data = data[:, 1]  # ç¬¬äºŒåˆ—ä¸ºyè½´æ•°æ®

        # æ„å»ºçº¿æ¡å˜åŒ–å‚æ•°
        line_variation_params = {
            'thinning_strength': thinning_strength,
            'fading_strength': fading_strength,
            'dash_density': dash_density
        }

        # ä½¿ç”¨matplotlibç»˜åˆ¶æ—¶å°±åº”ç”¨çº¿æ¡å˜åŒ–
        generator.generate_clean_chart(
            x_data, y_data,
            output_path=output_path,
            line_variation_params=line_variation_params
        )

        # åŠ è½½ç”Ÿæˆçš„å›¾åƒå¹¶è¿”å›
        import cv2
        result_image = cv2.imread(output_path)
        if result_image is None:
            raise ValueError(f"Failed to load generated image: {output_path}")

        return result_image

    def apply_single_blur_effect(self, image: np.ndarray, effect_type: str,
                               intensity: float = 0.5) -> np.ndarray:
        """
        åº”ç”¨å•ä¸ªæ¨¡ç³Šæ•ˆæœ - ç”¨äºæ¼”ç¤ºç›®çš„
        Args:
            intensity: æ•ˆæœå¼ºåº¦ (0-1)ï¼Œç”¨äºåŒºåˆ†easy/medium/hard
        """
        result = image.copy()

        if effect_type == 'gaussian':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´é«˜æ–¯æ¨¡ç³Šå‚æ•° - é™ä½å¼ºåº¦
            kernel_size = max(3, int(3 + 4 * intensity))  # 3-7 instead of 3-9
            if kernel_size % 2 == 0:
                kernel_size += 1
            sigma = 0.3 + 1.2 * intensity  # 0.3-1.5 instead of 0.5-2.5
            result = self.gaussian_blur(result, kernel_size=kernel_size, sigma_range=(sigma, sigma))
        elif effect_type == 'motion':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´è¿åŠ¨æ¨¡ç³Š - é™ä½å¼ºåº¦
            kernel_size = max(3, int(3 + 5 * intensity))  # 3-8 instead of 3-11
            result = self.motion_blur(result, kernel_size=kernel_size)
        elif effect_type == 'compression':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´å‹ç¼©è´¨é‡ - æé«˜æœ€ä½è´¨é‡
            quality = int(70 - 40 * intensity)  # 70->30 instead of 80->20
            result = self.compression_blur(result, quality=quality)
        elif effect_type == 'scan':
            # åŸºç¡€æ‰«ææ•ˆæœ - æ›´ç®€å•çš„å™ªå£°
            result = self.print_scan_simulation(result,
                                              noise_intensity=0.2 * intensity,
                                              brightness_contrast_intensity=0.1 * intensity)
        elif effect_type == 'lowres':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´ä¸‹é‡‡æ ·å› å­ - é™ä½å¼ºåº¦
            factor = int(2 + 2 * intensity)  # 2->4 instead of 2->6
            result = self.low_resolution_blur(result, downscale_factor=factor)
        elif effect_type == 'text':
            result = self.add_text_interference(result)
        elif effect_type == 'lines':
            result = self.add_line_interference(result)
        elif effect_type == 'print_scan':
            # é«˜çº§æ‰“å°æ‰«ææ•ˆæœ - æ›´å¼ºçš„å™ªå£°å’Œå¯¹æ¯”åº¦å˜åŒ–
            result = self.print_scan_simulation(result,
                                              noise_intensity=0.5 + 0.5 * intensity,
                                              brightness_contrast_intensity=0.2 + 0.3 * intensity)
        elif effect_type == 'localblur':
            result = self.local_blur_degradation(result)
        elif effect_type == 'scan_lines':
            result = self.add_scan_lines(result)
        elif effect_type == 'spectral_degradation':
            # ä½¿ç”¨é…ç½®åŒ–å‚æ•° - é™ä½å¼ºåº¦
            strength = 0.1 + 0.4 * intensity  # 0.1-0.5 instead of 0.2-0.8
            range_pct = 0.2 + 0.3 * intensity  # 0.2-0.5 instead of 0.3-0.6
            result = self.spectral_line_degradation(result,
                                                  degradation_strength=strength,
                                                  range_percentage=range_pct)
        else:
            print(f"æœªçŸ¥æ•ˆæœç±»å‹: {effect_type}")

        return result

    def spectral_line_degradation(self, image: np.ndarray,
                                x_range: tuple = None,
                                degradation_strength: float = 0.3,
                                range_percentage: float = 0.4,
                                degradation_type: str = 'both') -> np.ndarray:
        """
        Apply configurable degradation effects to spectral line ranges
        ä¸“é—¨é’ˆå¯¹å…‰è°±çº¿çš„ç‰¹å®šxè½´èŒƒå›´è¿›è¡Œå¯é…ç½®å¼ºåº¦çš„é€€åŒ–å¤„ç†

        Args:
            degradation_strength: é€€åŒ–å¼ºåº¦ (0-1)
            range_percentage: å½±å“èŒƒå›´ç™¾åˆ†æ¯” (0-1)
        """
        if x_range is None:
            # Use configurable range percentage
            w = image.shape[1]
            range_width = int(w * range_percentage)
            x_start = random.randint(int(w * 0.1), int(w * 0.6))
            x_range = (x_start, min(x_start + range_width, w))

        result = image.copy()
        x_start, x_end = x_range

        # Extract the region of interest
        roi = result[:, x_start:x_end].copy()

        # 1. å¯é…ç½®çº¿æ¡ç»†åŒ–
        if degradation_type in ['thinning', 'both']:
            # æ ¹æ®å¼ºåº¦è°ƒæ•´kernelå¤§å°å’Œè¿­ä»£æ¬¡æ•°
            kernel_size = max(1, int(1 + 2 * degradation_strength))  # 1-3
            if kernel_size % 2 == 0:
                kernel_size += 1
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
            iterations = max(1, int(degradation_strength * 2))  # 0-2æ¬¡è¿­ä»£
            if iterations > 0:
                roi = cv2.erode(roi, kernel, iterations=iterations)

            # å¯é…ç½®æ¨¡ç³Šå¼ºåº¦
            blur_sigma = 0.3 + 1.2 * degradation_strength  # 0.3-1.5
            roi = cv2.GaussianBlur(roi, (3, 3), blur_sigma)

        # 2. å¯é…ç½®æ–­ç»­æ•ˆæœ
        if degradation_type in ['discontinuity', 'both']:
            gap_density = 0.05 + 0.2 * degradation_strength  # 0.05-0.25
            gap_size_max = int(2 + 6 * degradation_strength)  # 2-8
            roi = self.line_discontinuity_blur(roi, gap_density=gap_density,
                                             gap_size_range=(1, gap_size_max))

        # 3. å¯é…ç½®è¿åŠ¨æ¨¡ç³Š
        motion_kernel_size = max(3, int(3 + 4 * degradation_strength))  # 3-7
        motion_kernel = np.zeros((1, motion_kernel_size))
        motion_kernel[0, :] = 1/motion_kernel_size
        roi = cv2.filter2D(roi, -1, motion_kernel)

        # 4. å¯é…ç½®å¯¹æ¯”åº¦é™ä½
        contrast_factor = 1.0 - 0.3 * degradation_strength  # 1.0-0.7
        if len(roi.shape) == 3:
            roi = roi.astype(np.float32)
            roi = roi * contrast_factor + 255 * (1 - contrast_factor)
            roi = np.clip(roi, 0, 255).astype(np.uint8)

        # Put back the processed region
        result[:, x_start:x_end] = roi

        return result

    def background_color_variation(self, image: np.ndarray,
                                 variation_type: str = 'random',
                                 intensity: float = 0.3) -> np.ndarray:
        """
        Apply background color variation to simulate different lighting/printing conditions
        åº”ç”¨èƒŒæ™¯é¢œè‰²å˜åŒ– - æ¨¡æ‹Ÿä¸åŒçš„å…‰çº¿æˆ–æ‰“å°æ¡ä»¶

        Args:
            variation_type: 'global' (æ•´ä½“å˜åŒ–), 'local' (å±€éƒ¨å˜åŒ–), 'random' (éšæœºé€‰æ‹©)
            intensity: å˜åŒ–å¼ºåº¦ 0.0-1.0
        """
        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        if variation_type == 'random':
            variation_type = random.choice(['global', 'local', 'gradient'])

        if variation_type == 'global':
            # æ•´ä½“é¢œè‰²åç§» - æ¨¡æ‹Ÿæ•´ä½“å…‰çº¿å˜åŒ– (å¢å¼ºæ•ˆæœ)
            if len(result.shape) == 3:
                # ç”Ÿæˆæ•´ä½“è‰²å - å¤§å¹…å¢åŠ å¼ºåº¦è®©æ•ˆæœæ˜æ˜¾
                color_shift = np.array([
                    random.uniform(-80*intensity, 80*intensity),  # R - å¢å¼º2.7å€
                    random.uniform(-70*intensity, 70*intensity),  # G - å¢å¼º2.8å€
                    random.uniform(-90*intensity, 90*intensity)   # B - å¢å¼º2.6å€
                ])

                # ä½¿ç”¨æ›´å®½æ¾çš„èƒŒæ™¯é®ç½©ï¼ŒåŒ…å«æ›´å¤šåƒç´ 
                for c in range(3):
                    channel = result[:, :, c]
                    bg_mask = channel > 150  # é™ä½é˜ˆå€¼ï¼š200â†’150ï¼ŒåŒ…å«æ›´å¤šèƒŒæ™¯åƒç´ 
                    channel[bg_mask] += color_shift[c]

            else:
                # ç°åº¦å›¾çš„äº®åº¦å˜åŒ– - å¢å¼ºæ•ˆæœ
                brightness_shift = random.uniform(-60*intensity, 60*intensity)  # å¢å¼º3å€
                bg_mask = result > 150  # é™ä½é˜ˆå€¼
                result[bg_mask] += brightness_shift

        elif variation_type == 'local':
            # å±€éƒ¨é¢œè‰²å˜åŒ– - æ¨¡æ‹Ÿæ‰«ææ—¶çš„ä¸å‡åŒ€å…‰ç…§
            num_patches = random.randint(3, 8)

            for _ in range(num_patches):
                # éšæœºè¡¥ä¸ä½ç½®å’Œå¤§å°
                patch_w = random.randint(int(w*0.2), int(w*0.6))
                patch_h = random.randint(int(h*0.2), int(h*0.6))
                patch_x = random.randint(0, max(1, w - patch_w))
                patch_y = random.randint(0, max(1, h - patch_h))

                # åˆ›å»ºæ¸å˜é®ç½©è®©å˜åŒ–æ›´è‡ªç„¶
                mask = np.zeros((patch_h, patch_w), dtype=np.float32)
                center_x, center_y = patch_w//2, patch_h//2
                max_dist = min(patch_w, patch_h) // 2

                for y in range(patch_h):
                    for x in range(patch_w):
                        dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                        mask[y, x] = max(0, 1 - dist/max_dist)

                if len(result.shape) == 3:
                    # å½©è‰²å›¾çš„å±€éƒ¨è‰²å - å¢å¼ºæ•ˆæœè®©å˜åŒ–æ›´æ˜æ˜¾
                    local_color_shift = np.array([
                        random.uniform(-60*intensity, 60*intensity),  # å¢å¼º2.4å€
                        random.uniform(-50*intensity, 50*intensity),  # å¢å¼º2.5å€
                        random.uniform(-70*intensity, 70*intensity)   # å¢å¼º2.3å€
                    ])

                    for c in range(3):
                        patch = result[patch_y:patch_y+patch_h, patch_x:patch_x+patch_w, c]
                        bg_mask = patch > 140  # é™ä½é˜ˆå€¼ï¼š180â†’140ï¼ŒåŒ…å«æ›´å¤šèƒŒæ™¯åŒºåŸŸ
                        patch[bg_mask] += mask[bg_mask] * local_color_shift[c]
                else:
                    # ç°åº¦å›¾çš„å±€éƒ¨äº®åº¦å˜åŒ– - å¢å¼ºæ•ˆæœ
                    brightness_shift = random.uniform(-45*intensity, 45*intensity)  # å¢å¼º3å€
                    patch = result[patch_y:patch_y+patch_h, patch_x:patch_x+patch_w]
                    bg_mask = patch > 140  # é™ä½é˜ˆå€¼
                    patch[bg_mask] += mask[bg_mask] * brightness_shift

        elif variation_type == 'gradient':
            # æ¸å˜å˜åŒ– - æ¨¡æ‹Ÿæ‰«æä»ªå…‰æºä¸å‡ (å¢å¼ºæ•ˆæœ)
            direction = random.choice(['horizontal', 'vertical', 'diagonal'])

            if direction == 'horizontal':
                gradient = np.linspace(-50*intensity, 50*intensity, w)  # å¢å¼º2.5å€
                gradient_map = np.tile(gradient, (h, 1))
            elif direction == 'vertical':
                gradient = np.linspace(-50*intensity, 50*intensity, h)  # å¢å¼º2.5å€
                gradient_map = np.tile(gradient.reshape(-1, 1), (1, w))
            else:  # diagonal
                x_grad = np.linspace(-40*intensity, 40*intensity, w)  # å¢å¼º2.7å€
                y_grad = np.linspace(-40*intensity, 40*intensity, h)  # å¢å¼º2.7å€
                gradient_map = np.add.outer(y_grad, x_grad) / 2

            if len(result.shape) == 3:
                # éšæœºé€‰æ‹©ä¸»è¦å½±å“çš„é¢œè‰²é€šé“
                primary_channel = random.randint(0, 2)
                for c in range(3):
                    channel = result[:, :, c]
                    bg_mask = channel > 140  # é™ä½é˜ˆå€¼ï¼š180â†’140
                    if c == primary_channel:
                        channel[bg_mask] += gradient_map[bg_mask]
                    else:
                        channel[bg_mask] += gradient_map[bg_mask] * 0.5  # å¢å¼ºæ¬¡è¦é€šé“å½±å“
            else:
                bg_mask = result > 140  # é™ä½é˜ˆå€¼
                result[bg_mask] += gradient_map[bg_mask]

        # ç¡®ä¿å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
        result = np.clip(result, 0, 255).astype(np.uint8)
        return result

    def apply_base_degradation(self, image: np.ndarray) -> tuple:
        """
        Apply base degradation effects that should be present in every image:
        - Background color variation (lighting/printing conditions)
        - Line thickness inconsistency (regional_thinning with color variation)
        - Line discontinuity (dashed line effect)
        - Print noise artifacts
        å¯¹æ¯å¼ å›¾ç‰‡éƒ½åº”ç”¨çš„åŸºç¡€é€€åŒ–æ•ˆæœç»„åˆ - ä½¿ç”¨é…ç½®åŒ–çš„å¼ºåº¦èŒƒå›´

        Returns:
            tuple: (degraded_image, effects_log)
        """
        result = image.copy()
        config = self.difficulty_config
        applied_effects = []

        try:
            # 1. åº•è‰²å˜åŒ– (æ¨¡æ‹Ÿå…‰çº¿/æ‰“å°æ¡ä»¶å·®å¼‚) - ä½¿ç”¨é…ç½®åŒ–å¼ºåº¦
            bg_intensity = get_random_value_in_range(config['background_variation']['intensity'])
            effect_log = f"background_variation(intensity={bg_intensity:.3f})"
            applied_effects.append(effect_log)
            result = self.background_color_variation(result, intensity=bg_intensity)

            # 2. çº¿æ¡å˜åŒ–æ•ˆæœ - ä¿å­˜å‚æ•°ä»¥ä¾¿åœ¨ç»˜åˆ¶æ—¶åº”ç”¨
            line_config = config['line_thinning_fading']
            thinning_strength = get_random_value_in_range(line_config['thinning_strength'])
            fading_strength = get_random_value_in_range(line_config['fading_strength'])
            num_regions = get_random_value_in_range(line_config['num_regions'], is_int=True)
            effect_log = f"line_variations(thin={thinning_strength:.3f}, fade={fading_strength:.3f}, regions={num_regions})"
            applied_effects.append(effect_log)

            # 3. çº¿æ®µæ–­æ–­ç»­ç»­ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°ï¼Œæ•´åˆåˆ°çº¿æ¡å˜åŒ–ä¸­
            discontinuity_config = config['line_discontinuity']
            gap_density = get_random_value_in_range(discontinuity_config['gap_density'])
            gap_size_range = discontinuity_config['gap_size_range'][0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªèŒƒå›´

            # ç¡®ä¿gap_size_rangeæœ‰æ•ˆ
            if gap_size_range[0] > gap_size_range[1]:
                gap_size_range = (gap_size_range[1], gap_size_range[0])

            effect_log = f"line_discontinuity(density={gap_density:.3f}, gap_range={gap_size_range})"
            applied_effects.append(effect_log)

            # å­˜å‚¨å®Œæ•´çš„çº¿æ¡å˜åŒ–å‚æ•°ï¼ŒåŒ…å«è™šçº¿æ•ˆæœ
            self.line_variation_params = {
                'thinning_strength': thinning_strength,
                'fading_strength': fading_strength,
                'dash_density': gap_density  # ä½¿ç”¨gap_densityä½œä¸ºè™šçº¿å¯†åº¦
            }

            # æ³¨æ„ï¼šç°åœ¨ä¸å†è°ƒç”¨å›¾åƒå¤„ç†æ–¹æ³•ï¼Œçº¿æ¡å˜åŒ–å°†åœ¨ç»˜åˆ¶æ—¶åº”ç”¨
            # result = self.line_discontinuity_blur(...) # æ³¨é‡Šæ‰åŸæ¥çš„å›¾åƒå¤„ç†æ–¹æ³•

            # 4. æ‰“å°å™ªç‚¹æ•ˆæœ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°
            noise_intensity = get_random_value_in_range(config['print_noise']['noise_intensity'])
            effect_log = f"print_noise(intensity={noise_intensity:.3f})"
            applied_effects.append(effect_log)
            result = self.add_print_noise(result, noise_intensity=noise_intensity)

        except Exception as e:
            print(f"ğŸš¨ BASE DEGRADATION ERROR:")
            print(f"   Difficulty: {self.difficulty}")
            print(f"   Applied effects so far: {applied_effects}")
            print(f"   Error: {str(e)}")
            print(f"   Config: {config}")
            raise e

        return result, applied_effects

    def apply_random_additional_blur(self, image: np.ndarray, num_effects: int = None) -> Dict[str, Any]:
        """
        Apply random additional blur effects on top of base degradation using difficulty-based parameters
        åœ¨åŸºç¡€é€€åŒ–çš„åŸºç¡€ä¸Šéšæœºæ·»åŠ é¢å¤–çš„æ¨¡ç³Šæ•ˆæœï¼ˆä½¿ç”¨é…ç½®åŒ–çš„éš¾åº¦å‚æ•°ï¼‰
        """
        config = self.difficulty_config
        if num_effects is None:
            num_effects = get_random_value_in_range(config['additional_effects_count'], is_int=True)

        # å¯é€‰çš„é¢å¤–æ¨¡ç³Šæ•ˆæœï¼ˆä¸åŒ…æ‹¬åŸºç¡€å¿…åŠ æ•ˆæœï¼‰
        additional_effects = [
            'gaussian', 'motion', 'compression', 'scan', 'lowres',
            'text', 'lines', 'print_scan', 'localblur',  # æš‚æ—¶ç§»é™¤threshold
            'scan_lines', 'spectral_degradation'
        ]

        # éšæœºé€‰æ‹©effects
        selected_effects = random.sample(additional_effects,
                                       min(num_effects, len(additional_effects)))

        result = image.copy()
        applied_effects = []
        effect_details = []

        print(f"ğŸ”§ ADDITIONAL BLUR: {self.difficulty} difficulty, applying {num_effects} effects: {selected_effects}")

        for effect in selected_effects:
            try:
                if effect == 'gaussian':
                    # ä½¿ç”¨é…ç½®åŒ–çš„é«˜æ–¯æ¨¡ç³Šå‚æ•°
                    gaussian_config = config['gaussian_blur']
                    kernel_range = get_random_range_in_ranges(gaussian_config['kernel_size_range'], is_int=True)
                    sigma_range = get_random_range_in_ranges(gaussian_config['sigma_range'])
                    effect_details.append(f"gaussian(kernel={kernel_range}, sigma={sigma_range})")
                    result = self.gaussian_blur(result, kernel_size_range=kernel_range, sigma_range=sigma_range)
                elif effect == 'motion':
                    # ä½¿ç”¨é…ç½®åŒ–çš„è¿åŠ¨æ¨¡ç³Šå‚æ•°
                    motion_config = config['motion_blur']
                    kernel_range = get_random_range_in_ranges(motion_config['kernel_size_range'], is_int=True)
                    effect_details.append(f"motion(kernel={kernel_range})")
                    result = self.motion_blur(result, kernel_size_range=kernel_range)
                elif effect == 'compression':
                    # ä½¿ç”¨é…ç½®åŒ–çš„å‹ç¼©å‚æ•°
                    comp_config = config['compression']
                    quality_range = get_random_range_in_ranges(comp_config['quality_range'], is_int=True)
                    effect_details.append(f"compression(quality={quality_range})")
                    result = self.compression_artifacts(result, quality_range=quality_range)
                elif effect == 'scan':
                    effect_details.append("print_scan_simulation")
                    result = self.print_scan_simulation(result, enable_geometric_distortion=False)
                elif effect == 'lowres':
                    # ä½¿ç”¨é…ç½®åŒ–çš„ä½åˆ†è¾¨ç‡å‚æ•°
                    lowres_config = config['lowres']
                    factor_range = get_random_range_in_ranges(lowres_config['downscale_factor_range'], is_int=True)
                    effect_details.append(f"lowres(factor={factor_range})")
                    result = self.low_resolution_upscale(result, downscale_factor_range=factor_range)
                elif effect == 'text':
                    # ä½¿ç”¨é…ç½®åŒ–çš„æ–‡æœ¬å¹²æ‰°å‚æ•° (å›ºå®šèŒƒå›´)
                    effect_details.append("text_interference(1-3)")
                    result = self.add_text_interference(result, num_texts_range=(1, 3))
                elif effect == 'lines':
                    # ä½¿ç”¨é…ç½®åŒ–çš„çº¿æ¡å¹²æ‰°å‚æ•° (å›ºå®šèŒƒå›´)
                    effect_details.append("line_interference(1-3)")
                    result = self.add_line_interference(result, num_lines_range=(1, 3))
                elif effect == 'print_scan':
                    effect_details.append("print_scan_blur")
                    result = self.print_scan_blur(result)
                elif effect == 'localblur':
                    effect_details.append("local_blur")
                    result = self.local_blur(result)
                elif effect == 'threshold':
                    # ä½¿ç”¨é…ç½®åŒ–çš„é˜ˆå€¼å‚æ•°
                    threshold_config = config['threshold']
                    threshold_range = get_random_range_in_ranges(threshold_config['threshold_range'], is_int=True)
                    effect_details.append(f"threshold(range={threshold_range})")
                    result = self.threshold_artifacts(result, threshold_range=threshold_range)
                elif effect == 'scan_lines':
                    effect_details.append("scan_lines")
                    result = self.add_scan_lines(result)
                elif effect == 'spectral_degradation':
                    # ä½¿ç”¨é…ç½®åŒ–çš„å…‰è°±é€€åŒ–å‚æ•°
                    spectral_config = config['spectral_degradation']
                    degradation_strength = get_random_value_in_range(spectral_config['degradation_strength'])
                    range_percentage = get_random_value_in_range(spectral_config['range_percentage'])
                    effect_details.append(f"spectral_degradation(strength={degradation_strength:.3f}, range={range_percentage:.3f})")
                    result = self.spectral_line_degradation(result)

                applied_effects.append(effect)
            except Exception as e:
                print(f"ğŸš¨ ADDITIONAL BLUR ERROR in {effect}:")
                print(f"   Difficulty: {self.difficulty}")
                print(f"   Applied effects so far: {effect_details}")
                print(f"   Current effect: {effect}")
                print(f"   Error: {str(e)}")
                raise e

        return {
            'image': result,
            'blur_type': f"base_plus_{'_'.join(applied_effects)}",
            'additional_effects': applied_effects,
            'additional_effects_details': effect_details,
            'num_additional': len(applied_effects)
        }

    def simple_line_thinning_and_fading(self, image: np.ndarray,
                                      thinning_strength: float = 0.3,
                                      fading_strength: float = 0.3) -> np.ndarray:
        """
        ç®€å•çš„çº¿æ¡ç»†åŒ–å’Œå˜æ·¡æ•ˆæœ

        Args:
            image: è¾“å…¥å›¾åƒ
            thinning_strength: ç»†åŒ–å¼ºåº¦ (0-1)
            fading_strength: å˜æ·¡å¼ºåº¦ (0-1)

        Returns:
            å¤„ç†åçš„å›¾åƒ
        """
        result = image.copy()

        # æ£€æµ‹çº¿æ¡åŒºåŸŸ (æš—è‰²åŒºåŸŸ)
        gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) if len(result.shape) == 3 else result.copy()
        line_mask = gray < 180  # çº¿æ¡é€šå¸¸æ˜¯æš—è‰²çš„

        # 1. å¢å¼ºçš„çº¿æ¡ç»†åŒ– - å¤šçº§è…èš€ç¡®ä¿å¯è§æ•ˆæœ
        if thinning_strength > 0:
            # ä½¿ç”¨æ›´å¤§çš„kernelå’Œæ›´å¤šè¿­ä»£æ¥ç¡®ä¿æ˜æ˜¾æ•ˆæœ
            kernel_size = max(3, int(5 * thinning_strength))  # å¢åŠ kernelå¤§å°
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))

            # å¤šæ¬¡è¿­ä»£è…èš€ï¼Œå¢å¼ºç»†åŒ–æ•ˆæœ
            iterations = max(1, int(2 * thinning_strength))
            thinned_gray = cv2.erode(gray, kernel, iterations=iterations)

            # å‡å°‘æ··åˆæ¯”ä¾‹ï¼Œè®©ç»†åŒ–æ•ˆæœæ›´æ˜æ˜¾
            alpha = max(0.3, 1 - thinning_strength * 1.5)  # æ›´å¼ºçš„ç»†åŒ–æ··åˆ
            gray = cv2.addWeighted(gray, alpha, thinned_gray, 1 - alpha, 0)

        # 2. å¢å¼ºçš„çº¿æ¡å˜æ·¡ - æ›´æ˜æ˜¾çš„äº®åº¦å¢åŠ 
        if fading_strength > 0:
            # å¢åŠ å˜æ·¡å¼ºåº¦ï¼Œä½¿æ•ˆæœæ›´æ˜æ˜¾
            fade_amount = int(80 * fading_strength)  # å¢åŠ åˆ°80æœ€å¤§äº®åº¦å¢åŠ 

            # é‡æ–°æ£€æµ‹çº¿æ¡åŒºåŸŸï¼ˆå› ä¸ºç»†åŒ–åå¯èƒ½æœ‰å˜åŒ–ï¼‰
            current_line_mask = gray < 180

            # åˆ†çº§å˜æ·¡ - ä¸åŒåŒºåŸŸä¸åŒç¨‹åº¦çš„å˜æ·¡
            gray[current_line_mask] = np.clip(gray[current_line_mask] + fade_amount, 0, 255)

            # é¢å¤–çš„è¾¹ç¼˜å˜æ·¡æ•ˆæœ
            if fading_strength > 0.5:  # é«˜å¼ºåº¦æ—¶æ·»åŠ è¾¹ç¼˜å¤„ç†
                edge_mask = cv2.Canny(gray, 50, 150) > 0
                gray[edge_mask] = np.clip(gray[edge_mask] + fade_amount//2, 0, 255)

        # è½¬æ¢å›åŸå§‹è‰²å½©ç©ºé—´
        if len(result.shape) == 3:
            result = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
        else:
            result = gray

        return result

    def local_blur_degradation(self, image: np.ndarray,
                              num_regions: int = 3,
                              blur_intensity: float = 0.5) -> np.ndarray:
        """
        å±€éƒ¨æ¨¡ç³Šé€€åŒ–æ•ˆæœ - åœ¨å›¾åƒçš„éšæœºåŒºåŸŸåº”ç”¨æ¨¡ç³Š

        Args:
            image: è¾“å…¥å›¾åƒ
            num_regions: æ¨¡ç³ŠåŒºåŸŸæ•°é‡
            blur_intensity: æ¨¡ç³Šå¼ºåº¦ (0-1)

        Returns:
            å¤„ç†åçš„å›¾åƒ
        """
        result = image.copy()
        h, w = result.shape[:2]

        for i in range(num_regions):
            # å¢å¤§åŒºåŸŸå°ºå¯¸ä»¥ç¡®ä¿å¯è§æ•ˆæœ
            region_w = random.randint(w//6, w//2)  # æ›´å¤§çš„åŒºåŸŸå®½åº¦
            region_h = random.randint(h//6, h//2)  # æ›´å¤§çš„åŒºåŸŸé«˜åº¦
            x = random.randint(0, w - region_w)
            y = random.randint(0, h - region_h)

            # æå–åŒºåŸŸ
            region = result[y:y+region_h, x:x+region_w].copy()

            # å¢å¼ºå±€éƒ¨æ¨¡ç³Šæ•ˆæœ
            kernel_size = max(7, int(15 * blur_intensity))  # æ›´å¤§çš„kernel
            if kernel_size % 2 == 0:  # ç¡®ä¿æ˜¯å¥‡æ•°
                kernel_size += 1
            sigma = 2.0 + 4.0 * blur_intensity  # æ›´å¤§çš„sigma
            blurred_region = cv2.GaussianBlur(region, (kernel_size, kernel_size), sigma)

            # åˆ›å»ºæ¸å˜æ··åˆè’™ç‰ˆï¼Œé¿å…ç¡¬è¾¹ç¼˜
            mask = np.zeros((region_h, region_w), dtype=np.float32)
            center_x, center_y = region_w // 2, region_h // 2
            max_dist = min(region_w, region_h) // 2

            for py in range(region_h):
                for px in range(region_w):
                    dist = np.sqrt((px - center_x)**2 + (py - center_y)**2)
                    if dist < max_dist:
                        mask[py, px] = 1.0 - (dist / max_dist)

            # åº”ç”¨æ··åˆè’™ç‰ˆ
            if len(result.shape) == 3:
                mask = np.stack([mask] * 3, axis=-1)

            # å¢å¼ºæ··åˆæ•ˆæœï¼Œè®©æ¨¡ç³Šæ›´æ˜æ˜¾
            enhanced_intensity = min(1.0, blur_intensity * 1.5)  # å¢å¼ºå¼ºåº¦
            mixed_region = region * (1 - mask * enhanced_intensity) + blurred_region * (mask * enhanced_intensity)
            result[y:y+region_h, x:x+region_w] = mixed_region.astype(np.uint8)

        return result

    def compression_blur(self, image: np.ndarray, quality: int = None, quality_range: tuple = (30, 70)) -> np.ndarray:
        """
        å‹ç¼©æ¨¡ç³Šæ•ˆæœçš„åˆ«åæ–¹æ³• - å…¼å®¹main.pyä¸­çš„è°ƒç”¨

        Args:
            image: è¾“å…¥å›¾åƒ
            quality: å‹ç¼©è´¨é‡ (1-100ï¼Œè¶Šå°å‹ç¼©è¶Šå¼º)
            quality_range: è´¨é‡èŒƒå›´ï¼Œå½“qualityä¸ºNoneæ—¶ä½¿ç”¨

        Returns:
            å‹ç¼©åçš„å›¾åƒ
        """
        if quality is not None:
            # å•ä¸ªè´¨é‡å€¼
            return self.compression_artifacts(image, quality_range=(quality, quality))
        else:
            # ä½¿ç”¨èŒƒå›´
            return self.compression_artifacts(image, quality_range=quality_range)

    def low_resolution_blur(self, image: np.ndarray, downscale_factor: int = None, downscale_factor_range: tuple = (4, 8)) -> np.ndarray:
        """
        ä½åˆ†è¾¨ç‡æ¨¡ç³Šæ•ˆæœçš„åˆ«åæ–¹æ³• - å…¼å®¹main.pyä¸­çš„è°ƒç”¨

        Args:
            image: è¾“å…¥å›¾åƒ
            downscale_factor: ä¸‹é‡‡æ ·å› å­
            downscale_factor_range: ä¸‹é‡‡æ ·å› å­èŒƒå›´ï¼Œå½“downscale_factorä¸ºNoneæ—¶ä½¿ç”¨

        Returns:
            ä½åˆ†è¾¨ç‡å¤„ç†åçš„å›¾åƒ
        """
        if downscale_factor is not None:
            # å•ä¸ªå› å­å€¼
            return self.low_resolution_upscale(image, downscale_factor_range=(downscale_factor, downscale_factor))
        else:
            # ä½¿ç”¨èŒƒå›´
            return self.low_resolution_upscale(image, downscale_factor_range=downscale_factor_range)