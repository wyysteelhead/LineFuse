import cv2
import numpy as np
import albumentations as A
from pathlib import Path
from typing import Union, List, Dict, Any
import random
import logging
from .difficulty_config import get_difficulty_config, get_random_value_in_range, get_random_range_in_ranges

class BlurGenerator:
    def __init__(self, random_seed: int = 42, difficulty: str = 'easy'):
        self.random_seed = random_seed
        self.difficulty = difficulty
        self.difficulty_config = get_difficulty_config(difficulty)
        random.seed(random_seed)
        np.random.seed(random_seed)
        
    def gaussian_blur(self, image: np.ndarray, kernel_size_range: tuple = (5, 15),
                     sigma_range: tuple = (1.0, 3.0)) -> np.ndarray:
        # ç¡®ä¿kernel_sizeä¸ºå¥‡æ•°ä¸”åœ¨æœ‰æ•ˆèŒƒå›´å†…
        min_size = kernel_size_range[0]
        max_size = kernel_size_range[1]

        # ç¡®ä¿æœ€å°å€¼ä¸ºå¥‡æ•°
        if min_size % 2 == 0:
            min_size += 1
        # ç¡®ä¿æœ€å¤§å€¼ä¸ºå¥‡æ•°
        if max_size % 2 == 0:
            max_size -= 1

        # ç¡®ä¿æœ‰æ•ˆèŒƒå›´
        if min_size > max_size:
            min_size = max_size

        # ç”Ÿæˆå¥‡æ•°kernelå¤§å°
        if min_size == max_size:
            kernel_size = min_size
        else:
            kernel_size = random.randrange(min_size, max_size + 1, 2)

        sigma = random.uniform(sigma_range[0], sigma_range[1])
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)
    
    def motion_blur(self, image: np.ndarray, kernel_size_range: tuple = (5, 20), 
                   angle_range: tuple = (0, 180)) -> np.ndarray:
        kernel_size = random.randint(kernel_size_range[0], kernel_size_range[1])
        angle = random.randint(angle_range[0], angle_range[1])
        
        kernel = np.zeros((kernel_size, kernel_size))
        kernel[int((kernel_size-1)/2), :] = np.ones(kernel_size)
        kernel = kernel / kernel_size
        
        angle_rad = np.deg2rad(angle)
        rotation_matrix = cv2.getRotationMatrix2D((kernel_size//2, kernel_size//2), angle, 1)
        kernel = cv2.warpAffine(kernel, rotation_matrix, (kernel_size, kernel_size))
        
        return cv2.filter2D(image, -1, kernel)
    
    def compression_artifacts(self, image: np.ndarray, quality_range: tuple = (30, 70)) -> np.ndarray:
        quality = random.randint(quality_range[0], quality_range[1])
        
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]
        result, encoded_img = cv2.imencode('.jpg', image, encode_param)
        decoded_img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)
        
        return decoded_img
    
    def print_scan_simulation(self, image: np.ndarray, enable_geometric_distortion: bool = False) -> np.ndarray:
        transforms = []

        # å¯é€‰çš„å‡ ä½•å˜å½¢ï¼ˆæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ï¼‰
        if enable_geometric_distortion:
            transforms.append(A.Affine(
                translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},
                scale=(0.9, 1.1),
                rotate=(-2, 2),
                p=0.8
            ))

        # å§‹ç»ˆåº”ç”¨çš„æ•ˆæœï¼šå™ªå£°å’Œäº®åº¦å¯¹æ¯”åº¦
        transforms.extend([
            A.GaussNoise(var_limit=(10.0, 50.0), mean=0, p=0.7),
            A.RandomBrightnessContrast(
                brightness_limit=0.1,
                contrast_limit=0.1,
                p=0.8
            )
        ])

        transform = A.Compose(transforms)
        augmented = transform(image=image)
        return augmented['image']
    
    def low_resolution_upscale(self, image: np.ndarray, 
                              downscale_factor_range: tuple = (4, 8)) -> np.ndarray:
        h, w = image.shape[:2]
        factor = random.randint(downscale_factor_range[0], downscale_factor_range[1])
        
        low_res = cv2.resize(image, (w//factor, h//factor), interpolation=cv2.INTER_AREA)
        upscaled = cv2.resize(low_res, (w, h), interpolation=cv2.INTER_CUBIC)
        
        return upscaled
    
    def add_text_interference(self, image: np.ndarray, 
                            num_texts_range: tuple = (3, 8)) -> np.ndarray:
        h, w = image.shape[:2]
        result = image.copy()
        
        num_texts = random.randint(num_texts_range[0], num_texts_range[1])
        
        for _ in range(num_texts):
            text = random.choice(['A', 'B', 'C', '1', '2', '3', 'X', 'Y'])
            font_scale = random.uniform(0.3, 0.8)
            thickness = random.randint(1, 2)
            
            x = random.randint(50, w-50)
            y = random.randint(50, h-50)
            
            cv2.putText(result, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 
                       font_scale, (128, 128, 128), thickness)
        
        return result
    
    def add_line_interference(self, image: np.ndarray, 
                            num_lines_range: tuple = (2, 6)) -> np.ndarray:
        h, w = image.shape[:2]
        result = image.copy()
        
        num_lines = random.randint(num_lines_range[0], num_lines_range[1])
        
        for _ in range(num_lines):
            pt1 = (random.randint(0, w), random.randint(0, h))
            pt2 = (random.randint(0, w), random.randint(0, h))
            thickness = random.randint(1, 2)
            
            cv2.line(result, pt1, pt2, (200, 200, 200), thickness)
        
        return result
    
    def apply_random_blur(self, image: np.ndarray, blur_types: List[str] = None) -> Dict[str, Any]:
        if blur_types is None:
            blur_types = [
                'gaussian', 'motion', 'compression', 'scan', 'lowres',
                'text', 'lines',
                'print_scan', 'localblur', 'threshold', 'print_noise',
                'scan_lines', 'composite',
                'line_discontinuity', 'regional_thinning', 'spectral_degradation'
            ]

        blur_type = random.choice(blur_types)
        result_image = image.copy()

        if blur_type == 'gaussian':
            result_image = self.gaussian_blur(result_image)
        elif blur_type == 'motion':
            result_image = self.motion_blur(result_image)
        elif blur_type == 'compression':
            result_image = self.compression_artifacts(result_image)
        elif blur_type == 'scan':
            result_image = self.print_scan_simulation(result_image, enable_geometric_distortion=False)
        elif blur_type == 'lowres':
            result_image = self.low_resolution_upscale(result_image)
        elif blur_type == 'text':
            result_image = self.add_text_interference(result_image)
        elif blur_type == 'lines':
            result_image = self.add_line_interference(result_image)
        elif blur_type == 'print_scan':
            result_image = self.print_scan_blur(result_image)
        elif blur_type == 'localblur':
            result_image = self.local_blur(result_image)
        elif blur_type == 'threshold':
            result_image = self.threshold_artifacts(result_image)
        elif blur_type == 'print_noise':
            result_image = self.add_print_noise(result_image)
        elif blur_type == 'scan_lines':
            result_image = self.add_scan_lines(result_image)
        elif blur_type == 'line_discontinuity':
            result_image = self.line_discontinuity_blur(result_image)
        elif blur_type == 'regional_thinning':
            result_image = self.regional_line_thinning(result_image)
        elif blur_type == 'spectral_degradation':
            result_image = self.spectral_line_degradation(result_image)
        elif blur_type == 'composite':
            return self.apply_composite_blur(result_image, num_ops=random.randint(2, 3))

        return {
            'image': result_image,
            'blur_type': blur_type
        }

    def print_scan_blur(self, image: np.ndarray,
                        edge_blur_sigma: float = 1.2,
                        contrast_reduction: float = 0.9) -> np.ndarray:
        """æ¨¡æ‹ŸçœŸå®çš„æ‰“å°æ‰«ææ•ˆæœï¼šçº¿æ¡å˜ç»†+è¾¹ç¼˜æ¨¡ç³Š+å¯¹æ¯”åº¦é™ä½"""

        # 1. å¼ºçƒˆçš„é«˜æ–¯æ¨¡ç³Šï¼Œæ¨¡æ‹Ÿæ‰“å°çš„ç¾½åŒ–æ•ˆæœ
        heavily_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma)

        # 2. è½»åº¦æ¨¡ç³Šï¼Œä¿æŒä¸€äº›çº¿æ¡ç»“æ„
        lightly_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma * 0.3)

        # 3. æ··åˆå¾—åˆ°ç¾½åŒ–ä½†è¿˜èƒ½çœ‹åˆ°çš„çº¿æ¡ - é™ä½é‡åº¦æ¨¡ç³Šæ¯”ä¾‹
        result = cv2.addWeighted(lightly_blurred, 0.5, heavily_blurred, 0.5, 0)

        # 4. é™ä½å¯¹æ¯”åº¦ï¼Œæ¨¡æ‹ŸçœŸå®æ‰“å°çš„ç°åº¦æ•ˆæœ
        result = result.astype(np.float32)
        # å°†é»‘è‰²(0)å˜æˆæ·±ç°è‰²ï¼Œç™½è‰²(255)ä¿æŒ
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # 5. æ·»åŠ ç»†å¾®çš„èƒŒæ™¯å™ªå£°ï¼Œæ¨¡æ‹Ÿçº¸å¼ çº¹ç†
        paper_texture = np.random.normal(0, 8, result.shape)
        result += paper_texture

        return np.clip(result, 0, 255).astype(np.uint8)

    def local_blur(self, image: np.ndarray,
                   num_patches_range: tuple = (3, 8),
                   patch_size_range: tuple = (20, 60)) -> np.ndarray:
        """Apply blur to random local patches to simulate partial degradation"""
        h, w = image.shape[:2]
        result = image.copy()

        num_patches = random.randint(num_patches_range[0], num_patches_range[1])

        for _ in range(num_patches):
            # Random patch location and size
            patch_size = random.randint(patch_size_range[0], patch_size_range[1])
            x = random.randint(0, max(1, w - patch_size))
            y = random.randint(0, max(1, h - patch_size))

            # Extract patch
            patch = result[y:y+patch_size, x:x+patch_size].copy()

            # Apply strong blur to patch
            kernel_size = random.randrange(7, 15, 2)
            sigma = random.uniform(2.0, 4.0)
            blurred_patch = cv2.GaussianBlur(patch, (kernel_size, kernel_size), sigma)

            # Put back the blurred patch
            result[y:y+patch_size, x:x+patch_size] = blurred_patch

        return result

    def threshold_artifacts(self, image: np.ndarray,
                           threshold_range: tuple = (80, 120)) -> np.ndarray:
        """Apply threshold artifacts to simulate binary conversion effects"""
        # Convert to grayscale if color image
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            is_color = True
        else:
            gray = image.copy()
            is_color = False

        # Apply random threshold
        threshold_val = random.randint(threshold_range[0], threshold_range[1])
        _, binary = cv2.threshold(gray, threshold_val, 255, cv2.THRESH_BINARY)

        # Convert back to original format
        if is_color:
            # Convert back to BGR
            result = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
        else:
            result = binary

        return result

    def add_print_noise(self, image: np.ndarray,
                       noise_intensity: float = 0.15) -> np.ndarray:
        """æ·»åŠ çœŸå®çš„æ‰“å°çº¸å¼ å™ªç‚¹ï¼šç°è‰²æ–‘ç‚¹ã€çº¸å¼ çº¹ç†"""
        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # 1. ç”Ÿæˆçº¸å¼ çº¹ç†å™ªå£°ï¼ˆä¸»è¦æ˜¯ç°è‰²å€¼ï¼‰
        paper_noise = np.random.normal(0, noise_intensity * 20, (h, w))

        # 2. ç”Ÿæˆç»†å¾®çš„æ‰“å°æ–‘ç‚¹ï¼ˆä¸æ˜¯çº¯é»‘ç™½ï¼Œè€Œæ˜¯ç°è‰²ï¼‰
        spot_mask = np.random.random((h, w)) < (noise_intensity * 0.02)  # 2%çš„åƒç´ æœ‰æ–‘ç‚¹
        spot_values = np.random.uniform(180, 220, np.sum(spot_mask))  # ç°è‰²æ–‘ç‚¹ï¼Œä¸æ˜¯çº¯ç™½

        # 3. åº”ç”¨çº¸å¼ çº¹ç†
        if len(result.shape) == 3:
            for c in range(3):
                result[:, :, c] += paper_noise
        else:
            result += paper_noise

        # 4. æ·»åŠ ç°è‰²æ–‘ç‚¹
        if len(result.shape) == 3:
            # å¯¹äºå½©è‰²å›¾åƒï¼Œä¸ºæ¯ä¸ªé€šé“è®¾ç½®ç›¸åŒçš„ç°è‰²å€¼
            result[spot_mask, 0] = spot_values
            result[spot_mask, 1] = spot_values
            result[spot_mask, 2] = spot_values
        else:
            result[spot_mask] = spot_values

        # 5. ç¡®ä¿å€¼åœ¨åˆç†èŒƒå›´å†…
        result = np.clip(result, 0, 255).astype(np.uint8)

        return result

    def add_scan_lines(self, image: np.ndarray,
                      line_intensity: float = 0.1,
                      line_spacing: int = 3) -> np.ndarray:
        """æ·»åŠ æ‰«ææ¡çº¹æ•ˆæœ"""
        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # åˆ›å»ºæ°´å¹³æ‰«æçº¿æ•ˆæœ
        for y in range(0, h, line_spacing):
            # éšæœºå¼ºåº¦çš„æ‰«æçº¿
            line_strength = np.random.uniform(0.5, 1.0) * line_intensity * 30
            if len(result.shape) == 3:
                result[y, :] = result[y, :] * (1 - line_strength) + 240 * line_strength
            else:
                result[y, :] = result[y, :] * (1 - line_strength) + 240 * line_strength

        return np.clip(result, 0, 255).astype(np.uint8)

    def apply_composite_blur(self, image: np.ndarray, num_ops: int = 2) -> Dict[str, Any]:
        """Apply multiple blur operations in sequence for more realistic degradation"""
        available_ops = [
            'gaussian', 'motion', 'compression', 'print_scan',
            'localblur', 'threshold', 'print_noise', 'scan_lines'
        ]

        # Randomly select operations
        selected_ops = random.sample(available_ops, min(num_ops, len(available_ops)))

        result_image = image.copy()
        applied_operations = []

        for op in selected_ops:
            if op == 'gaussian':
                result_image = self.gaussian_blur(result_image)
            elif op == 'motion':
                result_image = self.motion_blur(result_image)
            elif op == 'compression':
                result_image = self.compression_artifacts(result_image)
            elif op == 'morphology':
                result_image = self.random_morphology(result_image)
            elif op == 'localblur':
                result_image = self.local_blur(result_image)
            elif op == 'threshold':
                result_image = self.threshold_artifacts(result_image)
            elif op == 'saltpepper':
                result_image = self.add_salt_pepper(result_image)

            applied_operations.append(op)

        return {
            'image': result_image,
            'blur_type': f"composite_{'_'.join(applied_operations)}"
        }

    def batch_generate_blur(self, 
                          input_dir: Union[str, Path],
                          output_dir: Union[str, Path],
                          num_variants_per_image: int = 5) -> None:
        
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        image_files = list(input_path.glob("*.png")) + list(input_path.glob("*.jpg"))
        
        for img_file in image_files:
            image = cv2.imread(str(img_file))
            if image is None:
                logging.warning(f"Could not load image: {img_file}")
                continue
                
            for i in range(num_variants_per_image):
                result = self.apply_random_blur(image)
                blur_image = result['image']
                blur_type = result['blur_type']

                output_file = output_path / f"{img_file.stem}_{blur_type}_{i}.png"
                cv2.imwrite(str(output_file), blur_image)

                logging.info(f"Generated blur variant: {output_file}")

    def generate_blur(self, input_path: Union[str, Path], output_path: Union[str, Path],
                     blur_type: str = None) -> None:
        """Generate a single blurred image"""
        # Load the image
        image = cv2.imread(str(input_path))
        if image is None:
            raise ValueError(f"Could not load image: {input_path}")

        # Apply blur effect
        if blur_type:
            result = self.apply_random_blur(image, blur_types=[blur_type])
        else:
            result = self.apply_random_blur(image)

        # Save result
        cv2.imwrite(str(output_path), result['image'])

    def generate_blur_with_difficulty(self, input_path: Union[str, Path],
                                    output_path: Union[str, Path],
                                    blur_type: str, difficulty_config: dict) -> None:
        """æ ¹æ®éš¾åº¦é…ç½®ç”Ÿæˆæ¨¡ç³Šå›¾åƒ"""
        # Load the image
        image = cv2.imread(str(input_path))
        if image is None:
            raise ValueError(f"Could not load image: {input_path}")

        # æ ¹æ®æ¨¡ç³Šç±»å‹å’Œéš¾åº¦é…ç½®åº”ç”¨æ•ˆæœ
        if blur_type == 'print_scan':
            result = self.print_scan_blur_with_config(image, difficulty_config)
        elif blur_type == 'print_noise':
            result = self.add_print_noise_with_config(image, difficulty_config)
        elif blur_type == 'scan_lines':
            result = self.add_scan_lines_with_config(image, difficulty_config)
        else:
            # é»˜è®¤ä½¿ç”¨åŸæœ‰æ–¹æ³•
            blur_result = self.apply_random_blur(image, blur_types=[blur_type])
            result = blur_result['image']

        # Save result
        cv2.imwrite(str(output_path), result)

    def print_scan_blur_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰“å°æ‰«ææ¨¡ç³Šæ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # æ ¹æ®éš¾åº¦è°ƒæ•´æ¨¡ç³Šå¼ºåº¦
        edge_blur_sigma = 1.5 * blur_strength

        # çº¿æ¡ç»†åŒ–å¤„ç†ï¼ˆæ›´é«˜éš¾åº¦->æ›´ç»†çš„çº¿ï¼‰
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        # å¤šå±‚æ¨¡ç³Šå åŠ 
        heavily_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma)
        lightly_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma * 0.3)

        # æ··åˆæ¨¡ç³Šæ•ˆæœ
        result = cv2.addWeighted(lightly_blurred, 0.4, heavily_blurred, 0.6, 0)

        # å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # æ·»åŠ è½»å¾®çš„çº¸å¼ çº¹ç†
        noise_intensity = 0.02 * blur_strength
        noise = np.random.normal(0, noise_intensity * 255, image.shape).astype(np.float32)
        result = np.clip(result + noise, 0, 255)

        return result.astype(np.uint8)

    def add_print_noise_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰“å°å™ªç‚¹æ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # é¦–å…ˆåº”ç”¨ç»†åŒ–å¤„ç†
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        result = image.copy().astype(np.float32)

        # æ ¹æ®éš¾åº¦è°ƒæ•´å™ªç‚¹å¯†åº¦å’Œå¼ºåº¦
        noise_density = 0.001 * (blur_strength ** 2)  # éš¾åº¦è¶Šé«˜å™ªç‚¹è¶Šå¤š
        noise_intensity = 30 * blur_strength  # éš¾åº¦è¶Šé«˜å™ªç‚¹è¶Šæ˜æ˜¾

        # ç”Ÿæˆå™ªç‚¹ä½ç½®
        h, w = result.shape[:2]
        num_spots = int(h * w * noise_density)

        if num_spots > 0:
            spot_coords = np.random.randint(0, [h, w], size=(num_spots, 2))

            # ç”Ÿæˆç°è‰²å™ªç‚¹ï¼ˆä¸æ˜¯çº¯é»‘ç™½ï¼‰
            spot_values = np.random.uniform(80, 180, num_spots).astype(np.float32)  # ç°è‰²èŒƒå›´

            # åˆ›å»ºæ©ç 
            spot_mask = (spot_coords[:, 0], spot_coords[:, 1])

            # åº”ç”¨å™ªç‚¹åˆ°æ‰€æœ‰é¢œè‰²é€šé“
            if len(result.shape) == 3:
                result[spot_mask[0], spot_mask[1], 0] = spot_values
                result[spot_mask[0], spot_mask[1], 1] = spot_values
                result[spot_mask[0], spot_mask[1], 2] = spot_values
            else:
                result[spot_mask] = spot_values

        # åº”ç”¨å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        return np.clip(result, 0, 255).astype(np.uint8)

    def add_scan_lines_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰«æçº¿æ¡æ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # é¦–å…ˆåº”ç”¨ç»†åŒ–å¤„ç†
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # æ ¹æ®éš¾åº¦è°ƒæ•´æ‰«æçº¿å¯†åº¦å’Œå¼ºåº¦
        line_spacing = max(2, int(8 - blur_strength * 2))  # éš¾åº¦è¶Šé«˜çº¿æ¡è¶Šå¯†
        line_opacity = 0.1 + 0.1 * blur_strength  # éš¾åº¦è¶Šé«˜çº¿æ¡è¶Šæ˜æ˜¾

        # æ·»åŠ æ°´å¹³æ‰«æçº¿
        for y in range(0, h, line_spacing):
            if len(result.shape) == 3:
                result[y, :, :] *= (1 - line_opacity)
            else:
                result[y, :] *= (1 - line_opacity)

        # æ·»åŠ è½»å¾®çš„å‚ç›´æ‰«æçº¿ï¼ˆå¯†åº¦æ›´ä½ï¼‰
        vertical_spacing = line_spacing * 3
        for x in range(0, w, vertical_spacing):
            if len(result.shape) == 3:
                result[:, x, :] *= (1 - line_opacity * 0.5)
            else:
                result[:, x] *= (1 - line_opacity * 0.5)

        # åº”ç”¨å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # æ·»åŠ è½»å¾®çš„æ•´ä½“æ¨¡ç³Š
        result = cv2.GaussianBlur(result.astype(np.uint8), (3, 3), 0.8 * blur_strength)

        return result.astype(np.uint8)

    def load_image(self, image_path: Union[str, Path]) -> np.ndarray:
        """Load an image from file"""
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        return image

    def line_discontinuity_blur(self, image: np.ndarray,
                               gap_density: float = 0.4,
                               gap_size_range: tuple = (2, 5)) -> np.ndarray:
        """
        Create dashed-line effects with many small gaps (not too disconnected)
        åˆ›å»ºè™šçº¿æ•ˆæœ - å°é—´éš™ä½†æ•°é‡å¤šï¼Œåƒè™šçº¿ä¸€æ ·
        """
        result = image.copy()
        h, w = result.shape[:2]

        # Convert to grayscale for line detection
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        # 1. åŸºäºHoughå˜æ¢çš„çº¿æ®µæ–­ç»­å¤„ç†
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=15,
                               minLineLength=8, maxLineGap=3)

        gaps_created = 0
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                line_length = np.sqrt((x2-x1)**2 + (y2-y1)**2)

                # Process lines to create dashed-line effect
                if line_length > 10:  # Process shorter lines too
                    # åˆ›å»ºè™šçº¿æ•ˆæœ - æ›´å¤šä½†æ›´å°çš„é—´éš™
                    num_gaps = max(3, int(line_length * gap_density / 6))  # More gaps

                    for _ in range(num_gaps):
                        # Random gap position along the line
                        t = random.uniform(0.1, 0.9)
                        gap_center_x = int(x1 + t * (x2 - x1))
                        gap_center_y = int(y1 + t * (y2 - y1))

                        # å°é—´éš™å°ºå¯¸ - åƒè™šçº¿çš„çŸ­åˆ’
                        gap_size = random.randint(gap_size_range[0], gap_size_range[1])

                        # Create small circular gaps for dashed effect
                        cv2.circle(result, (gap_center_x, gap_center_y), gap_size//2,
                                 (255, 255, 255) if len(result.shape) == 3 else 255, -1)
                        gaps_created += 1

        # 2. åŸºäºåƒç´ å¯†åº¦çš„æ™ºèƒ½é—´éš™ç”Ÿæˆ
        # æ‰¾åˆ°æ‰€æœ‰çº¿æ¡åƒç´ 
        line_mask = gray < 180  # æ›´å®½æ¾çš„é˜ˆå€¼ä»¥æ•è·æ›´å¤šçº¿æ¡
        line_coords = np.where(line_mask)

        if len(line_coords[0]) > 0:
            # è®¡ç®—è™šçº¿æ•ˆæœçš„å°é—´éš™
            num_pixel_gaps = int(len(line_coords[0]) * gap_density * 0.008)  # æ›´å¤šå°é—´éš™

            if num_pixel_gaps > 0:
                # éšæœºé€‰æ‹©çº¿æ¡åƒç´ ä½ç½®åˆ›å»ºå°é—´éš™
                indices = random.sample(range(len(line_coords[0])),
                                      min(num_pixel_gaps, len(line_coords[0])))

                for idx in indices:
                    gap_y, gap_x = line_coords[0][idx], line_coords[1][idx]
                    gap_size = random.randint(gap_size_range[0], gap_size_range[1])

                    # åªåˆ›å»ºå°åœ†å½¢é—´éš™ï¼Œä¿æŒè™šçº¿æ•ˆæœç®€å•ä¸€è‡´
                    cv2.circle(result, (gap_x, gap_y), gap_size//2,
                             (255, 255, 255) if len(result.shape) == 3 else 255, -1)
                    gaps_created += 1

        # 3. è½»å¾®çš„çº¿æ¡è¾¹ç¼˜å¤„ç†ï¼Œä¿æŒè™šçº¿æ•ˆæœè‡ªç„¶
        # å‡å°‘è¾¹ç¼˜è…èš€å¼ºåº¦ï¼Œé¿å…è¿‡åº¦æ–­å¼€
        if len(result.shape) == 3:
            result_gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
        else:
            result_gray = result.copy()

        # éå¸¸è½»å¾®çš„è…èš€ï¼Œåªæ˜¯ç¨å¾®è½¯åŒ–è¾¹ç¼˜
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        eroded = cv2.erode(result_gray, kernel, iterations=1)

        # éå¸¸è½»å¾®æ··åˆï¼Œä¿æŒç»å¤§éƒ¨åˆ†åŸå›¾ç»“æ„
        if len(result.shape) == 3:
            eroded_3ch = cv2.cvtColor(eroded, cv2.COLOR_GRAY2BGR)
            result = cv2.addWeighted(result, 0.95, eroded_3ch, 0.05, 0)  # æè½»çš„æ··åˆ
        else:
            result = cv2.addWeighted(result, 0.95, eroded, 0.05, 0)

        # print(f"  è™šçº¿æ•ˆæœå¤„ç†: åˆ›å»ºäº† {gaps_created} ä¸ªå°é—´éš™")
        return result

    def regional_line_thinning(self, image: np.ndarray,
                             num_regions: int = 4,
                             region_size_range: tuple = (80, 200),
                             thinning_strength: float = 1.2,
                             color_variation: bool = True) -> np.ndarray:
        """
        Apply aggressive line thinning with color variation to specific regions
        å¯¹ç‰¹å®šåŒºåŸŸè¿›è¡Œå¼ºåŒ–çº¿æ¡ç»†åŒ–å¤„ç† - åŒ…å«çº¿æ¡é¢œè‰²å˜åŒ–
        """
        result = image.copy()
        h, w = result.shape[:2]

        # å¦‚æœnum_regionsä¸º0ï¼Œç›´æ¥è¿”å›åŸå›¾ï¼ˆè·³è¿‡è¯¥æ•ˆæœï¼‰
        if num_regions == 0:
            return result

        for i in range(num_regions):
            # Random region location and size - æ›´å¤§çš„åŒºåŸŸä»¥ç¡®ä¿æ•ˆæœæ˜æ˜¾
            region_w = random.randint(region_size_range[0], region_size_range[1])
            region_h = random.randint(region_size_range[0], region_size_range[1])
            region_x = random.randint(0, max(1, w - region_w))
            region_y = random.randint(0, max(1, h - region_h))

            # Extract region
            region = result[region_y:region_y+region_h, region_x:region_x+region_w].copy()

            # å¤šé‡ç»†åŒ–å¤„ç†ä»¥è·å¾—æ›´æ˜æ˜¾çš„æ•ˆæœ
            processed_region = region.copy()

            # 1. æ¸©å’Œè…èš€æ“ä½œ - è½»å¾®è®©çº¿æ¡å˜ç»†
            erosion_kernel_size = max(1, int(2 * thinning_strength))  # å‡å°‘kernelå¤§å°
            erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,
                                                     (erosion_kernel_size, erosion_kernel_size))
            eroded_region = cv2.erode(processed_region, erosion_kernel, iterations=1)  # å‡å°‘è¿­ä»£æ¬¡æ•°

            # 2. è†¨èƒ€æ¢å¤å¤§éƒ¨åˆ†ç»“æ„
            processed_region = cv2.dilate(eroded_region, erosion_kernel, iterations=1)

            # 3. é¢å¤–çš„å±€éƒ¨ç»†åŒ– - éšæœºç§»é™¤ä¸€äº›åƒç´ è®©çº¿æ¡æ›´ä¸è¿ç»­
            if len(processed_region.shape) == 3:
                gray_region = cv2.cvtColor(processed_region, cv2.COLOR_BGR2GRAY)
            else:
                gray_region = processed_region.copy()

            # æ‰¾åˆ°çº¿æ¡åƒç´ å¹¶éšæœºç§»é™¤ä¸€äº›
            line_pixels = np.where(gray_region < 200)
            if len(line_pixels[0]) > 0:
                # éšæœºç§»é™¤å°‘é‡çº¿æ¡åƒç´  - é™ä½æ¯”ä¾‹
                num_pixels_to_remove = int(len(line_pixels[0]) * 0.05 * thinning_strength)
                if num_pixels_to_remove > 0:
                    indices_to_remove = random.sample(range(len(line_pixels[0])),
                                                     min(num_pixels_to_remove, len(line_pixels[0])))

                    for idx in indices_to_remove:
                        y_pos, x_pos = line_pixels[0][idx], line_pixels[1][idx]
                        # åˆ›å»ºå°çš„ç™½è‰²æ–‘ç‚¹
                        if len(processed_region.shape) == 3:
                            processed_region[y_pos:y_pos+2, x_pos:x_pos+2] = [255, 255, 255]
                        else:
                            processed_region[y_pos:y_pos+2, x_pos:x_pos+2] = 255

            # 4. æ·»åŠ çº¿æ¡é¢œè‰²å˜åŒ–æ•ˆæœ
            if color_variation and len(processed_region.shape) == 3:
                # æ‰¾åˆ°çº¿æ¡åŒºåŸŸï¼ˆæš—åƒç´ ï¼‰
                if len(processed_region.shape) == 3:
                    gray_region = cv2.cvtColor(processed_region, cv2.COLOR_BGR2GRAY)
                else:
                    gray_region = processed_region.copy()

                line_mask = gray_region < 200

                if np.any(line_mask):
                    # ç”Ÿæˆéšæœºé¢œè‰²å˜åŒ– - æ¨¡æ‹Ÿå¢¨æ°´é¢œè‰²ä¸å‡æˆ–æ‰«æè‰²å·®
                    color_shift = random.choice([
                        [random.randint(-15, 15), random.randint(-15, 15), random.randint(-15, 15)],  # æ•´ä½“è‰²å
                        [random.randint(-25, 0), 0, 0],      # çº¢è‰²å‡å°‘ï¼ˆå¢¨æ°´è¤ªè‰²ï¼‰
                        [0, random.randint(-25, 0), 0],      # ç»¿è‰²å‡å°‘
                        [0, 0, random.randint(-25, 0)],      # è“è‰²å‡å°‘
                        [random.randint(-20, -5), random.randint(-20, -5), random.randint(-20, -5)], # æ•´ä½“å˜æš—
                    ])

                    # åº”ç”¨é¢œè‰²å˜åŒ–åˆ°çº¿æ¡åŒºåŸŸ
                    processed_region = processed_region.astype(np.float32)
                    for c in range(3):
                        channel = processed_region[:, :, c]
                        channel[line_mask] += color_shift[c]
                    processed_region = np.clip(processed_region, 0, 255).astype(np.uint8)

            # 5. æ·»åŠ è½»å¾®çš„é«˜æ–¯æ¨¡ç³Šè®©æ•ˆæœçœ‹èµ·æ¥æ›´è‡ªç„¶
            processed_region = cv2.GaussianBlur(processed_region, (3, 3), 0.8)

            # 6. å¼ºåŒ–æ··åˆ - è®©ç»†åŒ–æ•ˆæœæ›´æ˜æ˜¾
            alpha = 0.7 + 0.2 * min(thinning_strength, 1.0)  # æ›´å¼ºçš„æ··åˆæ¯”ä¾‹
            final_region = cv2.addWeighted(region, 1-alpha, processed_region, alpha, 0)

            # Put back the heavily thinned region with color variation
            result[region_y:region_y+region_h, region_x:region_x+region_w] = final_region

            # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼ˆå®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦ç§»é™¤ï¼‰
            # print(f"  åº”ç”¨åŒºåŸŸç»†åŒ–: åŒºåŸŸ{i+1} ä½ç½®({region_x},{region_y}) å¤§å°({region_w}x{region_h})")

        return result

    def spectral_line_degradation(self, image: np.ndarray,
                                x_range: tuple = None,
                                degradation_type: str = 'both') -> np.ndarray:
        """
        Apply heavy degradation effects specifically to spectral line ranges
        ä¸“é—¨é’ˆå¯¹å…‰è°±çº¿çš„ç‰¹å®šxè½´èŒƒå›´è¿›è¡Œå¼ºåŒ–é€€åŒ–å¤„ç† - æ›´æ˜æ˜¾çš„æ¨¡ç³Šæ•ˆæœ
        """
        if x_range is None:
            # Select a more prominent range
            w = image.shape[1]
            range_width = int(w * random.uniform(0.3, 0.5))  # 30-50% of image width
            x_start = random.randint(int(w * 0.1), int(w * 0.5))  # More flexible positioning
            x_range = (x_start, min(x_start + range_width, w))

        result = image.copy()
        x_start, x_end = x_range

        # Extract the region of interest
        roi = result[:, x_start:x_end].copy()

        # 1. æ¸©å’Œçº¿æ¡ç»†åŒ– (å‡å¼±å¼ºåº¦)
        if degradation_type in ['thinning', 'both']:
            # Reduced erosion for gentler thinning
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))  # æ›´å°çš„kernel
            roi = cv2.erode(roi, kernel, iterations=1)  # å‡å°‘è¿­ä»£æ¬¡æ•° 2â†’1

            # Add mild blur
            roi = cv2.GaussianBlur(roi, (3, 3), 0.8)  # å‡å°‘sigma 1.2â†’0.8

        # 2. æ¸©å’Œæ–­ç»­æ•ˆæœ (å‡å¼±å¼ºåº¦)
        if degradation_type in ['discontinuity', 'both']:
            # Gentler discontinuity for spectral region
            gap_density = 0.15  # é™ä½å¯†åº¦ 0.3â†’0.15
            roi = self.line_discontinuity_blur(roi, gap_density=gap_density,
                                             gap_size_range=(1, 4))  # å‡å°é—´éš™ (3,8)â†’(1,4)

        # 3. è½»å¾®æ¨¡ç³Šå¤„ç† (å‡å¼±å¼ºåº¦)
        # Apply gentler motion blur in horizontal direction
        motion_kernel = np.zeros((1, 5))  # å‡å°kernel 7â†’5
        motion_kernel[0, :] = 1/5
        roi = cv2.filter2D(roi, -1, motion_kernel)

        # 4. è½»å¾®é™ä½å¯¹æ¯”åº¦ (å‡å¼±å¼ºåº¦)
        if len(roi.shape) == 3:
            roi = roi.astype(np.float32)
            roi = roi * 0.9 + 255 * 0.1  # å‡å°‘å¯¹æ¯”åº¦é™ä½ 0.8â†’0.9
            roi = np.clip(roi, 0, 255).astype(np.uint8)

        # Put back the heavily processed region
        result[:, x_start:x_end] = roi

        return result

    def background_color_variation(self, image: np.ndarray,
                                 variation_type: str = 'random',
                                 intensity: float = 0.3) -> np.ndarray:
        """
        Apply background color variation to simulate different lighting/printing conditions
        åº”ç”¨èƒŒæ™¯é¢œè‰²å˜åŒ– - æ¨¡æ‹Ÿä¸åŒçš„å…‰çº¿æˆ–æ‰“å°æ¡ä»¶

        Args:
            variation_type: 'global' (æ•´ä½“å˜åŒ–), 'local' (å±€éƒ¨å˜åŒ–), 'random' (éšæœºé€‰æ‹©)
            intensity: å˜åŒ–å¼ºåº¦ 0.0-1.0
        """
        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        if variation_type == 'random':
            variation_type = random.choice(['global', 'local', 'gradient'])

        if variation_type == 'global':
            # æ•´ä½“é¢œè‰²åç§» - æ¨¡æ‹Ÿæ•´ä½“å…‰çº¿å˜åŒ–
            if len(result.shape) == 3:
                # ç”Ÿæˆæ•´ä½“è‰²å
                color_shift = np.array([
                    random.uniform(-30*intensity, 30*intensity),  # R
                    random.uniform(-25*intensity, 25*intensity),  # G
                    random.uniform(-35*intensity, 35*intensity)   # B
                ])

                # åº”ç”¨åˆ°èƒŒæ™¯åŒºåŸŸï¼ˆäº®åƒç´ ï¼‰
                for c in range(3):
                    channel = result[:, :, c]
                    bg_mask = channel > 200  # èƒŒæ™¯åƒç´ 
                    channel[bg_mask] += color_shift[c]

            else:
                # ç°åº¦å›¾çš„äº®åº¦å˜åŒ–
                brightness_shift = random.uniform(-20*intensity, 20*intensity)
                bg_mask = result > 200
                result[bg_mask] += brightness_shift

        elif variation_type == 'local':
            # å±€éƒ¨é¢œè‰²å˜åŒ– - æ¨¡æ‹Ÿæ‰«ææ—¶çš„ä¸å‡åŒ€å…‰ç…§
            num_patches = random.randint(3, 8)

            for _ in range(num_patches):
                # éšæœºè¡¥ä¸ä½ç½®å’Œå¤§å°
                patch_w = random.randint(int(w*0.2), int(w*0.6))
                patch_h = random.randint(int(h*0.2), int(h*0.6))
                patch_x = random.randint(0, max(1, w - patch_w))
                patch_y = random.randint(0, max(1, h - patch_h))

                # åˆ›å»ºæ¸å˜é®ç½©è®©å˜åŒ–æ›´è‡ªç„¶
                mask = np.zeros((patch_h, patch_w), dtype=np.float32)
                center_x, center_y = patch_w//2, patch_h//2
                max_dist = min(patch_w, patch_h) // 2

                for y in range(patch_h):
                    for x in range(patch_w):
                        dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                        mask[y, x] = max(0, 1 - dist/max_dist)

                if len(result.shape) == 3:
                    # å½©è‰²å›¾çš„å±€éƒ¨è‰²å
                    local_color_shift = np.array([
                        random.uniform(-25*intensity, 25*intensity),
                        random.uniform(-20*intensity, 20*intensity),
                        random.uniform(-30*intensity, 30*intensity)
                    ])

                    for c in range(3):
                        patch = result[patch_y:patch_y+patch_h, patch_x:patch_x+patch_w, c]
                        bg_mask = patch > 180  # èƒŒæ™¯åŒºåŸŸ
                        patch[bg_mask] += mask[bg_mask] * local_color_shift[c]
                else:
                    # ç°åº¦å›¾çš„å±€éƒ¨äº®åº¦å˜åŒ–
                    brightness_shift = random.uniform(-15*intensity, 15*intensity)
                    patch = result[patch_y:patch_y+patch_h, patch_x:patch_x+patch_w]
                    bg_mask = patch > 180
                    patch[bg_mask] += mask[bg_mask] * brightness_shift

        elif variation_type == 'gradient':
            # æ¸å˜å˜åŒ– - æ¨¡æ‹Ÿæ‰«æä»ªå…‰æºä¸å‡
            direction = random.choice(['horizontal', 'vertical', 'diagonal'])

            if direction == 'horizontal':
                gradient = np.linspace(-20*intensity, 20*intensity, w)
                gradient_map = np.tile(gradient, (h, 1))
            elif direction == 'vertical':
                gradient = np.linspace(-20*intensity, 20*intensity, h)
                gradient_map = np.tile(gradient.reshape(-1, 1), (1, w))
            else:  # diagonal
                x_grad = np.linspace(-15*intensity, 15*intensity, w)
                y_grad = np.linspace(-15*intensity, 15*intensity, h)
                gradient_map = np.add.outer(y_grad, x_grad) / 2

            if len(result.shape) == 3:
                # éšæœºé€‰æ‹©ä¸»è¦å½±å“çš„é¢œè‰²é€šé“
                primary_channel = random.randint(0, 2)
                for c in range(3):
                    channel = result[:, :, c]
                    bg_mask = channel > 180
                    if c == primary_channel:
                        channel[bg_mask] += gradient_map[bg_mask]
                    else:
                        channel[bg_mask] += gradient_map[bg_mask] * 0.3
            else:
                bg_mask = result > 180
                result[bg_mask] += gradient_map[bg_mask]

        # ç¡®ä¿å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
        result = np.clip(result, 0, 255).astype(np.uint8)
        return result

    def apply_base_degradation(self, image: np.ndarray) -> tuple:
        """
        Apply base degradation effects that should be present in every image:
        - Background color variation (lighting/printing conditions)
        - Line thickness inconsistency (regional_thinning with color variation)
        - Line discontinuity (dashed line effect)
        - Print noise artifacts
        å¯¹æ¯å¼ å›¾ç‰‡éƒ½åº”ç”¨çš„åŸºç¡€é€€åŒ–æ•ˆæœç»„åˆ - ä½¿ç”¨é…ç½®åŒ–çš„å¼ºåº¦èŒƒå›´

        Returns:
            tuple: (degraded_image, effects_log)
        """
        result = image.copy()
        config = self.difficulty_config
        applied_effects = []

        try:
            # 1. åº•è‰²å˜åŒ– (æ¨¡æ‹Ÿå…‰çº¿/æ‰“å°æ¡ä»¶å·®å¼‚) - ä½¿ç”¨é…ç½®åŒ–å¼ºåº¦
            bg_intensity = get_random_value_in_range(config['background_variation']['intensity'])
            effect_log = f"background_variation(intensity={bg_intensity:.3f})"
            applied_effects.append(effect_log)
            result = self.background_color_variation(result, intensity=bg_intensity)

            # 2. çº¿æ®µç²—ç»†ä¸ä¸€è‡´ + é¢œè‰²å˜åŒ– - ä½¿ç”¨é…ç½®åŒ–å‚æ•°
            thinning_config = config['regional_thinning']
            num_regions = get_random_value_in_range(thinning_config['num_regions'], is_int=True)
            thinning_strength = get_random_value_in_range(thinning_config['thinning_strength'])
            effect_log = f"regional_thinning(regions={num_regions}, strength={thinning_strength:.3f}, color_var={thinning_config['color_variation']})"
            applied_effects.append(effect_log)
            result = self.regional_line_thinning(result,
                                               num_regions=num_regions,
                                               thinning_strength=thinning_strength,
                                               color_variation=thinning_config['color_variation'])

            # 3. çº¿æ®µæ–­æ–­ç»­ç»­ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°
            discontinuity_config = config['line_discontinuity']
            gap_density = get_random_value_in_range(discontinuity_config['gap_density'])
            gap_size_range = discontinuity_config['gap_size_range'][0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªèŒƒå›´

            # ç¡®ä¿gap_size_rangeæœ‰æ•ˆ
            if gap_size_range[0] > gap_size_range[1]:
                gap_size_range = (gap_size_range[1], gap_size_range[0])

            effect_log = f"line_discontinuity(density={gap_density:.3f}, gap_range={gap_size_range})"
            applied_effects.append(effect_log)
            result = self.line_discontinuity_blur(result,
                                                gap_density=gap_density,
                                                gap_size_range=gap_size_range)

            # 4. æ‰“å°å™ªç‚¹æ•ˆæœ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°
            noise_intensity = get_random_value_in_range(config['print_noise']['noise_intensity'])
            effect_log = f"print_noise(intensity={noise_intensity:.3f})"
            applied_effects.append(effect_log)
            result = self.add_print_noise(result, noise_intensity=noise_intensity)

        except Exception as e:
            print(f"ğŸš¨ BASE DEGRADATION ERROR:")
            print(f"   Difficulty: {self.difficulty}")
            print(f"   Applied effects so far: {applied_effects}")
            print(f"   Error: {str(e)}")
            print(f"   Config: {config}")
            raise e

        return result, applied_effects

    def apply_random_additional_blur(self, image: np.ndarray, num_effects: int = None) -> Dict[str, Any]:
        """
        Apply random additional blur effects on top of base degradation using difficulty-based parameters
        åœ¨åŸºç¡€é€€åŒ–çš„åŸºç¡€ä¸Šéšæœºæ·»åŠ é¢å¤–çš„æ¨¡ç³Šæ•ˆæœï¼ˆä½¿ç”¨é…ç½®åŒ–çš„éš¾åº¦å‚æ•°ï¼‰
        """
        config = self.difficulty_config
        if num_effects is None:
            num_effects = get_random_value_in_range(config['additional_effects_count'], is_int=True)

        # å¯é€‰çš„é¢å¤–æ¨¡ç³Šæ•ˆæœï¼ˆä¸åŒ…æ‹¬åŸºç¡€å¿…åŠ æ•ˆæœï¼‰
        additional_effects = [
            'gaussian', 'motion', 'compression', 'scan', 'lowres',
            'text', 'lines', 'print_scan', 'localblur', 'threshold',
            'scan_lines', 'spectral_degradation'
        ]

        # éšæœºé€‰æ‹©effects
        selected_effects = random.sample(additional_effects,
                                       min(num_effects, len(additional_effects)))

        result = image.copy()
        applied_effects = []
        effect_details = []

        print(f"ğŸ”§ ADDITIONAL BLUR: {self.difficulty} difficulty, applying {num_effects} effects: {selected_effects}")

        for effect in selected_effects:
            try:
                if effect == 'gaussian':
                    # ä½¿ç”¨é…ç½®åŒ–çš„é«˜æ–¯æ¨¡ç³Šå‚æ•°
                    gaussian_config = config['gaussian_blur']
                    kernel_range = get_random_range_in_ranges(gaussian_config['kernel_size_range'], is_int=True)
                    sigma_range = get_random_range_in_ranges(gaussian_config['sigma_range'])
                    effect_details.append(f"gaussian(kernel={kernel_range}, sigma={sigma_range})")
                    result = self.gaussian_blur(result, kernel_size_range=kernel_range, sigma_range=sigma_range)
                elif effect == 'motion':
                    # ä½¿ç”¨é…ç½®åŒ–çš„è¿åŠ¨æ¨¡ç³Šå‚æ•°
                    motion_config = config['motion_blur']
                    kernel_range = get_random_range_in_ranges(motion_config['kernel_size_range'], is_int=True)
                    effect_details.append(f"motion(kernel={kernel_range})")
                    result = self.motion_blur(result, kernel_size_range=kernel_range)
                elif effect == 'compression':
                    # ä½¿ç”¨é…ç½®åŒ–çš„å‹ç¼©å‚æ•°
                    comp_config = config['compression']
                    quality_range = get_random_range_in_ranges(comp_config['quality_range'], is_int=True)
                    effect_details.append(f"compression(quality={quality_range})")
                    result = self.compression_artifacts(result, quality_range=quality_range)
                elif effect == 'scan':
                    effect_details.append("print_scan_simulation")
                    result = self.print_scan_simulation(result, enable_geometric_distortion=False)
                elif effect == 'lowres':
                    # ä½¿ç”¨é…ç½®åŒ–çš„ä½åˆ†è¾¨ç‡å‚æ•°
                    lowres_config = config['lowres']
                    factor_range = get_random_range_in_ranges(lowres_config['downscale_factor_range'], is_int=True)
                    effect_details.append(f"lowres(factor={factor_range})")
                    result = self.low_resolution_upscale(result, downscale_factor_range=factor_range)
                elif effect == 'text':
                    # ä½¿ç”¨é…ç½®åŒ–çš„æ–‡æœ¬å¹²æ‰°å‚æ•° (å›ºå®šèŒƒå›´)
                    effect_details.append("text_interference(1-3)")
                    result = self.add_text_interference(result, num_texts_range=(1, 3))
                elif effect == 'lines':
                    # ä½¿ç”¨é…ç½®åŒ–çš„çº¿æ¡å¹²æ‰°å‚æ•° (å›ºå®šèŒƒå›´)
                    effect_details.append("line_interference(1-3)")
                    result = self.add_line_interference(result, num_lines_range=(1, 3))
                elif effect == 'print_scan':
                    effect_details.append("print_scan_blur")
                    result = self.print_scan_blur(result)
                elif effect == 'localblur':
                    effect_details.append("local_blur")
                    result = self.local_blur(result)
                elif effect == 'threshold':
                    # ä½¿ç”¨é…ç½®åŒ–çš„é˜ˆå€¼å‚æ•°
                    threshold_config = config['threshold']
                    threshold_range = get_random_range_in_ranges(threshold_config['threshold_range'], is_int=True)
                    effect_details.append(f"threshold(range={threshold_range})")
                    result = self.threshold_artifacts(result, threshold_range=threshold_range)
                elif effect == 'scan_lines':
                    effect_details.append("scan_lines")
                    result = self.add_scan_lines(result)
                elif effect == 'spectral_degradation':
                    # ä½¿ç”¨é…ç½®åŒ–çš„å…‰è°±é€€åŒ–å‚æ•°
                    spectral_config = config['spectral_degradation']
                    degradation_strength = get_random_value_in_range(spectral_config['degradation_strength'])
                    range_percentage = get_random_value_in_range(spectral_config['range_percentage'])
                    effect_details.append(f"spectral_degradation(strength={degradation_strength:.3f}, range={range_percentage:.3f})")
                    result = self.spectral_line_degradation(result)

                applied_effects.append(effect)
            except Exception as e:
                print(f"ğŸš¨ ADDITIONAL BLUR ERROR in {effect}:")
                print(f"   Difficulty: {self.difficulty}")
                print(f"   Applied effects so far: {effect_details}")
                print(f"   Current effect: {effect}")
                print(f"   Error: {str(e)}")
                raise e

        return {
            'image': result,
            'blur_type': f"base_plus_{'_'.join(applied_effects)}",
            'additional_effects': applied_effects,
            'additional_effects_details': effect_details,
            'num_additional': len(applied_effects)
        }