import cv2
import numpy as np
import albumentations as A
from pathlib import Path
from typing import Union, List, Dict, Any
import random
import logging
from .difficulty_config import get_difficulty_config, get_random_value_in_range, get_random_range_in_ranges

class BlurGenerator:
    def __init__(self, random_seed: int = 42, difficulty: str = 'easy'):
        self.random_seed = random_seed
        self.difficulty = difficulty
        self.difficulty_config = get_difficulty_config(difficulty)
        random.seed(random_seed)
        np.random.seed(random_seed)
        
    def gaussian_blur(self, image: np.ndarray, kernel_size_range: tuple = (5, 15),
                     sigma_range: tuple = (1.0, 3.0),
                     kernel_size: int = None) -> np.ndarray:
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæä¾›äº†å•ä¸ªkernel_sizeï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä»èŒƒå›´ä¸­éšæœºé€‰æ‹©
        if kernel_size is not None:
            selected_kernel_size = kernel_size
        else:
            # ç¡®ä¿kernel_sizeä¸ºå¥‡æ•°ä¸”åœ¨æœ‰æ•ˆèŒƒå›´å†…
            min_size = kernel_size_range[0]
            max_size = kernel_size_range[1]

            # ç¡®ä¿æœ€å°å€¼ä¸ºå¥‡æ•°
            if min_size % 2 == 0:
                min_size += 1
            # ç¡®ä¿æœ€å¤§å€¼ä¸ºå¥‡æ•°
            if max_size % 2 == 0:
                max_size -= 1

            # ç¡®ä¿æœ‰æ•ˆèŒƒå›´
            if min_size > max_size:
                min_size = max_size

            # ç”Ÿæˆå¥‡æ•°kernelå¤§å°
            if min_size == max_size:
                selected_kernel_size = min_size
            else:
                selected_kernel_size = random.randrange(min_size, max_size + 1, 2)

        # ç¡®ä¿selected_kernel_sizeæ˜¯å¥‡æ•°
        if selected_kernel_size % 2 == 0:
            selected_kernel_size += 1

        sigma = random.uniform(sigma_range[0], sigma_range[1])
        return cv2.GaussianBlur(image, (selected_kernel_size, selected_kernel_size), sigma)
    
    def motion_blur(self, image: np.ndarray, kernel_size_range: tuple = (5, 20),
                   angle_range: tuple = (0, 180),
                   kernel_size: int = None) -> np.ndarray:
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæä¾›äº†å•ä¸ªkernel_sizeï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä»èŒƒå›´ä¸­éšæœºé€‰æ‹©
        if kernel_size is not None:
            selected_kernel_size = kernel_size
        else:
            selected_kernel_size = random.randint(kernel_size_range[0], kernel_size_range[1])
        angle = random.randint(angle_range[0], angle_range[1])

        kernel = np.zeros((selected_kernel_size, selected_kernel_size))
        kernel[int((selected_kernel_size-1)/2), :] = np.ones(selected_kernel_size)
        kernel = kernel / selected_kernel_size

        angle_rad = np.deg2rad(angle)
        rotation_matrix = cv2.getRotationMatrix2D((selected_kernel_size//2, selected_kernel_size//2), angle, 1)
        kernel = cv2.warpAffine(kernel, rotation_matrix, (selected_kernel_size, selected_kernel_size))
        
        return cv2.filter2D(image, -1, kernel)
    
    def compression_artifacts(self, image: np.ndarray, quality_range: tuple = (30, 70)) -> np.ndarray:
        quality = random.randint(quality_range[0], quality_range[1])
        
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]
        result, encoded_img = cv2.imencode('.jpg', image, encode_param)
        decoded_img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)
        
        return decoded_img
    
    def print_scan_simulation(self, image: np.ndarray,
                             enable_geometric_distortion: bool = False,
                             noise_intensity: float = 0.3,
                             brightness_contrast_intensity: float = 0.1) -> np.ndarray:
        """
        æ‰“å°æ‰«ææ¨¡æ‹Ÿæ•ˆæœ - å¯é…ç½®å¼ºåº¦å‚æ•°

        Args:
            noise_intensity: å™ªå£°å¼ºåº¦ (0-1)
            brightness_contrast_intensity: äº®åº¦å¯¹æ¯”åº¦å˜åŒ–å¼ºåº¦ (0-1)
        """
        transforms = []

        # å¯é€‰çš„å‡ ä½•å˜å½¢ï¼ˆæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ï¼‰
        if enable_geometric_distortion:
            transforms.append(A.Affine(
                translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},
                scale=(0.9, 1.1),
                rotate=(-2, 2),
                p=0.8
            ))

        # å¯é…ç½®å¼ºåº¦çš„æ•ˆæœ
        # å™ªå£°å¼ºåº¦: æ ¹æ®difficultyè°ƒæ•´
        noise_var_max = 10.0 + 40.0 * noise_intensity  # 10-50çš„èŒƒå›´
        transforms.append(A.GaussNoise(
            var_limit=(5.0, noise_var_max),
            mean=0,
            p=0.7
        ))

        # äº®åº¦å¯¹æ¯”åº¦å˜åŒ–: æ ¹æ®difficultyè°ƒæ•´
        bc_limit = 0.05 + 0.15 * brightness_contrast_intensity  # 0.05-0.2çš„èŒƒå›´
        transforms.append(A.RandomBrightnessContrast(
            brightness_limit=bc_limit,
            contrast_limit=bc_limit,
            p=0.8
        ))

        transform = A.Compose(transforms)
        augmented = transform(image=image)
        return augmented['image']
    
    def low_resolution_upscale(self, image: np.ndarray, 
                              downscale_factor_range: tuple = (4, 8)) -> np.ndarray:
        h, w = image.shape[:2]
        factor = random.randint(downscale_factor_range[0], downscale_factor_range[1])
        
        low_res = cv2.resize(image, (w//factor, h//factor), interpolation=cv2.INTER_AREA)
        upscaled = cv2.resize(low_res, (w, h), interpolation=cv2.INTER_CUBIC)
        
        return upscaled
    
    def add_text_interference(self, image: np.ndarray, 
                            num_texts_range: tuple = (3, 8)) -> np.ndarray:
        h, w = image.shape[:2]
        result = image.copy()
        
        num_texts = random.randint(num_texts_range[0], num_texts_range[1])
        
        for _ in range(num_texts):
            text = random.choice(['A', 'B', 'C', '1', '2', '3', 'X', 'Y'])
            font_scale = random.uniform(0.3, 0.8)
            thickness = random.randint(1, 2)
            
            x = random.randint(50, w-50)
            y = random.randint(50, h-50)
            
            cv2.putText(result, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 
                       font_scale, (128, 128, 128), thickness)
        
        return result
    
    def add_line_interference(self, image: np.ndarray, 
                            num_lines_range: tuple = (2, 6)) -> np.ndarray:
        h, w = image.shape[:2]
        result = image.copy()
        
        num_lines = random.randint(num_lines_range[0], num_lines_range[1])
        
        for _ in range(num_lines):
            pt1 = (random.randint(0, w), random.randint(0, h))
            pt2 = (random.randint(0, w), random.randint(0, h))
            thickness = random.randint(1, 2)
            
            cv2.line(result, pt1, pt2, (200, 200, 200), thickness)
        
        return result
    
    def apply_random_blur(self, image: np.ndarray, blur_types: List[str] = None) -> Dict[str, Any]:
        if blur_types is None:
            blur_types = [
                'gaussian', 'motion', 'compression', 'scan', 'lowres',
                'text', 'lines',
                'print_scan', 'localblur', 'threshold', 'print_noise',
                'scan_lines', 'composite',
                'line_discontinuity', 'regional_thinning', 'spectral_degradation'
            ]

        blur_type = random.choice(blur_types)
        result_image = image.copy()

        if blur_type == 'gaussian':
            result_image = self.gaussian_blur(result_image)
        elif blur_type == 'motion':
            result_image = self.motion_blur(result_image)
        elif blur_type == 'compression':
            result_image = self.compression_artifacts(result_image)
        elif blur_type == 'scan':
            result_image = self.print_scan_simulation(result_image, enable_geometric_distortion=False)
        elif blur_type == 'lowres':
            result_image = self.low_resolution_upscale(result_image)
        elif blur_type == 'text':
            result_image = self.add_text_interference(result_image)
        elif blur_type == 'lines':
            result_image = self.add_line_interference(result_image)
        elif blur_type == 'print_scan':
            result_image = self.print_scan_blur(result_image)
        elif blur_type == 'localblur':
            result_image = self.local_blur(result_image)
        elif blur_type == 'threshold':
            result_image = self.threshold_artifacts(result_image)
        elif blur_type == 'print_noise':
            result_image = self.add_print_noise(result_image)
        elif blur_type == 'scan_lines':
            result_image = self.add_scan_lines(result_image)
        elif blur_type == 'line_discontinuity':
            result_image = self.line_discontinuity_blur(result_image)
        elif blur_type == 'regional_thinning':
            result_image = self.regional_line_thinning(result_image)
        elif blur_type == 'spectral_degradation':
            result_image = self.spectral_line_degradation(result_image)
        elif blur_type == 'composite':
            return self.apply_composite_blur(result_image, num_ops=random.randint(2, 3))

        return {
            'image': result_image,
            'blur_type': blur_type
        }

    def print_scan_blur(self, image: np.ndarray,
                        edge_blur_sigma: float = 1.2,
                        contrast_reduction: float = 0.9) -> np.ndarray:
        """æ¨¡æ‹ŸçœŸå®çš„æ‰“å°æ‰«ææ•ˆæœï¼šçº¿æ¡å˜ç»†+è¾¹ç¼˜æ¨¡ç³Š+å¯¹æ¯”åº¦é™ä½"""

        # 1. å¼ºçƒˆçš„é«˜æ–¯æ¨¡ç³Šï¼Œæ¨¡æ‹Ÿæ‰“å°çš„ç¾½åŒ–æ•ˆæœ
        heavily_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma)

        # 2. è½»åº¦æ¨¡ç³Šï¼Œä¿æŒä¸€äº›çº¿æ¡ç»“æ„
        lightly_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma * 0.3)

        # 3. æ··åˆå¾—åˆ°ç¾½åŒ–ä½†è¿˜èƒ½çœ‹åˆ°çš„çº¿æ¡ - é™ä½é‡åº¦æ¨¡ç³Šæ¯”ä¾‹
        result = cv2.addWeighted(lightly_blurred, 0.5, heavily_blurred, 0.5, 0)

        # 4. é™ä½å¯¹æ¯”åº¦ï¼Œæ¨¡æ‹ŸçœŸå®æ‰“å°çš„ç°åº¦æ•ˆæœ
        result = result.astype(np.float32)
        # å°†é»‘è‰²(0)å˜æˆæ·±ç°è‰²ï¼Œç™½è‰²(255)ä¿æŒ
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # 5. æ·»åŠ ç»†å¾®çš„èƒŒæ™¯å™ªå£°ï¼Œæ¨¡æ‹Ÿçº¸å¼ çº¹ç†
        paper_texture = np.random.normal(0, 8, result.shape)
        result += paper_texture

        return np.clip(result, 0, 255).astype(np.uint8)

    def local_blur(self, image: np.ndarray,
                   num_patches_range: tuple = (3, 8),
                   patch_size_range: tuple = (20, 60)) -> np.ndarray:
        """Apply blur to random local patches to simulate partial degradation"""
        h, w = image.shape[:2]
        result = image.copy()

        num_patches = random.randint(num_patches_range[0], num_patches_range[1])

        for _ in range(num_patches):
            # Random patch location and size
            patch_size = random.randint(patch_size_range[0], patch_size_range[1])
            x = random.randint(0, max(1, w - patch_size))
            y = random.randint(0, max(1, h - patch_size))

            # Extract patch
            patch = result[y:y+patch_size, x:x+patch_size].copy()

            # Apply strong blur to patch
            kernel_size = random.randrange(7, 15, 2)
            sigma = random.uniform(2.0, 4.0)
            blurred_patch = cv2.GaussianBlur(patch, (kernel_size, kernel_size), sigma)

            # Put back the blurred patch
            result[y:y+patch_size, x:x+patch_size] = blurred_patch

        return result

    def threshold_artifacts(self, image: np.ndarray,
                           threshold_range: tuple = (80, 120)) -> np.ndarray:
        """Apply threshold artifacts to simulate binary conversion effects"""
        # Convert to grayscale if color image
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            is_color = True
        else:
            gray = image.copy()
            is_color = False

        # Apply random threshold
        threshold_val = random.randint(threshold_range[0], threshold_range[1])
        _, binary = cv2.threshold(gray, threshold_val, 255, cv2.THRESH_BINARY)

        # Convert back to original format
        if is_color:
            # Convert back to BGR
            result = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
        else:
            result = binary

        return result

    def add_print_noise(self, image: np.ndarray,
                       noise_intensity: float = 0.15,
                       intensity: float = None) -> np.ndarray:
        """æ·»åŠ çœŸå®çš„æ‰“å°çº¸å¼ å™ªç‚¹ï¼šç°è‰²æ–‘ç‚¹ã€çº¸å¼ çº¹ç†"""
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä½¿ç”¨äº†intensityå‚æ•°ï¼Œåˆ™è¦†ç›–noise_intensity
        if intensity is not None:
            noise_intensity = intensity

        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # 1. ç”Ÿæˆçº¸å¼ çº¹ç†å™ªå£°ï¼ˆä¸»è¦æ˜¯ç°è‰²å€¼ï¼‰
        paper_noise = np.random.normal(0, noise_intensity * 20, (h, w))

        # 2. ç”Ÿæˆç»†å¾®çš„æ‰“å°æ–‘ç‚¹ï¼ˆä¸æ˜¯çº¯é»‘ç™½ï¼Œè€Œæ˜¯ç°è‰²ï¼‰
        spot_mask = np.random.random((h, w)) < (noise_intensity * 0.02)  # 2%çš„åƒç´ æœ‰æ–‘ç‚¹
        spot_values = np.random.uniform(180, 220, np.sum(spot_mask))  # ç°è‰²æ–‘ç‚¹ï¼Œä¸æ˜¯çº¯ç™½

        # 3. åº”ç”¨çº¸å¼ çº¹ç†
        if len(result.shape) == 3:
            for c in range(3):
                result[:, :, c] += paper_noise
        else:
            result += paper_noise

        # 4. æ·»åŠ ç°è‰²æ–‘ç‚¹
        if len(result.shape) == 3:
            # å¯¹äºå½©è‰²å›¾åƒï¼Œä¸ºæ¯ä¸ªé€šé“è®¾ç½®ç›¸åŒçš„ç°è‰²å€¼
            result[spot_mask, 0] = spot_values
            result[spot_mask, 1] = spot_values
            result[spot_mask, 2] = spot_values
        else:
            result[spot_mask] = spot_values

        # 5. ç¡®ä¿å€¼åœ¨åˆç†èŒƒå›´å†…
        result = np.clip(result, 0, 255).astype(np.uint8)

        return result

    def add_scan_lines(self, image: np.ndarray,
                      line_intensity: float = 0.1,
                      line_spacing: int = 3) -> np.ndarray:
        """æ·»åŠ æ‰«ææ¡çº¹æ•ˆæœ"""
        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # åˆ›å»ºæ°´å¹³æ‰«æçº¿æ•ˆæœ
        for y in range(0, h, line_spacing):
            # éšæœºå¼ºåº¦çš„æ‰«æçº¿
            line_strength = np.random.uniform(0.5, 1.0) * line_intensity * 30
            if len(result.shape) == 3:
                result[y, :] = result[y, :] * (1 - line_strength) + 240 * line_strength
            else:
                result[y, :] = result[y, :] * (1 - line_strength) + 240 * line_strength

        return np.clip(result, 0, 255).astype(np.uint8)

    def apply_composite_blur(self, image: np.ndarray, num_ops: int = 2) -> Dict[str, Any]:
        """Apply multiple blur operations in sequence for more realistic degradation"""
        available_ops = [
            'gaussian', 'motion', 'compression', 'print_scan',
            'localblur', 'threshold', 'print_noise', 'scan_lines'
        ]

        # Randomly select operations
        selected_ops = random.sample(available_ops, min(num_ops, len(available_ops)))

        result_image = image.copy()
        applied_operations = []

        for op in selected_ops:
            if op == 'gaussian':
                result_image = self.gaussian_blur(result_image)
            elif op == 'motion':
                result_image = self.motion_blur(result_image)
            elif op == 'compression':
                result_image = self.compression_artifacts(result_image)
            elif op == 'morphology':
                result_image = self.random_morphology(result_image)
            elif op == 'localblur':
                result_image = self.local_blur(result_image)
            elif op == 'threshold':
                result_image = self.threshold_artifacts(result_image)
            elif op == 'saltpepper':
                result_image = self.add_salt_pepper(result_image)

            applied_operations.append(op)

        return {
            'image': result_image,
            'blur_type': f"composite_{'_'.join(applied_operations)}"
        }

    def batch_generate_blur(self, 
                          input_dir: Union[str, Path],
                          output_dir: Union[str, Path],
                          num_variants_per_image: int = 5) -> None:
        
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        image_files = list(input_path.glob("*.png")) + list(input_path.glob("*.jpg"))
        
        for img_file in image_files:
            image = cv2.imread(str(img_file))
            if image is None:
                logging.warning(f"Could not load image: {img_file}")
                continue
                
            for i in range(num_variants_per_image):
                result = self.apply_random_blur(image)
                blur_image = result['image']
                blur_type = result['blur_type']

                output_file = output_path / f"{img_file.stem}_{blur_type}_{i}.png"
                cv2.imwrite(str(output_file), blur_image)

                logging.info(f"Generated blur variant: {output_file}")

    def generate_blur(self, input_path: Union[str, Path], output_path: Union[str, Path],
                     blur_type: str = None) -> None:
        """Generate a single blurred image"""
        # Load the image
        image = cv2.imread(str(input_path))
        if image is None:
            raise ValueError(f"Could not load image: {input_path}")

        # Apply blur effect
        if blur_type:
            result = self.apply_random_blur(image, blur_types=[blur_type])
        else:
            result = self.apply_random_blur(image)

        # Save result
        cv2.imwrite(str(output_path), result['image'])

    def generate_blur_with_difficulty(self, input_path: Union[str, Path],
                                    output_path: Union[str, Path],
                                    blur_type: str, difficulty_config: dict) -> None:
        """æ ¹æ®éš¾åº¦é…ç½®ç”Ÿæˆæ¨¡ç³Šå›¾åƒ"""
        # Load the image
        image = cv2.imread(str(input_path))
        if image is None:
            raise ValueError(f"Could not load image: {input_path}")

        # æ ¹æ®æ¨¡ç³Šç±»å‹å’Œéš¾åº¦é…ç½®åº”ç”¨æ•ˆæœ
        if blur_type == 'print_scan':
            result = self.print_scan_blur_with_config(image, difficulty_config)
        elif blur_type == 'print_noise':
            result = self.add_print_noise_with_config(image, difficulty_config)
        elif blur_type == 'scan_lines':
            result = self.add_scan_lines_with_config(image, difficulty_config)
        else:
            # é»˜è®¤ä½¿ç”¨åŸæœ‰æ–¹æ³•
            blur_result = self.apply_random_blur(image, blur_types=[blur_type])
            result = blur_result['image']

        # Save result
        cv2.imwrite(str(output_path), result)

    def print_scan_blur_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰“å°æ‰«ææ¨¡ç³Šæ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']
        print ("blur_strength", blur_strength, "contrast_reduction", contrast_reduction)

        # æ ¹æ®éš¾åº¦è°ƒæ•´æ¨¡ç³Šå¼ºåº¦
        edge_blur_sigma = 1.5 * blur_strength

        # çº¿æ¡ç»†åŒ–å¤„ç†ï¼ˆæ›´é«˜éš¾åº¦->æ›´ç»†çš„çº¿ï¼‰
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        # å¤šå±‚æ¨¡ç³Šå åŠ 
        heavily_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma)
        lightly_blurred = cv2.GaussianBlur(image, (0, 0), edge_blur_sigma * 0.3)

        # æ··åˆæ¨¡ç³Šæ•ˆæœ
        result = cv2.addWeighted(lightly_blurred, 0.4, heavily_blurred, 0.6, 0)

        # å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # æ·»åŠ è½»å¾®çš„çº¸å¼ çº¹ç†
        noise_intensity = 0.02 * blur_strength
        noise = np.random.normal(0, noise_intensity * 255, image.shape).astype(np.float32)
        result = np.clip(result + noise, 0, 255)

        return result.astype(np.uint8)

    def add_print_noise_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰“å°å™ªç‚¹æ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # é¦–å…ˆåº”ç”¨ç»†åŒ–å¤„ç†
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        result = image.copy().astype(np.float32)

        # æ ¹æ®éš¾åº¦è°ƒæ•´å™ªç‚¹å¯†åº¦å’Œå¼ºåº¦
        noise_density = 0.001 * (blur_strength ** 2)  # éš¾åº¦è¶Šé«˜å™ªç‚¹è¶Šå¤š
        noise_intensity = 30 * blur_strength  # éš¾åº¦è¶Šé«˜å™ªç‚¹è¶Šæ˜æ˜¾

        # ç”Ÿæˆå™ªç‚¹ä½ç½®
        h, w = result.shape[:2]
        num_spots = int(h * w * noise_density)

        if num_spots > 0:
            spot_coords = np.random.randint(0, [h, w], size=(num_spots, 2))

            # ç”Ÿæˆç°è‰²å™ªç‚¹ï¼ˆä¸æ˜¯çº¯é»‘ç™½ï¼‰
            spot_values = np.random.uniform(80, 180, num_spots).astype(np.float32)  # ç°è‰²èŒƒå›´

            # åˆ›å»ºæ©ç 
            spot_mask = (spot_coords[:, 0], spot_coords[:, 1])

            # åº”ç”¨å™ªç‚¹åˆ°æ‰€æœ‰é¢œè‰²é€šé“
            if len(result.shape) == 3:
                result[spot_mask[0], spot_mask[1], 0] = spot_values
                result[spot_mask[0], spot_mask[1], 1] = spot_values
                result[spot_mask[0], spot_mask[1], 2] = spot_values
            else:
                result[spot_mask] = spot_values

        # åº”ç”¨å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        return np.clip(result, 0, 255).astype(np.uint8)

    def add_scan_lines_with_config(self, image, difficulty_config):
        """åŸºäºéš¾åº¦é…ç½®çš„æ‰«æçº¿æ¡æ•ˆæœ"""
        blur_strength = difficulty_config['blur_strength']
        contrast_reduction = difficulty_config['contrast_reduction']

        # é¦–å…ˆåº”ç”¨ç»†åŒ–å¤„ç†
        kernel_size = max(1, int(3 - blur_strength))
        if kernel_size > 1:
            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            image = cv2.erode(image, kernel, iterations=1)

        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        # æ ¹æ®éš¾åº¦è°ƒæ•´æ‰«æçº¿å¯†åº¦å’Œå¼ºåº¦
        line_spacing = max(2, int(8 - blur_strength * 2))  # éš¾åº¦è¶Šé«˜çº¿æ¡è¶Šå¯†
        line_opacity = 0.1 + 0.1 * blur_strength  # éš¾åº¦è¶Šé«˜çº¿æ¡è¶Šæ˜æ˜¾

        # æ·»åŠ æ°´å¹³æ‰«æçº¿
        for y in range(0, h, line_spacing):
            if len(result.shape) == 3:
                result[y, :, :] *= (1 - line_opacity)
            else:
                result[y, :] *= (1 - line_opacity)

        # æ·»åŠ è½»å¾®çš„å‚ç›´æ‰«æçº¿ï¼ˆå¯†åº¦æ›´ä½ï¼‰
        vertical_spacing = line_spacing * 3
        for x in range(0, w, vertical_spacing):
            if len(result.shape) == 3:
                result[:, x, :] *= (1 - line_opacity * 0.5)
            else:
                result[:, x] *= (1 - line_opacity * 0.5)

        # åº”ç”¨å¯¹æ¯”åº¦é™ä½
        result = result * contrast_reduction + (255 * (1 - contrast_reduction))

        # æ·»åŠ è½»å¾®çš„æ•´ä½“æ¨¡ç³Š
        result = cv2.GaussianBlur(result.astype(np.uint8), (3, 3), 0.8 * blur_strength)

        return result.astype(np.uint8)

    def load_image(self, image_path: Union[str, Path]) -> np.ndarray:
        """Load an image from file"""
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        return image

    def line_discontinuity_blur(self, image: np.ndarray,
                               gap_density: float = 0.4,
                               gap_size_range: tuple = (2, 5)) -> np.ndarray:
        """
        Create dashed-line effects with many small gaps (not too disconnected)
        åˆ›å»ºè™šçº¿æ•ˆæœ - å°é—´éš™ä½†æ•°é‡å¤šï¼Œåƒè™šçº¿ä¸€æ ·
        """
        result = image.copy()
        h, w = result.shape[:2]

        # Convert to grayscale for line detection
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        # 1. åŸºäºHoughå˜æ¢çš„çº¿æ®µæ–­ç»­å¤„ç†
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=15,
                               minLineLength=8, maxLineGap=3)

        gaps_created = 0
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                line_length = np.sqrt((x2-x1)**2 + (y2-y1)**2)

                # Process lines to create dashed-line effect
                if line_length > 10:  # Process shorter lines too
                    # åˆ›å»ºè™šçº¿æ•ˆæœ - æ›´å¤šä½†æ›´å°çš„é—´éš™
                    num_gaps = max(3, int(line_length * gap_density / 6))  # More gaps

                    for _ in range(num_gaps):
                        # Random gap position along the line
                        t = random.uniform(0.1, 0.9)
                        gap_center_x = int(x1 + t * (x2 - x1))
                        gap_center_y = int(y1 + t * (y2 - y1))

                        # å°é—´éš™å°ºå¯¸ - åƒè™šçº¿çš„çŸ­åˆ’
                        gap_size = random.randint(gap_size_range[0], gap_size_range[1])

                        # Create small circular gaps for dashed effect
                        cv2.circle(result, (gap_center_x, gap_center_y), gap_size//2,
                                 (255, 255, 255) if len(result.shape) == 3 else 255, -1)
                        gaps_created += 1

        # 2. åŸºäºåƒç´ å¯†åº¦çš„æ™ºèƒ½é—´éš™ç”Ÿæˆ
        # æ‰¾åˆ°æ‰€æœ‰çº¿æ¡åƒç´ 
        line_mask = gray < 180  # æ›´å®½æ¾çš„é˜ˆå€¼ä»¥æ•è·æ›´å¤šçº¿æ¡
        line_coords = np.where(line_mask)

        if len(line_coords[0]) > 0:
            # è®¡ç®—è™šçº¿æ•ˆæœçš„å°é—´éš™
            num_pixel_gaps = int(len(line_coords[0]) * gap_density * 0.008)  # æ›´å¤šå°é—´éš™

            if num_pixel_gaps > 0:
                # éšæœºé€‰æ‹©çº¿æ¡åƒç´ ä½ç½®åˆ›å»ºå°é—´éš™
                indices = random.sample(range(len(line_coords[0])),
                                      min(num_pixel_gaps, len(line_coords[0])))

                for idx in indices:
                    gap_y, gap_x = line_coords[0][idx], line_coords[1][idx]
                    gap_size = random.randint(gap_size_range[0], gap_size_range[1])

                    # åªåˆ›å»ºå°åœ†å½¢é—´éš™ï¼Œä¿æŒè™šçº¿æ•ˆæœç®€å•ä¸€è‡´
                    cv2.circle(result, (gap_x, gap_y), gap_size//2,
                             (255, 255, 255) if len(result.shape) == 3 else 255, -1)
                    gaps_created += 1

        # 3. è½»å¾®çš„çº¿æ¡è¾¹ç¼˜å¤„ç†ï¼Œä¿æŒè™šçº¿æ•ˆæœè‡ªç„¶
        # å‡å°‘è¾¹ç¼˜è…èš€å¼ºåº¦ï¼Œé¿å…è¿‡åº¦æ–­å¼€
        if len(result.shape) == 3:
            result_gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
        else:
            result_gray = result.copy()

        # éå¸¸è½»å¾®çš„è…èš€ï¼Œåªæ˜¯ç¨å¾®è½¯åŒ–è¾¹ç¼˜
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        eroded = cv2.erode(result_gray, kernel, iterations=1)

        # éå¸¸è½»å¾®æ··åˆï¼Œä¿æŒç»å¤§éƒ¨åˆ†åŸå›¾ç»“æ„
        if len(result.shape) == 3:
            eroded_3ch = cv2.cvtColor(eroded, cv2.COLOR_GRAY2BGR)
            result = cv2.addWeighted(result, 0.95, eroded_3ch, 0.05, 0)  # æè½»çš„æ··åˆ
        else:
            result = cv2.addWeighted(result, 0.95, eroded, 0.05, 0)

        # print(f"  è™šçº¿æ•ˆæœå¤„ç†: åˆ›å»ºäº† {gaps_created} ä¸ªå°é—´éš™")
        return result

    def regional_line_variations(self, image: np.ndarray,
                                   thinning_strength: float = 0.3,
                                   fading_strength: float = 0.3,
                                   num_regions: int = 2) -> np.ndarray:
        """
        Regional line thinning and fading effects
        åŒºåŸŸæ€§çº¿æ¡å˜ç»†å’Œå˜æ·¡æ•ˆæœ - åªå½±å“å°‘æ•°åŒºåŸŸï¼Œä¿æŒä¸»ä½“çº¿æ¡æ­£å¸¸

        Args:
            thinning_strength: çº¿æ¡å˜ç»†å¼ºåº¦ (0-1)
            fading_strength: çº¿æ¡å˜æ·¡å¼ºåº¦ (0-1)
            num_regions: å½±å“çš„åŒºåŸŸæ•°é‡
        """
        result = image.copy()
        h, w = result.shape[:2]

        # å¦‚æœåŒºåŸŸæ•°é‡ä¸º0ï¼Œç›´æ¥è¿”å›åŸå›¾
        if num_regions == 0:
            return result

        for i in range(num_regions):
            # åˆ›å»ºè¾ƒå°çš„éšæœºåŒºåŸŸ - åªå½±å“å›¾åƒçš„ä¸€å°éƒ¨åˆ†
            region_w = random.randint(60, 150)  # è¾ƒå°çš„åŒºåŸŸ
            region_h = random.randint(60, 150)
            region_x = random.randint(0, max(1, w - region_w))
            region_y = random.randint(0, max(1, h - region_h))

            # æå–åŒºåŸŸ
            region = result[region_y:region_y+region_h, region_x:region_x+region_w].copy()

            # éšæœºé€‰æ‹©åº”ç”¨å˜ç»†æˆ–å˜æ·¡ï¼ˆä¸æ˜¯éƒ½åº”ç”¨ï¼‰
            effect_type = random.choice(['thinning', 'fading'])

            if effect_type == 'thinning' and thinning_strength > 0:
                # è½»å¾®çš„çº¿æ¡å˜ç»†
                kernel_size = max(1, min(3, int(1 + 2 * thinning_strength)))  # 1-3åƒç´ 
                if kernel_size % 2 == 0:
                    kernel_size += 1
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
                thinned_region = cv2.erode(region, kernel, iterations=1)  # åª1æ¬¡è¿­ä»£

                # è½»å¾®æ··åˆï¼Œä¿æŒå¤§éƒ¨åˆ†åŸå§‹çº¿æ¡
                alpha = 0.3 + 0.3 * thinning_strength  # æœ€å¤š0.6çš„æ··åˆæ¯”ä¾‹
                processed_region = cv2.addWeighted(region, 1-alpha, thinned_region, alpha, 0)

            elif effect_type == 'fading' and fading_strength > 0:
                # è½»å¾®çš„çº¿æ¡å˜æ·¡
                processed_region = region.copy().astype(np.float32)

                # æ‰¾åˆ°çº¿æ¡åŒºåŸŸ
                if len(region.shape) == 3:
                    gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
                else:
                    gray = region.copy()

                line_mask = gray < 200

                if np.any(line_mask):
                    # è½»å¾®çš„å˜æ·¡æ•ˆæœ
                    fade_amount = int(20 + 30 * fading_strength)  # 20-50çš„è½»å¾®å˜æ·¡

                    if len(processed_region.shape) == 3:
                        for c in range(3):
                            processed_region[:, :, c][line_mask] += fade_amount
                    else:
                        processed_region[line_mask] += fade_amount

                processed_region = np.clip(processed_region, 0, 255).astype(np.uint8)
            else:
                processed_region = region

            # å°†å¤„ç†åçš„åŒºåŸŸæ”¾å›åŸå›¾
            result[region_y:region_y+region_h, region_x:region_x+region_w] = processed_region

        return result

    def apply_single_blur_effect(self, image: np.ndarray, effect_type: str,
                               intensity: float = 0.5) -> np.ndarray:
        """
        åº”ç”¨å•ä¸ªæ¨¡ç³Šæ•ˆæœ - ç”¨äºæ¼”ç¤ºç›®çš„
        Args:
            intensity: æ•ˆæœå¼ºåº¦ (0-1)ï¼Œç”¨äºåŒºåˆ†easy/medium/hard
        """
        result = image.copy()

        if effect_type == 'gaussian':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´é«˜æ–¯æ¨¡ç³Šå‚æ•° - é™ä½å¼ºåº¦
            kernel_size = max(3, int(3 + 4 * intensity))  # 3-7 instead of 3-9
            if kernel_size % 2 == 0:
                kernel_size += 1
            sigma = 0.3 + 1.2 * intensity  # 0.3-1.5 instead of 0.5-2.5
            result = self.gaussian_blur(result, kernel_size=kernel_size, sigma_range=(sigma, sigma))
        elif effect_type == 'motion':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´è¿åŠ¨æ¨¡ç³Š - é™ä½å¼ºåº¦
            kernel_size = max(3, int(3 + 5 * intensity))  # 3-8 instead of 3-11
            result = self.motion_blur(result, kernel_size=kernel_size)
        elif effect_type == 'compression':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´å‹ç¼©è´¨é‡ - æé«˜æœ€ä½è´¨é‡
            quality = int(70 - 40 * intensity)  # 70->30 instead of 80->20
            result = self.compression_blur(result, quality=quality)
        elif effect_type == 'scan':
            # åŸºç¡€æ‰«ææ•ˆæœ - æ›´ç®€å•çš„å™ªå£°
            result = self.print_scan_simulation(result,
                                              noise_intensity=0.2 * intensity,
                                              brightness_contrast_intensity=0.1 * intensity)
        elif effect_type == 'lowres':
            # æ ¹æ®å¼ºåº¦è°ƒæ•´ä¸‹é‡‡æ ·å› å­ - é™ä½å¼ºåº¦
            factor = int(2 + 2 * intensity)  # 2->4 instead of 2->6
            result = self.low_resolution_blur(result, downscale_factor=factor)
        elif effect_type == 'text':
            result = self.add_text_interference(result)
        elif effect_type == 'lines':
            result = self.add_line_interference(result)
        elif effect_type == 'print_scan':
            # é«˜çº§æ‰“å°æ‰«ææ•ˆæœ - æ›´å¼ºçš„å™ªå£°å’Œå¯¹æ¯”åº¦å˜åŒ–
            result = self.print_scan_simulation(result,
                                              noise_intensity=0.5 + 0.5 * intensity,
                                              brightness_contrast_intensity=0.2 + 0.3 * intensity)
        elif effect_type == 'localblur':
            result = self.local_blur_degradation(result)
        elif effect_type == 'scan_lines':
            result = self.add_scan_lines(result)
        elif effect_type == 'spectral_degradation':
            # ä½¿ç”¨é…ç½®åŒ–å‚æ•° - é™ä½å¼ºåº¦
            strength = 0.1 + 0.4 * intensity  # 0.1-0.5 instead of 0.2-0.8
            range_pct = 0.2 + 0.3 * intensity  # 0.2-0.5 instead of 0.3-0.6
            result = self.spectral_line_degradation(result,
                                                  degradation_strength=strength,
                                                  range_percentage=range_pct)
        else:
            print(f"æœªçŸ¥æ•ˆæœç±»å‹: {effect_type}")

        return result

    def spectral_line_degradation(self, image: np.ndarray,
                                x_range: tuple = None,
                                degradation_strength: float = 0.3,
                                range_percentage: float = 0.4,
                                degradation_type: str = 'both') -> np.ndarray:
        """
        Apply configurable degradation effects to spectral line ranges
        ä¸“é—¨é’ˆå¯¹å…‰è°±çº¿çš„ç‰¹å®šxè½´èŒƒå›´è¿›è¡Œå¯é…ç½®å¼ºåº¦çš„é€€åŒ–å¤„ç†

        Args:
            degradation_strength: é€€åŒ–å¼ºåº¦ (0-1)
            range_percentage: å½±å“èŒƒå›´ç™¾åˆ†æ¯” (0-1)
        """
        if x_range is None:
            # Use configurable range percentage
            w = image.shape[1]
            range_width = int(w * range_percentage)
            x_start = random.randint(int(w * 0.1), int(w * 0.6))
            x_range = (x_start, min(x_start + range_width, w))

        result = image.copy()
        x_start, x_end = x_range

        # Extract the region of interest
        roi = result[:, x_start:x_end].copy()

        # 1. å¯é…ç½®çº¿æ¡ç»†åŒ–
        if degradation_type in ['thinning', 'both']:
            # æ ¹æ®å¼ºåº¦è°ƒæ•´kernelå¤§å°å’Œè¿­ä»£æ¬¡æ•°
            kernel_size = max(1, int(1 + 2 * degradation_strength))  # 1-3
            if kernel_size % 2 == 0:
                kernel_size += 1
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
            iterations = max(1, int(degradation_strength * 2))  # 0-2æ¬¡è¿­ä»£
            if iterations > 0:
                roi = cv2.erode(roi, kernel, iterations=iterations)

            # å¯é…ç½®æ¨¡ç³Šå¼ºåº¦
            blur_sigma = 0.3 + 1.2 * degradation_strength  # 0.3-1.5
            roi = cv2.GaussianBlur(roi, (3, 3), blur_sigma)

        # 2. å¯é…ç½®æ–­ç»­æ•ˆæœ
        if degradation_type in ['discontinuity', 'both']:
            gap_density = 0.05 + 0.2 * degradation_strength  # 0.05-0.25
            gap_size_max = int(2 + 6 * degradation_strength)  # 2-8
            roi = self.line_discontinuity_blur(roi, gap_density=gap_density,
                                             gap_size_range=(1, gap_size_max))

        # 3. å¯é…ç½®è¿åŠ¨æ¨¡ç³Š
        motion_kernel_size = max(3, int(3 + 4 * degradation_strength))  # 3-7
        motion_kernel = np.zeros((1, motion_kernel_size))
        motion_kernel[0, :] = 1/motion_kernel_size
        roi = cv2.filter2D(roi, -1, motion_kernel)

        # 4. å¯é…ç½®å¯¹æ¯”åº¦é™ä½
        contrast_factor = 1.0 - 0.3 * degradation_strength  # 1.0-0.7
        if len(roi.shape) == 3:
            roi = roi.astype(np.float32)
            roi = roi * contrast_factor + 255 * (1 - contrast_factor)
            roi = np.clip(roi, 0, 255).astype(np.uint8)

        # Put back the processed region
        result[:, x_start:x_end] = roi

        return result

    def background_color_variation(self, image: np.ndarray,
                                 variation_type: str = 'random',
                                 intensity: float = 0.3) -> np.ndarray:
        """
        Apply background color variation to simulate different lighting/printing conditions
        åº”ç”¨èƒŒæ™¯é¢œè‰²å˜åŒ– - æ¨¡æ‹Ÿä¸åŒçš„å…‰çº¿æˆ–æ‰“å°æ¡ä»¶

        Args:
            variation_type: 'global' (æ•´ä½“å˜åŒ–), 'local' (å±€éƒ¨å˜åŒ–), 'random' (éšæœºé€‰æ‹©)
            intensity: å˜åŒ–å¼ºåº¦ 0.0-1.0
        """
        result = image.copy().astype(np.float32)
        h, w = result.shape[:2]

        if variation_type == 'random':
            variation_type = random.choice(['global', 'local', 'gradient'])

        if variation_type == 'global':
            # æ•´ä½“é¢œè‰²åç§» - æ¨¡æ‹Ÿæ•´ä½“å…‰çº¿å˜åŒ–
            if len(result.shape) == 3:
                # ç”Ÿæˆæ•´ä½“è‰²å
                color_shift = np.array([
                    random.uniform(-30*intensity, 30*intensity),  # R
                    random.uniform(-25*intensity, 25*intensity),  # G
                    random.uniform(-35*intensity, 35*intensity)   # B
                ])

                # åº”ç”¨åˆ°èƒŒæ™¯åŒºåŸŸï¼ˆäº®åƒç´ ï¼‰
                for c in range(3):
                    channel = result[:, :, c]
                    bg_mask = channel > 200  # èƒŒæ™¯åƒç´ 
                    channel[bg_mask] += color_shift[c]

            else:
                # ç°åº¦å›¾çš„äº®åº¦å˜åŒ–
                brightness_shift = random.uniform(-20*intensity, 20*intensity)
                bg_mask = result > 200
                result[bg_mask] += brightness_shift

        elif variation_type == 'local':
            # å±€éƒ¨é¢œè‰²å˜åŒ– - æ¨¡æ‹Ÿæ‰«ææ—¶çš„ä¸å‡åŒ€å…‰ç…§
            num_patches = random.randint(3, 8)

            for _ in range(num_patches):
                # éšæœºè¡¥ä¸ä½ç½®å’Œå¤§å°
                patch_w = random.randint(int(w*0.2), int(w*0.6))
                patch_h = random.randint(int(h*0.2), int(h*0.6))
                patch_x = random.randint(0, max(1, w - patch_w))
                patch_y = random.randint(0, max(1, h - patch_h))

                # åˆ›å»ºæ¸å˜é®ç½©è®©å˜åŒ–æ›´è‡ªç„¶
                mask = np.zeros((patch_h, patch_w), dtype=np.float32)
                center_x, center_y = patch_w//2, patch_h//2
                max_dist = min(patch_w, patch_h) // 2

                for y in range(patch_h):
                    for x in range(patch_w):
                        dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                        mask[y, x] = max(0, 1 - dist/max_dist)

                if len(result.shape) == 3:
                    # å½©è‰²å›¾çš„å±€éƒ¨è‰²å
                    local_color_shift = np.array([
                        random.uniform(-25*intensity, 25*intensity),
                        random.uniform(-20*intensity, 20*intensity),
                        random.uniform(-30*intensity, 30*intensity)
                    ])

                    for c in range(3):
                        patch = result[patch_y:patch_y+patch_h, patch_x:patch_x+patch_w, c]
                        bg_mask = patch > 180  # èƒŒæ™¯åŒºåŸŸ
                        patch[bg_mask] += mask[bg_mask] * local_color_shift[c]
                else:
                    # ç°åº¦å›¾çš„å±€éƒ¨äº®åº¦å˜åŒ–
                    brightness_shift = random.uniform(-15*intensity, 15*intensity)
                    patch = result[patch_y:patch_y+patch_h, patch_x:patch_x+patch_w]
                    bg_mask = patch > 180
                    patch[bg_mask] += mask[bg_mask] * brightness_shift

        elif variation_type == 'gradient':
            # æ¸å˜å˜åŒ– - æ¨¡æ‹Ÿæ‰«æä»ªå…‰æºä¸å‡
            direction = random.choice(['horizontal', 'vertical', 'diagonal'])

            if direction == 'horizontal':
                gradient = np.linspace(-20*intensity, 20*intensity, w)
                gradient_map = np.tile(gradient, (h, 1))
            elif direction == 'vertical':
                gradient = np.linspace(-20*intensity, 20*intensity, h)
                gradient_map = np.tile(gradient.reshape(-1, 1), (1, w))
            else:  # diagonal
                x_grad = np.linspace(-15*intensity, 15*intensity, w)
                y_grad = np.linspace(-15*intensity, 15*intensity, h)
                gradient_map = np.add.outer(y_grad, x_grad) / 2

            if len(result.shape) == 3:
                # éšæœºé€‰æ‹©ä¸»è¦å½±å“çš„é¢œè‰²é€šé“
                primary_channel = random.randint(0, 2)
                for c in range(3):
                    channel = result[:, :, c]
                    bg_mask = channel > 180
                    if c == primary_channel:
                        channel[bg_mask] += gradient_map[bg_mask]
                    else:
                        channel[bg_mask] += gradient_map[bg_mask] * 0.3
            else:
                bg_mask = result > 180
                result[bg_mask] += gradient_map[bg_mask]

        # ç¡®ä¿å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
        result = np.clip(result, 0, 255).astype(np.uint8)
        return result

    def apply_base_degradation(self, image: np.ndarray) -> tuple:
        """
        Apply base degradation effects that should be present in every image:
        - Background color variation (lighting/printing conditions)
        - Line thickness inconsistency (regional_thinning with color variation)
        - Line discontinuity (dashed line effect)
        - Print noise artifacts
        å¯¹æ¯å¼ å›¾ç‰‡éƒ½åº”ç”¨çš„åŸºç¡€é€€åŒ–æ•ˆæœç»„åˆ - ä½¿ç”¨é…ç½®åŒ–çš„å¼ºåº¦èŒƒå›´

        Returns:
            tuple: (degraded_image, effects_log)
        """
        result = image.copy()
        config = self.difficulty_config
        applied_effects = []

        try:
            # 1. åº•è‰²å˜åŒ– (æ¨¡æ‹Ÿå…‰çº¿/æ‰“å°æ¡ä»¶å·®å¼‚) - ä½¿ç”¨é…ç½®åŒ–å¼ºåº¦
            bg_intensity = get_random_value_in_range(config['background_variation']['intensity'])
            effect_log = f"background_variation(intensity={bg_intensity:.3f})"
            applied_effects.append(effect_log)
            result = self.background_color_variation(result, intensity=bg_intensity)

            # 2. çº¿æ¡å˜ç»†å’Œå˜æ·¡ - åŒºåŸŸæ€§è½»å¾®å˜åŒ–
            line_config = config['line_thinning_fading']
            thinning_strength = get_random_value_in_range(line_config['thinning_strength'])
            fading_strength = get_random_value_in_range(line_config['fading_strength'])
            num_regions = get_random_value_in_range(line_config['num_regions'], is_int=True)
            effect_log = f"line_variations(thin={thinning_strength:.3f}, fade={fading_strength:.3f}, regions={num_regions})"
            applied_effects.append(effect_log)
            result = self.regional_line_variations(result,
                                                 thinning_strength=thinning_strength,
                                                 fading_strength=fading_strength,
                                                 num_regions=num_regions)

            # 3. çº¿æ®µæ–­æ–­ç»­ç»­ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°
            discontinuity_config = config['line_discontinuity']
            gap_density = get_random_value_in_range(discontinuity_config['gap_density'])
            gap_size_range = discontinuity_config['gap_size_range'][0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªèŒƒå›´

            # ç¡®ä¿gap_size_rangeæœ‰æ•ˆ
            if gap_size_range[0] > gap_size_range[1]:
                gap_size_range = (gap_size_range[1], gap_size_range[0])

            effect_log = f"line_discontinuity(density={gap_density:.3f}, gap_range={gap_size_range})"
            applied_effects.append(effect_log)
            result = self.line_discontinuity_blur(result,
                                                gap_density=gap_density,
                                                gap_size_range=gap_size_range)

            # 4. æ‰“å°å™ªç‚¹æ•ˆæœ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°
            noise_intensity = get_random_value_in_range(config['print_noise']['noise_intensity'])
            effect_log = f"print_noise(intensity={noise_intensity:.3f})"
            applied_effects.append(effect_log)
            result = self.add_print_noise(result, noise_intensity=noise_intensity)

        except Exception as e:
            print(f"ğŸš¨ BASE DEGRADATION ERROR:")
            print(f"   Difficulty: {self.difficulty}")
            print(f"   Applied effects so far: {applied_effects}")
            print(f"   Error: {str(e)}")
            print(f"   Config: {config}")
            raise e

        return result, applied_effects

    def apply_random_additional_blur(self, image: np.ndarray, num_effects: int = None) -> Dict[str, Any]:
        """
        Apply random additional blur effects on top of base degradation using difficulty-based parameters
        åœ¨åŸºç¡€é€€åŒ–çš„åŸºç¡€ä¸Šéšæœºæ·»åŠ é¢å¤–çš„æ¨¡ç³Šæ•ˆæœï¼ˆä½¿ç”¨é…ç½®åŒ–çš„éš¾åº¦å‚æ•°ï¼‰
        """
        config = self.difficulty_config
        if num_effects is None:
            num_effects = get_random_value_in_range(config['additional_effects_count'], is_int=True)

        # å¯é€‰çš„é¢å¤–æ¨¡ç³Šæ•ˆæœï¼ˆä¸åŒ…æ‹¬åŸºç¡€å¿…åŠ æ•ˆæœï¼‰
        additional_effects = [
            'gaussian', 'motion', 'compression', 'scan', 'lowres',
            'text', 'lines', 'print_scan', 'localblur',  # æš‚æ—¶ç§»é™¤threshold
            'scan_lines', 'spectral_degradation'
        ]

        # éšæœºé€‰æ‹©effects
        selected_effects = random.sample(additional_effects,
                                       min(num_effects, len(additional_effects)))

        result = image.copy()
        applied_effects = []
        effect_details = []

        print(f"ğŸ”§ ADDITIONAL BLUR: {self.difficulty} difficulty, applying {num_effects} effects: {selected_effects}")

        for effect in selected_effects:
            try:
                if effect == 'gaussian':
                    # ä½¿ç”¨é…ç½®åŒ–çš„é«˜æ–¯æ¨¡ç³Šå‚æ•°
                    gaussian_config = config['gaussian_blur']
                    kernel_range = get_random_range_in_ranges(gaussian_config['kernel_size_range'], is_int=True)
                    sigma_range = get_random_range_in_ranges(gaussian_config['sigma_range'])
                    effect_details.append(f"gaussian(kernel={kernel_range}, sigma={sigma_range})")
                    result = self.gaussian_blur(result, kernel_size_range=kernel_range, sigma_range=sigma_range)
                elif effect == 'motion':
                    # ä½¿ç”¨é…ç½®åŒ–çš„è¿åŠ¨æ¨¡ç³Šå‚æ•°
                    motion_config = config['motion_blur']
                    kernel_range = get_random_range_in_ranges(motion_config['kernel_size_range'], is_int=True)
                    effect_details.append(f"motion(kernel={kernel_range})")
                    result = self.motion_blur(result, kernel_size_range=kernel_range)
                elif effect == 'compression':
                    # ä½¿ç”¨é…ç½®åŒ–çš„å‹ç¼©å‚æ•°
                    comp_config = config['compression']
                    quality_range = get_random_range_in_ranges(comp_config['quality_range'], is_int=True)
                    effect_details.append(f"compression(quality={quality_range})")
                    result = self.compression_artifacts(result, quality_range=quality_range)
                elif effect == 'scan':
                    effect_details.append("print_scan_simulation")
                    result = self.print_scan_simulation(result, enable_geometric_distortion=False)
                elif effect == 'lowres':
                    # ä½¿ç”¨é…ç½®åŒ–çš„ä½åˆ†è¾¨ç‡å‚æ•°
                    lowres_config = config['lowres']
                    factor_range = get_random_range_in_ranges(lowres_config['downscale_factor_range'], is_int=True)
                    effect_details.append(f"lowres(factor={factor_range})")
                    result = self.low_resolution_upscale(result, downscale_factor_range=factor_range)
                elif effect == 'text':
                    # ä½¿ç”¨é…ç½®åŒ–çš„æ–‡æœ¬å¹²æ‰°å‚æ•° (å›ºå®šèŒƒå›´)
                    effect_details.append("text_interference(1-3)")
                    result = self.add_text_interference(result, num_texts_range=(1, 3))
                elif effect == 'lines':
                    # ä½¿ç”¨é…ç½®åŒ–çš„çº¿æ¡å¹²æ‰°å‚æ•° (å›ºå®šèŒƒå›´)
                    effect_details.append("line_interference(1-3)")
                    result = self.add_line_interference(result, num_lines_range=(1, 3))
                elif effect == 'print_scan':
                    effect_details.append("print_scan_blur")
                    result = self.print_scan_blur(result)
                elif effect == 'localblur':
                    effect_details.append("local_blur")
                    result = self.local_blur(result)
                elif effect == 'threshold':
                    # ä½¿ç”¨é…ç½®åŒ–çš„é˜ˆå€¼å‚æ•°
                    threshold_config = config['threshold']
                    threshold_range = get_random_range_in_ranges(threshold_config['threshold_range'], is_int=True)
                    effect_details.append(f"threshold(range={threshold_range})")
                    result = self.threshold_artifacts(result, threshold_range=threshold_range)
                elif effect == 'scan_lines':
                    effect_details.append("scan_lines")
                    result = self.add_scan_lines(result)
                elif effect == 'spectral_degradation':
                    # ä½¿ç”¨é…ç½®åŒ–çš„å…‰è°±é€€åŒ–å‚æ•°
                    spectral_config = config['spectral_degradation']
                    degradation_strength = get_random_value_in_range(spectral_config['degradation_strength'])
                    range_percentage = get_random_value_in_range(spectral_config['range_percentage'])
                    effect_details.append(f"spectral_degradation(strength={degradation_strength:.3f}, range={range_percentage:.3f})")
                    result = self.spectral_line_degradation(result)

                applied_effects.append(effect)
            except Exception as e:
                print(f"ğŸš¨ ADDITIONAL BLUR ERROR in {effect}:")
                print(f"   Difficulty: {self.difficulty}")
                print(f"   Applied effects so far: {effect_details}")
                print(f"   Current effect: {effect}")
                print(f"   Error: {str(e)}")
                raise e

        return {
            'image': result,
            'blur_type': f"base_plus_{'_'.join(applied_effects)}",
            'additional_effects': applied_effects,
            'additional_effects_details': effect_details,
            'num_additional': len(applied_effects)
        }

    def simple_line_thinning_and_fading(self, image: np.ndarray,
                                      thinning_strength: float = 0.3,
                                      fading_strength: float = 0.3) -> np.ndarray:
        """
        ç®€å•çš„çº¿æ¡ç»†åŒ–å’Œå˜æ·¡æ•ˆæœ

        Args:
            image: è¾“å…¥å›¾åƒ
            thinning_strength: ç»†åŒ–å¼ºåº¦ (0-1)
            fading_strength: å˜æ·¡å¼ºåº¦ (0-1)

        Returns:
            å¤„ç†åçš„å›¾åƒ
        """
        result = image.copy()

        # æ£€æµ‹çº¿æ¡åŒºåŸŸ (æš—è‰²åŒºåŸŸ)
        gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) if len(result.shape) == 3 else result.copy()
        line_mask = gray < 180  # çº¿æ¡é€šå¸¸æ˜¯æš—è‰²çš„

        # 1. çº¿æ¡ç»†åŒ– - ä½¿ç”¨å½¢æ€å­¦è…èš€
        if thinning_strength > 0:
            kernel_size = max(1, int(3 * thinning_strength))
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
            # ä»…åœ¨çº¿æ¡åŒºåŸŸåº”ç”¨è…èš€
            thinned_gray = cv2.erode(gray, kernel, iterations=1)
            # æ··åˆåŸå›¾å’Œç»†åŒ–ç»“æœ
            alpha = 1 - thinning_strength
            gray = cv2.addWeighted(gray, alpha, thinned_gray, thinning_strength, 0)

        # 2. çº¿æ¡å˜æ·¡ - å¢åŠ çº¿æ¡åŒºåŸŸçš„äº®åº¦
        if fading_strength > 0:
            fade_amount = int(50 * fading_strength)  # æœ€å¤šå¢åŠ 50çš„äº®åº¦
            gray[line_mask] = np.clip(gray[line_mask] + fade_amount, 0, 255)

        # è½¬æ¢å›åŸå§‹è‰²å½©ç©ºé—´
        if len(result.shape) == 3:
            result = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
        else:
            result = gray

        return result

    def local_blur_degradation(self, image: np.ndarray,
                              num_regions: int = 3,
                              blur_intensity: float = 0.5) -> np.ndarray:
        """
        å±€éƒ¨æ¨¡ç³Šé€€åŒ–æ•ˆæœ - åœ¨å›¾åƒçš„éšæœºåŒºåŸŸåº”ç”¨æ¨¡ç³Š

        Args:
            image: è¾“å…¥å›¾åƒ
            num_regions: æ¨¡ç³ŠåŒºåŸŸæ•°é‡
            blur_intensity: æ¨¡ç³Šå¼ºåº¦ (0-1)

        Returns:
            å¤„ç†åçš„å›¾åƒ
        """
        result = image.copy()
        h, w = result.shape[:2]

        for i in range(num_regions):
            # éšæœºé€‰æ‹©åŒºåŸŸä½ç½®å’Œå¤§å°
            region_w = random.randint(w//8, w//3)  # åŒºåŸŸå®½åº¦
            region_h = random.randint(h//8, h//3)  # åŒºåŸŸé«˜åº¦
            x = random.randint(0, w - region_w)
            y = random.randint(0, h - region_h)

            # æå–åŒºåŸŸ
            region = result[y:y+region_h, x:x+region_w].copy()

            # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
            kernel_size = max(3, int(7 * blur_intensity))
            if kernel_size % 2 == 0:  # ç¡®ä¿æ˜¯å¥‡æ•°
                kernel_size += 1
            sigma = 1.0 + 2.0 * blur_intensity
            blurred_region = cv2.GaussianBlur(region, (kernel_size, kernel_size), sigma)

            # åˆ›å»ºæ¸å˜æ··åˆè’™ç‰ˆï¼Œé¿å…ç¡¬è¾¹ç¼˜
            mask = np.zeros((region_h, region_w), dtype=np.float32)
            center_x, center_y = region_w // 2, region_h // 2
            max_dist = min(region_w, region_h) // 2

            for py in range(region_h):
                for px in range(region_w):
                    dist = np.sqrt((px - center_x)**2 + (py - center_y)**2)
                    if dist < max_dist:
                        mask[py, px] = 1.0 - (dist / max_dist)

            # åº”ç”¨æ··åˆè’™ç‰ˆ
            if len(result.shape) == 3:
                mask = np.stack([mask] * 3, axis=-1)

            # æ··åˆåŸå§‹åŒºåŸŸå’Œæ¨¡ç³ŠåŒºåŸŸ
            mixed_region = region * (1 - mask * blur_intensity) + blurred_region * (mask * blur_intensity)
            result[y:y+region_h, x:x+region_w] = mixed_region.astype(np.uint8)

        return result

    def compression_blur(self, image: np.ndarray, quality: int = None, quality_range: tuple = (30, 70)) -> np.ndarray:
        """
        å‹ç¼©æ¨¡ç³Šæ•ˆæœçš„åˆ«åæ–¹æ³• - å…¼å®¹main.pyä¸­çš„è°ƒç”¨

        Args:
            image: è¾“å…¥å›¾åƒ
            quality: å‹ç¼©è´¨é‡ (1-100ï¼Œè¶Šå°å‹ç¼©è¶Šå¼º)
            quality_range: è´¨é‡èŒƒå›´ï¼Œå½“qualityä¸ºNoneæ—¶ä½¿ç”¨

        Returns:
            å‹ç¼©åçš„å›¾åƒ
        """
        if quality is not None:
            # å•ä¸ªè´¨é‡å€¼
            return self.compression_artifacts(image, quality_range=(quality, quality))
        else:
            # ä½¿ç”¨èŒƒå›´
            return self.compression_artifacts(image, quality_range=quality_range)

    def low_resolution_blur(self, image: np.ndarray, downscale_factor: int = None, downscale_factor_range: tuple = (4, 8)) -> np.ndarray:
        """
        ä½åˆ†è¾¨ç‡æ¨¡ç³Šæ•ˆæœçš„åˆ«åæ–¹æ³• - å…¼å®¹main.pyä¸­çš„è°ƒç”¨

        Args:
            image: è¾“å…¥å›¾åƒ
            downscale_factor: ä¸‹é‡‡æ ·å› å­
            downscale_factor_range: ä¸‹é‡‡æ ·å› å­èŒƒå›´ï¼Œå½“downscale_factorä¸ºNoneæ—¶ä½¿ç”¨

        Returns:
            ä½åˆ†è¾¨ç‡å¤„ç†åçš„å›¾åƒ
        """
        if downscale_factor is not None:
            # å•ä¸ªå› å­å€¼
            return self.low_resolution_upscale(image, downscale_factor_range=(downscale_factor, downscale_factor))
        else:
            # ä½¿ç”¨èŒƒå›´
            return self.low_resolution_upscale(image, downscale_factor_range=downscale_factor_range)