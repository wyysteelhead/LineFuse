#!/usr/bin/env python3
"""
LineFuse ä¸»ç¨‹åº
å…‰è°±æŠ˜çº¿å›¾æ¨¡ç³Šæ•°æ®ç”Ÿæˆå’Œæ¨¡å‹è®­ç»ƒçš„ç»Ÿä¸€å…¥å£
"""

import sys
import argparse
import random
from pathlib import Path
sys.path.append(str(Path(__file__).parent / 'src'))

import numpy as np
from data.clean_chart_generator import CleanChartGenerator
from data.dataset_builder import DatasetBuilder

def generate_dataset(num_samples: int = 10, output_dir: str = "linefuse_dataset",
                    difficulty_levels: list = ["easy", "medium", "hard"],
                    enable_style_diversity: bool = True,
                    style_diversity_level: float = 0.8,
                    image_size: int = 1024,
                    line_width: float = 0.8,
                    pixel_perfect: bool = True,
                    pure_line_only: bool = False,
                    target_style: str = None):
    """ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæ•°æ®é›†"""
    print(f"=== LineFuse æ•°æ®é›†ç”Ÿæˆ ===")
    print(f"ä½¿ç”¨æ ·æœ¬æ•°é‡: {num_samples}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"éš¾åº¦çº§åˆ«: {', '.join(difficulty_levels)}")
    print(f"æ ·å¼å¤šæ ·åŒ–: {'å¯ç”¨' if enable_style_diversity else 'ç¦ç”¨'}")
    if enable_style_diversity:
        print(f"å¤šæ ·åŒ–ç¨‹åº¦: {style_diversity_level:.1f} (0.0=æœ€ä½, 1.0=æœ€é«˜)")
        if target_style:
            print(f"ç›®æ ‡æ ·å¼: {target_style}")
    print(f"åƒç´ å®Œç¾å¯¹é½: {'å¯ç”¨' if pixel_perfect else 'ç¦ç”¨'}")
    print(f"çº¯çº¿æ¡æ¨¡å¼: {'å¯ç”¨' if pure_line_only else 'ç¦ç”¨'}")

    # å®šä¹‰éš¾åº¦çº§åˆ«é…ç½®
    difficulty_config = {
        "easy": {
            "line_width": 0.6,
            "blur_strength": 1.5,
            "contrast_reduction": 0.8,
            "description": "è½»åº¦æ¨¡ç³Šï¼Œçº¿æ¡é€‚ä¸­"
        },
        "medium": {
            "line_width": 0.3,
            "blur_strength": 2.5,
            "contrast_reduction": 0.7,
            "description": "ä¸­åº¦æ¨¡ç³Šï¼Œçº¿æ¡å¾ˆç»†"
        },
        "hard": {
            "line_width": 0.15,
            "blur_strength": 3.5,
            "contrast_reduction": 0.6,
            "description": "é‡åº¦æ¨¡ç³Šï¼Œçº¿æ¡æç»†"
        },
        "extreme": {
            "line_width": 0.1,
            "blur_strength": 4.5,
            "contrast_reduction": 0.5,
            "description": "æåº¦æ¨¡ç³Šï¼Œå‡ ä¹ä¸å¯è§çº¿æ¡"
        }
    }

    # æ£€æŸ¥å·²æœ‰çš„CSVæ•°æ®
    existing_csv_dir = Path('dataset/csv_data')
    if not existing_csv_dir.exists():
        print(f"âœ— æœªæ‰¾åˆ°CSVæ•°æ®ç›®å½•: {existing_csv_dir}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆåˆ›å»ºCSVæ–‡ä»¶")
        return False

    # è·å–å¯ç”¨çš„CSVæ–‡ä»¶
    csv_files = list(existing_csv_dir.glob("*.csv"))
    if not csv_files:
        print(f"âœ— CSVç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•CSVæ–‡ä»¶")
        return False

    # é™åˆ¶ä½¿ç”¨çš„æ ·æœ¬æ•°é‡
    csv_files = csv_files[:num_samples]
    actual_samples = len(csv_files)
    print(f"âœ“ æ‰¾åˆ° {len(list(existing_csv_dir.glob('*.csv')))} ä¸ªCSVæ–‡ä»¶ï¼Œä½¿ç”¨ {actual_samples} ä¸ª")

    # ç›´æ¥åˆ›å»ºæœ€ç»ˆæ•°æ®é›†ç›®å½•
    final_dir = Path(output_dir) / 'final_dataset'
    final_dir.mkdir(parents=True, exist_ok=True)

    # ä¸´æ—¶ç›®å½•ç”¨äºä¸­é—´å¤„ç†
    temp_clean_dir = Path(output_dir) / '.temp_clean'
    temp_blur_dir = Path(output_dir) / '.temp_blur'
    temp_clean_dir.mkdir(exist_ok=True)
    temp_blur_dir.mkdir(exist_ok=True)

    # æ­¥éª¤1: ä»å·²æœ‰CSVç”Ÿæˆæ¸…æ™°å›¾è¡¨
    print(f"\n1. ä»å·²æœ‰CSVç”Ÿæˆæ¸…æ™°å…‰è°±å›¾è¡¨...")

    # æ³¨æ„ï¼šè¿™é‡Œä¸å†ç›´æ¥ç”Ÿæˆæœ€ç»ˆçš„cleanå›¾è¡¨
    # è€Œæ˜¯ä¸ºæ¯ä¸ªéš¾åº¦çº§åˆ«ç”Ÿæˆå¯¹åº”çš„cleanåŸºç¡€å›¾ï¼Œç¡®ä¿clean/blurèƒŒæ™¯ä¸€è‡´
    print("  æ¸…æ™°å›¾è¡¨å°†æŒ‰éš¾åº¦çº§åˆ«ç”Ÿæˆä»¥ç¡®ä¿ä¸æ¨¡ç³Šå›¾è¡¨èƒŒæ™¯ä¸€è‡´...")

    # æ­¥éª¤2: æŒ‰éš¾åº¦çº§åˆ«ç”Ÿæˆç»Ÿä¸€åŸºç¡€å›¾å’Œé…å¯¹çš„clean/blurå›¾
    print(f"\n2. æŒ‰éš¾åº¦çº§åˆ«ç”Ÿæˆç»Ÿä¸€åŸºç¡€å›¾å’Œé…å¯¹çš„clean/blurå›¾...")

    # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç”Ÿæˆæ¨¡ç³Šæ•ˆæœ
    can_generate_blur = True
    try:
        from data.blur_generator import BlurGenerator
    except ImportError as e:
        print(f"âš ï¸  æ¨¡ç³Šæ•ˆæœç”Ÿæˆéœ€è¦ä¾èµ–åº“: {e}")
        print("è¯·è¿è¡Œ: pip install opencv-python albumentations")
        print("å°†ä»…ç”Ÿæˆæ¸…æ™°å›¾...")
        can_generate_blur = False

    total_blur_count = 0
    total_clean_count = 0

    # åˆå§‹åŒ–æ¨¡ç³Šæ•ˆæœæ—¥å¿—æ–‡ä»¶
    log_file = Path(output_dir) / 'blur_effects_log.txt'
    with open(log_file, 'w', encoding='utf-8') as f:
        f.write("LineFuse æ¨¡ç³Šæ•ˆæœè¯¦ç»†æ—¥å¿—\n")
        f.write("=" * 50 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {__import__('datetime').datetime.now()}\n")
        f.write(f"æ ·æœ¬æ•°é‡: {num_samples}\n")
        f.write(f"éš¾åº¦çº§åˆ«: {', '.join(difficulty_levels)}\n")
        f.write(f"æ ·å¼å¤šæ ·åŒ–: {'å¯ç”¨' if enable_style_diversity else 'ç¦ç”¨'}\n")
        f.write("=" * 50 + "\n")

    # ä¸ºæ¯ä¸ªéš¾åº¦çº§åˆ«ç”Ÿæˆé…å¯¹çš„æ¸…æ™°å›¾å’Œæ¨¡ç³Šå›¾
    for difficulty in difficulty_levels:
        config = difficulty_config[difficulty]
        print(f"\n  ç”Ÿæˆ {difficulty} éš¾åº¦ ({config['description']})...")

        difficulty_blur_count = 0
        difficulty_clean_count = 0

        # å¦‚æœå¯ä»¥ç”Ÿæˆæ¨¡ç³Šæ•ˆæœï¼Œåˆå§‹åŒ–æ¨¡ç³Šç”Ÿæˆå™¨
        if can_generate_blur:
            blur_generator = BlurGenerator(difficulty=difficulty)

        # ä¸ºæ¯ä¸ªCSVæ–‡ä»¶ç”Ÿæˆç»Ÿä¸€åŸºç¡€å›¾ï¼Œç„¶åé…å¯¹ç”Ÿæˆclean/blur
        for csv_file in csv_files:
            # åˆ›å»ºè¯¥éš¾åº¦çš„åŸºç¡€å›¾ç”Ÿæˆå™¨ï¼ŒåŒ…å«æ ·å¼å¤šæ ·åŒ–
            difficulty_generator = CleanChartGenerator(
                figure_size=(image_size, image_size),
                line_width=config['line_width'],
                enable_style_diversity=enable_style_diversity,
                style_diversity_level=style_diversity_level,
                target_style=target_style
            )

            # ç»Ÿä¸€åŸºç¡€å›¾æ–‡ä»¶è·¯å¾„ - è¿™å°†ä½œä¸ºè¯¥éš¾åº¦ä¸‹è¯¥CSVçš„æ ‡å‡†åŸºç¡€å›¾
            base_chart_file = temp_clean_dir / f"{csv_file.stem}_{difficulty}_base.png"

            try:
                # æ ¹æ®éœ€æ±‚åˆ†åˆ«ç”Ÿæˆcleanå’Œblurçš„åŸºç¡€å›¾
                if pure_line_only:
                    # pure_line_onlyæ¨¡å¼ï¼šcleanå›¾ä¸ºçº¯çº¿æ¡ï¼Œblurå›¾æœ‰åæ ‡

                    # 1. ç”Ÿæˆçº¯çº¿æ¡çš„cleanå›¾
                    clean_output_name = f"{csv_file.stem}_{difficulty}_clean.png"
                    clean_output_path = temp_clean_dir / clean_output_name
                    difficulty_generator.process_csv_to_chart(csv_file, clean_output_path,
                                                            pure_line_only=True,  # cleanå›¾çº¯çº¿æ¡
                                                            pixel_perfect=pixel_perfect)
                    difficulty_clean_count += 1

                    # 2. å¦‚æœéœ€è¦æ¨¡ç³Šæ•ˆæœï¼Œç”Ÿæˆæœ‰åæ ‡çš„åŸºç¡€å›¾ç”¨äºæ¨¡ç³Š
                    if can_generate_blur:
                        # ç”Ÿæˆæœ‰åæ ‡çš„åŸºç¡€å›¾ï¼ˆä»…ç”¨äºæ¨¡ç³Šå›¾ç”Ÿæˆï¼‰
                        blur_base_generator = CleanChartGenerator(
                            figure_size=(image_size, image_size),
                            line_width=config['line_width'],
                            enable_style_diversity=enable_style_diversity,
                            style_diversity_level=style_diversity_level,
                            target_style=target_style
                        )

                        blur_base_file = temp_clean_dir / f"{csv_file.stem}_{difficulty}_blur_base.png"
                        blur_base_generator.process_csv_to_chart(csv_file, blur_base_file,
                                                               pure_line_only=False,  # bluråŸºç¡€å›¾æœ‰åæ ‡
                                                               pixel_perfect=pixel_perfect)

                        # ç”Ÿæˆ3å¼ ä¸åŒçš„æ¨¡ç³Šå›¾å˜ä½“
                        for variant in range(3):
                            blur_output_name = f"{csv_file.stem}_{difficulty}_variant_{variant}.png"
                            blur_output_path = temp_blur_dir / blur_output_name

                            try:
                                # åŠ è½½æœ‰åæ ‡çš„åŸºç¡€å›¾
                                base_image = blur_generator.load_image(blur_base_file)

                                # 1. åº”ç”¨åŸºç¡€é€€åŒ–æ•ˆæœï¼ˆæ¯å¼ éƒ½æœ‰ï¼‰
                                base_degraded = blur_generator.apply_base_degradation(base_image)

                                # 2. éšæœºæ·»åŠ é¢å¤–æ•ˆæœ
                                final_result = blur_generator.apply_random_additional_blur(base_degraded)

                                # ä¿å­˜ç»“æœ
                                import cv2
                                cv2.imwrite(str(blur_output_path), final_result['image'])
                                difficulty_blur_count += 1

                            except Exception as e:
                                print(f"    ğŸš¨ BLUR GENERATION FAILED for {blur_output_name}:")
                                print(f"       Error: {str(e)}")

                        # åˆ é™¤æ¨¡ç³ŠåŸºç¡€å›¾æ–‡ä»¶
                        if blur_base_file.exists():
                            blur_base_file.unlink()

                else:
                    # æ ‡å‡†æ¨¡å¼ï¼šcleanå’Œblurä½¿ç”¨ç»Ÿä¸€åŸºç¡€å›¾

                    # ç”Ÿæˆç»Ÿä¸€åŸºç¡€å›¾ï¼ˆæœ‰åæ ‡ï¼‰
                    difficulty_generator.process_csv_to_chart(csv_file, base_chart_file,
                                                            pure_line_only=False,  # æ ‡å‡†æ¨¡å¼æœ‰åæ ‡
                                                            pixel_perfect=pixel_perfect)

                    # 1. å°†åŸºç¡€å›¾ä½œä¸ºè¯¥éš¾åº¦çš„æ¸…æ™°å›¾ (ç›´æ¥å¤åˆ¶ï¼Œä¿æŒå®Œå…¨ä¸€è‡´)
                    clean_output_name = f"{csv_file.stem}_{difficulty}_clean.png"
                    clean_output_path = temp_clean_dir / clean_output_name

                    import shutil
                    shutil.copy2(base_chart_file, clean_output_path)
                    difficulty_clean_count += 1

                    # 2. å¦‚æœå¯ä»¥ç”Ÿæˆæ¨¡ç³Šæ•ˆæœï¼ŒåŸºäºåŒæ ·çš„åŸºç¡€å›¾ç”Ÿæˆæ¨¡ç³Šå›¾
                    if can_generate_blur:
                        # ç”Ÿæˆ3å¼ ä¸åŒçš„æ¨¡ç³Šå›¾å˜ä½“ï¼Œæ¯å¼ éƒ½åŸºäºç›¸åŒçš„åŸºç¡€å›¾
                        for variant in range(3):
                            blur_output_name = f"{csv_file.stem}_{difficulty}_variant_{variant}.png"
                            blur_output_path = temp_blur_dir / blur_output_name

                            try:
                                # åŠ è½½ç»Ÿä¸€åŸºç¡€å›¾
                                base_image = blur_generator.load_image(base_chart_file)

                                # 1. åº”ç”¨åŸºç¡€é€€åŒ–æ•ˆæœï¼ˆæ¯å¼ éƒ½æœ‰ï¼‰
                                base_degraded, base_effects_log = blur_generator.apply_base_degradation(base_image)

                                # 2. éšæœºæ·»åŠ é¢å¤–æ•ˆæœ
                                final_result = blur_generator.apply_random_additional_blur(base_degraded)

                                # 3. è®°å½•è¯¦ç»†çš„æ¨¡ç³Šæ•ˆæœæ—¥å¿—
                                blur_log = {
                                    'file': blur_output_name,
                                    'difficulty': difficulty,
                                    'variant': variant,
                                    'csv_source': csv_file.name,
                                    'base_effects': base_effects_log,
                                    'additional_effects': final_result.get('additional_effects_details', []),
                                    'total_effects': len(base_effects_log) + final_result.get('num_additional', 0)
                                }

                                # æ‰“å°ç®€åŒ–æ—¥å¿—
                                print(f"       ğŸ“ {blur_output_name}:")
                                print(f"          Base: {', '.join(base_effects_log)}")
                                if final_result.get('additional_effects_details'):
                                    print(f"          Extra: {', '.join(final_result['additional_effects_details'])}")
                                else:
                                    print(f"          Extra: None")

                                # ä¿å­˜ç»“æœ
                                import cv2
                                cv2.imwrite(str(blur_output_path), final_result['image'])
                                difficulty_blur_count += 1

                                # ä¿å­˜è¯¦ç»†æ—¥å¿—åˆ°æ–‡ä»¶
                                log_file = Path(output_dir) / 'blur_effects_log.txt'
                                with open(log_file, 'a', encoding='utf-8') as f:
                                    f.write(f"\n=== {blur_output_name} ===\n")
                                    f.write(f"Difficulty: {difficulty}\n")
                                    f.write(f"CSV Source: {csv_file.name}\n")
                                    f.write(f"Variant: {variant}\n")
                                    f.write(f"\nBase Effects:\n")
                                    for effect in base_effects_log:
                                        f.write(f"  - {effect}\n")
                                    f.write(f"\nAdditional Effects:\n")
                                    if final_result.get('additional_effects_details'):
                                        for effect in final_result['additional_effects_details']:
                                            f.write(f"  - {effect}\n")
                                    else:
                                        f.write(f"  - None\n")
                                    f.write(f"\nTotal Effects: {blur_log['total_effects']}\n")
                                    f.write("-" * 50 + "\n")

                            except Exception as e:
                                print(f"    ğŸš¨ BLUR GENERATION FAILED for {blur_output_name}:")
                                print(f"       Error: {str(e)}")

                    # åˆ é™¤ä¸´æ—¶åŸºç¡€å›¾æ–‡ä»¶ (å·²ç»å¤åˆ¶ç»™cleanï¼Œä¸å†éœ€è¦)
                    if base_chart_file.exists():
                        base_chart_file.unlink()

            except Exception as e:
                print(f"    âœ— ç”Ÿæˆ{difficulty}åŸºç¡€å›¾å¤±è´¥ {csv_file.name}: {e}")

        print(f"    âœ“ ç”Ÿæˆ {difficulty_clean_count} ä¸ªæ¸…æ™°å›¾ å’Œ {difficulty_blur_count} ä¸ª {difficulty} æ¨¡ç³Šå›¾")
        total_blur_count += difficulty_blur_count
        total_clean_count += difficulty_clean_count

    print(f"âœ“ æ€»å…±ç”Ÿæˆ {total_clean_count} ä¸ªæ¸…æ™°å›¾ å’Œ {total_blur_count} ä¸ªæ¨¡ç³Šå›¾")

    # æ­¥éª¤4: æ„å»ºåˆ†å±‚è®­ç»ƒæ•°æ®é›†
    print(f"\n4. æ„å»ºåˆ†å±‚è®­ç»ƒæ•°æ®é›†...")
    builder = DatasetBuilder()
    builder.split_paired_data_by_difficulty(temp_clean_dir, temp_blur_dir, final_dir,
                                          difficulties=difficulty_levels,
                                          split_ratios=(0.7, 0.15, 0.15))

    # æ¸…ç†ä¸´æ—¶ç›®å½•
    import shutil
    shutil.rmtree(temp_clean_dir, ignore_errors=True)
    shutil.rmtree(temp_blur_dir, ignore_errors=True)
    print(f"âœ“ æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

    # ç»Ÿè®¡åˆ†å±‚æ•°æ®é›†ç»“æœ
    print(f"\n=== åˆ†å±‚æ•°æ®é›†ç”Ÿæˆå®Œæˆ ===")
    total_train_clean = total_train_blur = 0
    total_val_clean = total_val_blur = 0
    total_test_clean = total_test_blur = 0

    for difficulty in difficulty_levels:
        difficulty_dir = final_dir / difficulty
        if difficulty_dir.exists():
            train_clean = len(list((difficulty_dir / 'train' / 'clean').glob("*.png")))
            train_blur = len(list((difficulty_dir / 'train' / 'blur').glob("*.png")))
            val_clean = len(list((difficulty_dir / 'val' / 'clean').glob("*.png")))
            val_blur = len(list((difficulty_dir / 'val' / 'blur').glob("*.png")))
            test_clean = len(list((difficulty_dir / 'test' / 'clean').glob("*.png")))
            test_blur = len(list((difficulty_dir / 'test' / 'blur').glob("*.png")))

            print(f"\n{difficulty.upper()} éš¾åº¦:")
            print(f"  è®­ç»ƒé›†: {train_clean} æ¸…æ™° + {train_blur} æ¨¡ç³Š")
            print(f"  éªŒè¯é›†: {val_clean} æ¸…æ™° + {val_blur} æ¨¡ç³Š")
            print(f"  æµ‹è¯•é›†: {test_clean} æ¸…æ™° + {test_blur} æ¨¡ç³Š")

            total_train_clean += train_clean
            total_train_blur += train_blur
            total_val_clean += val_clean
            total_val_blur += val_blur
            total_test_clean += test_clean
            total_test_blur += test_blur

    print(f"\næ€»è®¡:")
    print(f"è®­ç»ƒé›†: {total_train_clean} æ¸…æ™° + {total_train_blur} æ¨¡ç³Š")
    print(f"éªŒè¯é›†: {total_val_clean} æ¸…æ™° + {total_val_blur} æ¨¡ç³Š")
    print(f"æµ‹è¯•é›†: {total_test_clean} æ¸…æ™° + {total_test_blur} æ¨¡ç³Š")
    print(f"æ•°æ®é›†ä¿å­˜åœ¨: {final_dir.absolute()}")

    return True


def train_model(dataset_path: str, model_type: str = "unet",
                difficulty: str = "easy", epochs: int = 50,
                batch_size: int = 8, learning_rate: float = 1e-4):
    """è®­ç»ƒå»æ¨¡ç³Šæ¨¡å‹"""
    print(f"=== LineFuse æ¨¡å‹è®­ç»ƒ ===")
    print(f"æ•°æ®é›†: {dataset_path}")
    print(f"æ¨¡å‹ç±»å‹: {model_type}")
    print(f"éš¾åº¦çº§åˆ«: {difficulty}")
    print(f"è®­ç»ƒè½®æ•°: {epochs}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"å­¦ä¹ ç‡: {learning_rate}")

    try:
        import torch
        import torch.nn as nn
        from torch.utils.data import DataLoader
        from pathlib import Path
        import logging

        # è®¾ç½®è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")

        if not torch.cuda.is_available():
            print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

        # éªŒè¯æ•°æ®é›†è·¯å¾„
        dataset_dir = Path(dataset_path) / difficulty
        if not dataset_dir.exists():
            print(f"âœ— æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_dir}")
            print("è¯·å…ˆè¿è¡Œ 'python main.py generate' ç”Ÿæˆæ•°æ®é›†")
            return False

        # æ£€æŸ¥æ•°æ®é›†ç»“æ„
        train_clean = dataset_dir / 'train' / 'clean'
        train_blur = dataset_dir / 'train' / 'blur'
        val_clean = dataset_dir / 'val' / 'clean'
        val_blur = dataset_dir / 'val' / 'blur'

        for path in [train_clean, train_blur, val_clean, val_blur]:
            if not path.exists():
                print(f"âœ— ç¼ºå°‘æ•°æ®é›†ç›®å½•: {path}")
                return False

        print(f"âœ“ æ•°æ®é›†éªŒè¯é€šè¿‡")

        # å¯¼å…¥æ¨¡å‹å’Œè®­ç»ƒå™¨
        from src.models.unet_baseline import UNetBaseline
        from src.models.trainer import (
            ModelTrainer, DeblurDataset, get_default_transforms,
            create_loss_function, create_optimizer, create_scheduler
        )

        # åˆ›å»ºæ•°æ®é›†
        print("å‡†å¤‡æ•°æ®é›†...")
        transforms = get_default_transforms(image_size=512)

        train_dataset = DeblurDataset(str(train_clean), str(train_blur), transform=transforms)
        val_dataset = DeblurDataset(str(val_clean), str(val_blur), transform=transforms)

        train_loader = DataLoader(train_dataset, batch_size=batch_size,
                                shuffle=True, num_workers=4, pin_memory=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size,
                              shuffle=False, num_workers=4, pin_memory=True)

        print(f"è®­ç»ƒé›†: {len(train_dataset)} å›¾åƒå¯¹")
        print(f"éªŒè¯é›†: {len(val_dataset)} å›¾åƒå¯¹")

        # åˆ›å»ºæ¨¡å‹
        if model_type == "unet":
            model = UNetBaseline(in_channels=3, out_channels=3)
            print(f"âœ“ åˆ›å»ºU-Netæ¨¡å‹")
            print(f"æ¨¡å‹å‚æ•°é‡: {model.get_model_size():,}")
        elif model_type == "diffusion":
            from src.models.diffusion_model import ConditionalDiffusionModel
            model = ConditionalDiffusionModel(
                in_channels=3,
                out_channels=3,
                sample_size=512,
                num_train_timesteps=1000
            )
            print(f"âœ“ åˆ›å»ºæ¡ä»¶æ‰©æ•£æ¨¡å‹")
            print(f"æ¨¡å‹å‚æ•°é‡: {model.get_model_size():,}")
        else:
            print(f"âœ— ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
            return False

        # åˆ›å»ºæŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        loss_fn = create_loss_function('combined')
        optimizer = create_optimizer(model, 'adamw', learning_rate)
        scheduler = create_scheduler(optimizer, 'cosine', epochs)

        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ModelTrainer(
            model=model,
            loss_fn=loss_fn,
            optimizer=optimizer,
            scheduler=scheduler,
            device=device,
            mixed_precision=True
        )

        # è®¾ç½®ä¿å­˜ç›®å½•
        save_dir = Path(f'models/{model_type}_{difficulty}')
        save_dir.mkdir(parents=True, exist_ok=True)

        print(f"å¼€å§‹è®­ç»ƒ...")
        print(f"æ¨¡å‹å°†ä¿å­˜åˆ°: {save_dir.absolute()}")

        # å¼€å§‹è®­ç»ƒ
        results = trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            num_epochs=epochs,
            save_dir=save_dir,
            save_every=10
        )

        print(f"\n=== è®­ç»ƒå®Œæˆ ===")
        print(f"æœ€ä½³éªŒè¯PSNR: {results['best_val_psnr']:.2f}dB")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {results['best_val_loss']:.4f}")
        print(f"æ¨¡å‹ä¿å­˜åœ¨: {save_dir / 'best_model.pth'}")

        return True

    except ImportError as e:
        print(f"âœ— ç¼ºå°‘å¿…è¦ä¾èµ–: {e}")
        print("è¯·è¿è¡Œ: conda install pytorch torchvision -c pytorch")
        print("æˆ–å®‰è£…GPUç‰ˆæœ¬: conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia")
        return False
    except Exception as e:
        print(f"âœ— è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description='LineFuse - å…‰è°±å›¾åƒå»æ¨¡ç³Šç³»ç»Ÿ')

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # æ•°æ®ç”Ÿæˆå‘½ä»¤
    gen_parser = subparsers.add_parser('generate', help='ç”Ÿæˆè®­ç»ƒæ•°æ®é›†')
    gen_parser.add_argument('--samples', type=int, default=50,
                           help='ç”Ÿæˆçš„å…‰è°±æ ·æœ¬æ•°é‡ (é»˜è®¤: 50)')
    gen_parser.add_argument('--output', type=str, default='linefuse_dataset',
                           help='è¾“å‡ºç›®å½• (é»˜è®¤: linefuse_dataset)')
    gen_parser.add_argument('--no-style-diversity', action='store_true',
                           help='ç¦ç”¨æ ·å¼å¤šæ ·åŒ– (é»˜è®¤: å¯ç”¨)')
    gen_parser.add_argument('--style-level', type=float, default=0.8,
                           help='æ ·å¼å¤šæ ·åŒ–ç¨‹åº¦ 0.0-1.0 (é»˜è®¤: 0.8)')
    gen_parser.add_argument('--target-style', type=str, choices=['scan_document', 'academic_paper', 'lab_notebook', 'field_notes', 'mixed'],
                           help='æŒ‡å®šç‰¹å®šæ ·å¼æ¨¡æ¿ (mixed=éšæœºæ··åˆ)')
    gen_parser.add_argument('--image-size', type=int, default=1024,
                           help='å›¾åƒå°ºå¯¸ (é»˜è®¤: 1024x1024)')
    gen_parser.add_argument('--line-width', type=float, default=0.8,
                           help='çº¿æ¡ç²—ç»† (é»˜è®¤: 0.8)')
    gen_parser.add_argument('--pixel-perfect', action='store_true', default=True,
                           help='å¯ç”¨åƒç´ å®Œç¾å¯¹é½ (é»˜è®¤: True)')
    gen_parser.add_argument('--no-pixel-perfect', action='store_true',
                           help='ç¦ç”¨åƒç´ å®Œç¾å¯¹é½')
    gen_parser.add_argument('--pure-line-only', action='store_true',
                           help='çº¯çº¿æ¡æ¨¡å¼ (ä»…çº¿æ¡ï¼Œæ— åæ ‡è½´ç­‰)')
    gen_parser.add_argument('--test-new-blur', action='store_true',
                           help='æµ‹è¯•æ–°çš„æ¨¡ç³Šæ•ˆæœ (çº¿æ¡æ–­ç»­ã€åŒºåŸŸç»†åŒ–ç­‰)')

    # è®­ç»ƒå‘½ä»¤
    train_parser = subparsers.add_parser('train', help='è®­ç»ƒå»æ¨¡ç³Šæ¨¡å‹')
    train_parser.add_argument('--dataset', type=str, required=True,
                             help='è®­ç»ƒæ•°æ®é›†è·¯å¾„')
    train_parser.add_argument('--model', type=str, default='unet',
                             choices=['unet', 'diffusion'],
                             help='æ¨¡å‹ç±»å‹ (é»˜è®¤: unet)')
    train_parser.add_argument('--difficulty', type=str, default='easy',
                             choices=['easy', 'medium', 'hard'],
                             help='è®­ç»ƒéš¾åº¦çº§åˆ« (é»˜è®¤: easy)')
    train_parser.add_argument('--epochs', type=int, default=50,
                             help='è®­ç»ƒè½®æ•° (é»˜è®¤: 50)')
    train_parser.add_argument('--batch-size', type=int, default=8,
                             help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 8)')
    train_parser.add_argument('--lr', type=float, default=1e-4,
                             help='å­¦ä¹ ç‡ (é»˜è®¤: 1e-4)')

    # å¿«é€Ÿæ¼”ç¤ºå‘½ä»¤
    demo_parser = subparsers.add_parser('demo', help='å¿«é€Ÿæ¼”ç¤º (10ä¸ªæ ·æœ¬)')

    args = parser.parse_args()

    if args.command == 'generate':
        # å¤„ç†pixel_perfectå‚æ•°
        pixel_perfect = args.pixel_perfect and not args.no_pixel_perfect

        generate_dataset(
            num_samples=args.samples,
            output_dir=args.output,
            enable_style_diversity=not args.no_style_diversity,
            style_diversity_level=args.style_level,
            image_size=args.image_size,
            line_width=args.line_width,
            pixel_perfect=pixel_perfect,
            pure_line_only=args.pure_line_only,
            target_style=args.target_style
        )
    elif args.command == 'train':
        train_model(
            dataset_path=args.dataset,
            model_type=args.model,
            difficulty=args.difficulty,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.lr
        )
    elif args.command == 'demo':
        print("=== LineFuse å¿«é€Ÿæ¼”ç¤º ===")
        generate_dataset(
            num_samples=10,
            output_dir="demo_dataset",
            enable_style_diversity=True,
            style_diversity_level=0.9  # æ¼”ç¤ºæ—¶ä½¿ç”¨é«˜å¤šæ ·æ€§
        )
    else:
        parser.print_help()

if __name__ == "__main__":
    main()